<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.10.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>fbgemm_gpu: Quantization Operators (CUDA)</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">fbgemm_gpu
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.10.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">Quantization Operators (CUDA)</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ga2f1cc4b6dc6f708324855f94d558cfc1" id="r_ga2f1cc4b6dc6f708324855f94d558cfc1"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga2f1cc4b6dc6f708324855f94d558cfc1">_float_to_bfloat16_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>)</td></tr>
<tr class="separator:ga2f1cc4b6dc6f708324855f94d558cfc1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2076a59fd190690f67c1eddb79b6acc4" id="r_ga2076a59fd190690f67c1eddb79b6acc4"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga2076a59fd190690f67c1eddb79b6acc4">_bfloat16_to_float_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>)</td></tr>
<tr class="separator:ga2076a59fd190690f67c1eddb79b6acc4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga31b9029d43a60ad1fc90dc6ec54af9db" id="r_ga31b9029d43a60ad1fc90dc6ec54af9db"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga31b9029d43a60ad1fc90dc6ec54af9db">_float_to_FP8rowwise_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> forward)</td></tr>
<tr class="separator:ga31b9029d43a60ad1fc90dc6ec54af9db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga70d90c85fad4384b23c8958a6c300ce2" id="r_ga70d90c85fad4384b23c8958a6c300ce2"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga70d90c85fad4384b23c8958a6c300ce2">_FP8rowwise_to_float_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> forward, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">output_dtype</a>)</td></tr>
<tr class="separator:ga70d90c85fad4384b23c8958a6c300ce2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga8c11c8dc06cae57b3afba79358c00e99" id="r_ga8c11c8dc06cae57b3afba79358c00e99"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga8c11c8dc06cae57b3afba79358c00e99">_float_to_fused8bitrowwise_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>)</td></tr>
<tr class="separator:ga8c11c8dc06cae57b3afba79358c00e99"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gadfeb2fc956b7aa5c2446a00ccbcd058e" id="r_gadfeb2fc956b7aa5c2446a00ccbcd058e"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gadfeb2fc956b7aa5c2446a00ccbcd058e">_half_to_fused8bitrowwise_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>)</td></tr>
<tr class="separator:gadfeb2fc956b7aa5c2446a00ccbcd058e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaff285349cb9c51a56fc418b628772b16" id="r_gaff285349cb9c51a56fc418b628772b16"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaff285349cb9c51a56fc418b628772b16">_single_or_half_precision_to_fused8bitrowwise_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>)</td></tr>
<tr class="separator:gaff285349cb9c51a56fc418b628772b16"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaab093a380068925d1b267452a1e255c2" id="r_gaab093a380068925d1b267452a1e255c2"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaab093a380068925d1b267452a1e255c2">_fused8bitrowwise_to_float_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>)</td></tr>
<tr class="separator:gaab093a380068925d1b267452a1e255c2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga3aa2e594cf4bbb5cb5241c4eaa593f8a" id="r_ga3aa2e594cf4bbb5cb5241c4eaa593f8a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga3aa2e594cf4bbb5cb5241c4eaa593f8a">_fused8bitrowwise_to_half_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>)</td></tr>
<tr class="separator:ga3aa2e594cf4bbb5cb5241c4eaa593f8a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gafacdb4ec7d8f5b969c75d2127537ab16" id="r_gafacdb4ec7d8f5b969c75d2127537ab16"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gafacdb4ec7d8f5b969c75d2127537ab16">_fused8bitrowwise_to_single_or_half_precision_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">output_dtype</a>)</td></tr>
<tr class="separator:gafacdb4ec7d8f5b969c75d2127537ab16"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga4c2c033e940095d20e76e9e00fe925d3" id="r_ga4c2c033e940095d20e76e9e00fe925d3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga4c2c033e940095d20e76e9e00fe925d3">_fused8bitrowwise_to_float_mixed_dim_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="gen__batch__index__select__dim0__forward__kernel__small_8cu.html#a8a3ac708f5fc38ea5ebecdbe685f3c73">D_offsets</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">output_dtype</a>)</td></tr>
<tr class="separator:ga4c2c033e940095d20e76e9e00fe925d3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaa3e8fd136e9bfa0e4d0c0016659bf708" id="r_gaa3e8fd136e9bfa0e4d0c0016659bf708"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaa3e8fd136e9bfa0e4d0c0016659bf708">_float_to_fusednbitrowwise_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bit_rate</a>)</td></tr>
<tr class="separator:gaa3e8fd136e9bfa0e4d0c0016659bf708"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6e2bd64f3f9e3b36493ec955680771af" id="r_ga6e2bd64f3f9e3b36493ec955680771af"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga6e2bd64f3f9e3b36493ec955680771af">_half_to_fusednbitrowwise_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bit_rate</a>)</td></tr>
<tr class="separator:ga6e2bd64f3f9e3b36493ec955680771af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga3b963d0e45c2bc0060aaa974efe64b8a" id="r_ga3b963d0e45c2bc0060aaa974efe64b8a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga3b963d0e45c2bc0060aaa974efe64b8a">_float_or_half_to_fusednbitrowwise_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bit_rate</a>)</td></tr>
<tr class="separator:ga3b963d0e45c2bc0060aaa974efe64b8a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae0193dd7bbb4e72fc977330cc3f019a4" id="r_gae0193dd7bbb4e72fc977330cc3f019a4"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gae0193dd7bbb4e72fc977330cc3f019a4">_fusednbitrowwise_to_float_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bit_rate</a>)</td></tr>
<tr class="separator:gae0193dd7bbb4e72fc977330cc3f019a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6152517943258bd3adc42b7c103a9277" id="r_ga6152517943258bd3adc42b7c103a9277"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga6152517943258bd3adc42b7c103a9277">_fusednbitrowwise_to_half_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bit_rate</a>)</td></tr>
<tr class="separator:ga6152517943258bd3adc42b7c103a9277"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga07f4c02c95710472b815bdc1d7bfff19" id="r_ga07f4c02c95710472b815bdc1d7bfff19"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga07f4c02c95710472b815bdc1d7bfff19">_fusednbitrowwise_to_float_or_half_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bit_rate</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">output_dtype</a>)</td></tr>
<tr class="separator:ga07f4c02c95710472b815bdc1d7bfff19"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab2837424e3774fe34ba255658554a75a" id="r_gab2837424e3774fe34ba255658554a75a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gab2837424e3774fe34ba255658554a75a">_float_to_hfp8_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">ebits</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">exponent_bias</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">max_pos</a>)</td></tr>
<tr class="separator:gab2837424e3774fe34ba255658554a75a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga03a8f8825a16c6235b699886fa46e1f6" id="r_ga03a8f8825a16c6235b699886fa46e1f6"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga03a8f8825a16c6235b699886fa46e1f6">_hfp8_to_float_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">ebits</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">exponent_bias</a>)</td></tr>
<tr class="separator:ga03a8f8825a16c6235b699886fa46e1f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga427f81e1d8901e2fafc9611860fbd4d5" id="r_ga427f81e1d8901e2fafc9611860fbd4d5"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga427f81e1d8901e2fafc9611860fbd4d5">_float_to_msfp_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bounding_box_size</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">ebits</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">mbits</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bias</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">min_pos</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">max_pos</a>)</td></tr>
<tr class="separator:ga427f81e1d8901e2fafc9611860fbd4d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gac0c20377454dbfafcc5ac245fe6427ce" id="r_gac0c20377454dbfafcc5ac245fe6427ce"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gac0c20377454dbfafcc5ac245fe6427ce">_msfp_to_float_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">ebits</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">mbits</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bias</a>)</td></tr>
<tr class="separator:gac0c20377454dbfafcc5ac245fe6427ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga5043927653e4d50462b79b7f3df33223" id="r_ga5043927653e4d50462b79b7f3df33223"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga5043927653e4d50462b79b7f3df33223">_float_to_paddedFP8rowwise_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> forward, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">row_dim</a>)</td></tr>
<tr class="separator:ga5043927653e4d50462b79b7f3df33223"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gafc30bb56977528d8a85e43f9aa5c2cf8" id="r_gafc30bb56977528d8a85e43f9aa5c2cf8"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gafc30bb56977528d8a85e43f9aa5c2cf8">_paddedFP8rowwise_to_float_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> forward, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">row_dim</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">output_last_dim</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">output_dtype</a>)</td></tr>
<tr class="separator:gafc30bb56977528d8a85e43f9aa5c2cf8"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<h2 class="groupheader">Function Documentation</h2>
<a id="ga2076a59fd190690f67c1eddb79b6acc4" name="ga2076a59fd190690f67c1eddb79b6acc4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga2076a59fd190690f67c1eddb79b6acc4">&#9670;&#160;</a></span>_bfloat16_to_float_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _bfloat16_to_float_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of Brain Floating Point (<code>bfloat16</code>) values into a tensor of <code>float</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>bfloat16</code> values</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>float</code>. </dd></dl>

</div>
</div>
<a id="ga3b963d0e45c2bc0060aaa974efe64b8a" name="ga3b963d0e45c2bc0060aaa974efe64b8a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga3b963d0e45c2bc0060aaa974efe64b8a">&#9670;&#160;</a></span>_float_or_half_to_fusednbitrowwise_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _float_or_half_to_fusednbitrowwise_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bit_rate</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>float</code> or <code>at::Half</code> values into a tensor of fused N-bit rowwise values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>float</code> or <code>at::Half</code> values </td></tr>
    <tr><td class="paramname">bit_rate</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to fused N-bit rowwise. </dd></dl>

</div>
</div>
<a id="ga2f1cc4b6dc6f708324855f94d558cfc1" name="ga2f1cc4b6dc6f708324855f94d558cfc1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga2f1cc4b6dc6f708324855f94d558cfc1">&#9670;&#160;</a></span>_float_to_bfloat16_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _float_to_bfloat16_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>float</code> values into a tensor of Brain Floating Point (<code>bfloat16</code>) values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>float</code> values</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>bfloat16</code>. </dd></dl>

</div>
</div>
<a id="ga31b9029d43a60ad1fc90dc6ec54af9db" name="ga31b9029d43a60ad1fc90dc6ec54af9db"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga31b9029d43a60ad1fc90dc6ec54af9db">&#9670;&#160;</a></span>_float_to_FP8rowwise_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _float_to_FP8rowwise_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>forward</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>float</code> values into a tensor of <code>fp8</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>float</code> values. The dtype can be either <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833ea693aa0bef84c25fe81c7e62e72f9313d">SparseType::FP32</a></code>, <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833eaa4bf99d6945c25077fd6660d536af8a0">SparseType::FP16</a></code>, or <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833eaf656bbf613964dcf710b771b0918ab30">SparseType::BF16</a></code> </td></tr>
    <tr><td class="paramname">forward</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>fp8</code>.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">c10::Error</td><td>if <code>input.dtype</code> is not one of (<code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833ea693aa0bef84c25fe81c7e62e72f9313d">SparseType::FP32</a></code>, <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833eaa4bf99d6945c25077fd6660d536af8a0">SparseType::FP16</a></code>, or <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833eaf656bbf613964dcf710b771b0918ab30">SparseType::BF16</a></code>). </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga8c11c8dc06cae57b3afba79358c00e99" name="ga8c11c8dc06cae57b3afba79358c00e99"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga8c11c8dc06cae57b3afba79358c00e99">&#9670;&#160;</a></span>_float_to_fused8bitrowwise_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _float_to_fused8bitrowwise_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>float</code> values into a tensor of fused 8-bit rowwise values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>float</code> values</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to fused 8-bit rowwise. </dd></dl>

</div>
</div>
<a id="gaa3e8fd136e9bfa0e4d0c0016659bf708" name="gaa3e8fd136e9bfa0e4d0c0016659bf708"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaa3e8fd136e9bfa0e4d0c0016659bf708">&#9670;&#160;</a></span>_float_to_fusednbitrowwise_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _float_to_fusednbitrowwise_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bit_rate</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>float</code> values into a tensor of fused N-bit rowwise values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>float</code> values </td></tr>
    <tr><td class="paramname">bit_rate</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to fused N-bit rowwise. </dd></dl>

</div>
</div>
<a id="gab2837424e3774fe34ba255658554a75a" name="gab2837424e3774fe34ba255658554a75a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab2837424e3774fe34ba255658554a75a">&#9670;&#160;</a></span>_float_to_hfp8_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _float_to_hfp8_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>ebits</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>exponent_bias</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>max_pos</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>float</code> values into a tensor of Hybrid 8-bit Floating Point (<code>hfp8</code>) values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>float</code> values </td></tr>
    <tr><td class="paramname">ebits</td><td></td></tr>
    <tr><td class="paramname">exponent_bias</td><td></td></tr>
    <tr><td class="paramname">max_pos</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>hfp8</code>.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">c10::Error</td><td>if <code>ebits &gt; 0</code> or <code>exponent_bias &gt; 0</code>. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga427f81e1d8901e2fafc9611860fbd4d5" name="ga427f81e1d8901e2fafc9611860fbd4d5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga427f81e1d8901e2fafc9611860fbd4d5">&#9670;&#160;</a></span>_float_to_msfp_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _float_to_msfp_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bounding_box_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>ebits</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>mbits</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bias</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>min_pos</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>max_pos</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>float</code> values into a tensor of Microsoft Floating Point (<code>msfp</code>) values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>float</code> values </td></tr>
    <tr><td class="paramname">bounding_box_size</td><td></td></tr>
    <tr><td class="paramname">ebits</td><td></td></tr>
    <tr><td class="paramname">mbits</td><td></td></tr>
    <tr><td class="paramname">bias</td><td></td></tr>
    <tr><td class="paramname">min_pos</td><td></td></tr>
    <tr><td class="paramname">max_pos</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>msfp</code>. </dd></dl>

</div>
</div>
<a id="ga5043927653e4d50462b79b7f3df33223" name="ga5043927653e4d50462b79b7f3df33223"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga5043927653e4d50462b79b7f3df33223">&#9670;&#160;</a></span>_float_to_paddedFP8rowwise_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _float_to_paddedFP8rowwise_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>forward</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>row_dim</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>float</code> values into a tensor of padded <code>fp8</code> rowwise values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>float</code> values. The dtype can be either <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833ea693aa0bef84c25fe81c7e62e72f9313d">SparseType::FP32</a></code>, <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833eaa4bf99d6945c25077fd6660d536af8a0">SparseType::FP16</a></code>, or <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833eaf656bbf613964dcf710b771b0918ab30">SparseType::BF16</a></code> </td></tr>
    <tr><td class="paramname">forward</td><td></td></tr>
    <tr><td class="paramname">row_dim</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to padded <code>fp8</code> rowwise. </dd></dl>

</div>
</div>
<a id="ga70d90c85fad4384b23c8958a6c300ce2" name="ga70d90c85fad4384b23c8958a6c300ce2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga70d90c85fad4384b23c8958a6c300ce2">&#9670;&#160;</a></span>_FP8rowwise_to_float_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _FP8rowwise_to_float_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>forward</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>output_dtype</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>fp8</code> values into a tensor of <code>float</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>fp8</code> values </td></tr>
    <tr><td class="paramname">forward</td><td></td></tr>
    <tr><td class="paramname">output_dtype</td><td>The target floating point type, specified as integer representation of <code>SparseType</code> enum</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>float</code> (with <code>dtype</code> of either <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833ea693aa0bef84c25fe81c7e62e72f9313d">SparseType::FP32</a></code>, <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833eaa4bf99d6945c25077fd6660d536af8a0">SparseType::FP16</a></code>, or <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833eaf656bbf613964dcf710b771b0918ab30">SparseType::BF16</a></code>).</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">c10::Error</td><td>if <code>output_dtype</code> is not one of (<code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833ea693aa0bef84c25fe81c7e62e72f9313d">SparseType::FP32</a></code>, <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833eaa4bf99d6945c25077fd6660d536af8a0">SparseType::FP16</a></code>, or <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833eaf656bbf613964dcf710b771b0918ab30">SparseType::BF16</a></code>). </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="gaab093a380068925d1b267452a1e255c2" name="gaab093a380068925d1b267452a1e255c2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaab093a380068925d1b267452a1e255c2">&#9670;&#160;</a></span>_fused8bitrowwise_to_float_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _fused8bitrowwise_to_float_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of fused 8-bit rowwise values into a tensor of <code>float</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of fused 8-bit rowwise values</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>float</code>. </dd></dl>

</div>
</div>
<a id="ga4c2c033e940095d20e76e9e00fe925d3" name="ga4c2c033e940095d20e76e9e00fe925d3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga4c2c033e940095d20e76e9e00fe925d3">&#9670;&#160;</a></span>_fused8bitrowwise_to_float_mixed_dim_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _fused8bitrowwise_to_float_mixed_dim_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>D_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>output_dtype</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of fused 8-bit rowwise values into a tensor of <code>at::kFloat</code> or <code>at::kHalf</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of fused 8-bit rowwise values </td></tr>
    <tr><td class="paramname">D_offsets</td><td></td></tr>
    <tr><td class="paramname">output_dtype</td><td>The target floating point type, specified as integer representation of <code>SparseType</code> enum</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>at::kFloat</code> or <code>at::kHalf</code>.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">c10::Error</td><td>if <code>output_dtype</code> is not one of (<code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833ea693aa0bef84c25fe81c7e62e72f9313d">SparseType::FP32</a></code>, <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833eaa4bf99d6945c25077fd6660d536af8a0">SparseType::FP16</a></code>) </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga3aa2e594cf4bbb5cb5241c4eaa593f8a" name="ga3aa2e594cf4bbb5cb5241c4eaa593f8a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga3aa2e594cf4bbb5cb5241c4eaa593f8a">&#9670;&#160;</a></span>_fused8bitrowwise_to_half_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _fused8bitrowwise_to_half_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of fused 8-bit rowwise values into a tensor of <code>at::Half</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of fused 8-bit rowwise values</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>at::Half</code>. </dd></dl>

</div>
</div>
<a id="gafacdb4ec7d8f5b969c75d2127537ab16" name="gafacdb4ec7d8f5b969c75d2127537ab16"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gafacdb4ec7d8f5b969c75d2127537ab16">&#9670;&#160;</a></span>_fused8bitrowwise_to_single_or_half_precision_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _fused8bitrowwise_to_single_or_half_precision_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>output_dtype</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of fused 8-bit rowwise values into a tensor of <code>float</code>, <code>at::Half</code>, or <code>at::BFloat16</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of fused 8-bit rowwise values </td></tr>
    <tr><td class="paramname">output_dtype</td><td>The target floating point type, specified as integer representation of <code>SparseType</code> enum</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>float</code>, <code>at::Half</code>, or <code>at::BFloat16</code>.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">c10::Error</td><td>if <code>output_dtype</code> is not one of (<code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833ea693aa0bef84c25fe81c7e62e72f9313d">SparseType::FP32</a></code>, <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833eaa4bf99d6945c25077fd6660d536af8a0">SparseType::FP16</a></code>, or <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833eaf656bbf613964dcf710b771b0918ab30">SparseType::BF16</a></code>). </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="gae0193dd7bbb4e72fc977330cc3f019a4" name="gae0193dd7bbb4e72fc977330cc3f019a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae0193dd7bbb4e72fc977330cc3f019a4">&#9670;&#160;</a></span>_fusednbitrowwise_to_float_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _fusednbitrowwise_to_float_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bit_rate</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of fused N-bit rowwise values into a tensor of <code>float</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of fused N-bit rowwise values </td></tr>
    <tr><td class="paramname">bit_rate</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>float</code>. </dd></dl>

</div>
</div>
<a id="ga07f4c02c95710472b815bdc1d7bfff19" name="ga07f4c02c95710472b815bdc1d7bfff19"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga07f4c02c95710472b815bdc1d7bfff19">&#9670;&#160;</a></span>_fusednbitrowwise_to_float_or_half_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _fusednbitrowwise_to_float_or_half_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bit_rate</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>output_dtype</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of fused N-bit rowwise values into a tensor of <code>float</code> or <code>at::Half</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of fused N-bit rowwise values </td></tr>
    <tr><td class="paramname">bit_rate</td><td></td></tr>
    <tr><td class="paramname">output_dtype</td><td>The target floating point type, specified as integer representation of <code>SparseType</code> enum</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>float</code> or <code>at::Half</code>, depending on <code>output_dtype</code>.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">c10::Error</td><td>if <code>output_dtype</code> is not one of (<code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833ea693aa0bef84c25fe81c7e62e72f9313d">SparseType::FP32</a></code> or <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833eaa4bf99d6945c25077fd6660d536af8a0">SparseType::FP16</a></code>). </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga6152517943258bd3adc42b7c103a9277" name="ga6152517943258bd3adc42b7c103a9277"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga6152517943258bd3adc42b7c103a9277">&#9670;&#160;</a></span>_fusednbitrowwise_to_half_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _fusednbitrowwise_to_half_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bit_rate</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of fused N-bit rowwise values into a tensor of <code>at::Half</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of fused N-bit rowwise values </td></tr>
    <tr><td class="paramname">bit_rate</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>at::Half</code>. </dd></dl>

</div>
</div>
<a id="gadfeb2fc956b7aa5c2446a00ccbcd058e" name="gadfeb2fc956b7aa5c2446a00ccbcd058e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gadfeb2fc956b7aa5c2446a00ccbcd058e">&#9670;&#160;</a></span>_half_to_fused8bitrowwise_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _half_to_fused8bitrowwise_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>at::Half</code> values into a tensor of fused 8-bit rowwise values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>at::Half</code> values</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to fused 8-bit rowwise. </dd></dl>

</div>
</div>
<a id="ga6e2bd64f3f9e3b36493ec955680771af" name="ga6e2bd64f3f9e3b36493ec955680771af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga6e2bd64f3f9e3b36493ec955680771af">&#9670;&#160;</a></span>_half_to_fusednbitrowwise_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _half_to_fusednbitrowwise_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bit_rate</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>at::Half</code> values into a tensor of fused N-bit rowwise values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>at::Half</code> values </td></tr>
    <tr><td class="paramname">bit_rate</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to fused N-bit rowwise. </dd></dl>

</div>
</div>
<a id="ga03a8f8825a16c6235b699886fa46e1f6" name="ga03a8f8825a16c6235b699886fa46e1f6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga03a8f8825a16c6235b699886fa46e1f6">&#9670;&#160;</a></span>_hfp8_to_float_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _hfp8_to_float_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>ebits</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>exponent_bias</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of Hybrid 8-bit Floating Point (<code>hfp8</code>) values into a tensor of <code>float</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>hfp8</code> values </td></tr>
    <tr><td class="paramname">ebits</td><td></td></tr>
    <tr><td class="paramname">exponent_bias</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>float</code>.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">c10::Error</td><td>if <code>ebits &gt; 0</code> or <code>exponent_bias &gt; 0</code>. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="gac0c20377454dbfafcc5ac245fe6427ce" name="gac0c20377454dbfafcc5ac245fe6427ce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gac0c20377454dbfafcc5ac245fe6427ce">&#9670;&#160;</a></span>_msfp_to_float_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _msfp_to_float_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>ebits</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>mbits</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bias</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of Microsoft Floating Point (<code>msfp</code>) values into a tensor of <code>float</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>msfp</code> values </td></tr>
    <tr><td class="paramname">ebits</td><td></td></tr>
    <tr><td class="paramname">mbits</td><td></td></tr>
    <tr><td class="paramname">bias</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>float</code>. </dd></dl>

</div>
</div>
<a id="gafc30bb56977528d8a85e43f9aa5c2cf8" name="gafc30bb56977528d8a85e43f9aa5c2cf8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gafc30bb56977528d8a85e43f9aa5c2cf8">&#9670;&#160;</a></span>_paddedFP8rowwise_to_float_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _paddedFP8rowwise_to_float_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>forward</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>row_dim</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>output_last_dim</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>output_dtype</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of padded <code>fp8</code> rowwise values into a tensor of <code>float values</code>.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>float</code> values. The dtype can be either <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833ea693aa0bef84c25fe81c7e62e72f9313d">SparseType::FP32</a></code>, <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833eaa4bf99d6945c25077fd6660d536af8a0">SparseType::FP16</a></code>, or <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833eaf656bbf613964dcf710b771b0918ab30">SparseType::BF16</a></code> </td></tr>
    <tr><td class="paramname">forward</td><td></td></tr>
    <tr><td class="paramname">row_dim</td><td></td></tr>
    <tr><td class="paramname">output_last_dim</td><td></td></tr>
    <tr><td class="paramname">output_dtype</td><td>The target floating point type, specified as integer representation of <code>SparseType</code> enum</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>float</code>.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">c10::Error</td><td>if <code>output_dtype</code> is not one of (<code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833ea693aa0bef84c25fe81c7e62e72f9313d">SparseType::FP32</a></code>, <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833eaa4bf99d6945c25077fd6660d536af8a0">SparseType::FP16</a></code>, <code><a class="el" href="namespacefbgemm__gpu.html#a47b4476e5f749d63e15d2f8e55be833eaf656bbf613964dcf710b771b0918ab30">SparseType::BF16</a></code>). </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="gaff285349cb9c51a56fc418b628772b16" name="gaff285349cb9c51a56fc418b628772b16"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaff285349cb9c51a56fc418b628772b16">&#9670;&#160;</a></span>_single_or_half_precision_to_fused8bitrowwise_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _single_or_half_precision_to_fused8bitrowwise_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="namespacefbgemm__gpu.html#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>at::Single</code> or <code>at::Half</code> values into a tensor of fused 8-bit rowwise values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>at::Single</code> or <code>at::Half</code> values</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to fused 8-bit rowwise. </dd></dl>

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.10.0
</small></address>
</body>
</html>
