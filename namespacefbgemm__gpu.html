<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.10.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>fbgemm_gpu: fbgemm_gpu Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">fbgemm_gpu
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.10.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">fbgemm_gpu Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_bitonic_sort.html">BitonicSort</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_comparator.html">Comparator</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_default_ptr_traits.html">DefaultPtrTraits</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classfbgemm__gpu_1_1enum__registration.html">enum_registration</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classfbgemm__gpu_1_1_fixed_divisor.html">FixedDivisor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classfbgemm__gpu_1_1_generic_packed_tensor_accessor.html">GenericPackedTensorAccessor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classfbgemm__gpu_1_1_generic_packed_tensor_accessor_3_01_t_00_011_00_01_ptr_traits_00_01index__t_01_4.html">GenericPackedTensorAccessor&lt; T, 1, PtrTraits, index_t &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classfbgemm__gpu_1_1_generic_packed_tensor_accessor_base.html">GenericPackedTensorAccessorBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_half4.html">Half4</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classfbgemm__gpu_1_1_permute_pooled_embs_function.html">PermutePooledEmbsFunction</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classfbgemm__gpu_1_1_permute_pooled_embs_function_split.html">PermutePooledEmbsFunctionSplit</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1rk__state.html">rk_state</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_shared_memory.html">SharedMemory</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_shared_memory_3_01double_01_4.html">SharedMemory&lt; double &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_shared_memory_3_01float_01_4.html">SharedMemory&lt; float &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_shared_memory_3_01int32__t_01_4.html">SharedMemory&lt; int32_t &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_shared_memory_3_01int64__t_01_4.html">SharedMemory&lt; int64_t &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_shared_memory_3_01_vec4_t_3_01at_1_1acc__type_3_01double_00_01true_01_4_01_4_01_4.html">SharedMemory&lt; Vec4T&lt; at::acc_type&lt; double, true &gt; &gt; &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_shared_memory_3_01_vec4_t_3_01at_1_1acc__type_3_01float_00_01true_01_4_01_4_01_4.html">SharedMemory&lt; Vec4T&lt; at::acc_type&lt; float, true &gt; &gt; &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_stochastic_rounding_r_n_g_state.html">StochasticRoundingRNGState</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">TensorAccessor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor_3_01_t_00_011_00_01_ptr_traits_00_01index__t_01_4.html">TensorAccessor&lt; T, 1, PtrTraits, index_t &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor_base.html">TensorAccessorBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_vec4_acc_t.html">Vec4AccT</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_vec4_step_t.html">Vec4StepT</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_vec4_step_t_3_01_s_t_e_p_00_01at_1_1_half_01_4.html">Vec4StepT&lt; STEP, at::Half &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_vec4_step_t_3_01_s_t_e_p_00_01float_01_4.html">Vec4StepT&lt; STEP, float &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_vec4_step_t_3_01_s_t_e_p_00_01uint8__t_01_4.html">Vec4StepT&lt; STEP, uint8_t &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">Vec4T</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_vec4_t_3_01at_1_1_b_float16_01_4.html">Vec4T&lt; at::BFloat16 &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_vec4_t_3_01at_1_1_half_01_4.html">Vec4T&lt; at::Half &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_vec4_t_3_01double_01_4.html">Vec4T&lt; double &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_vec4_t_3_01float_01_4.html">Vec4T&lt; float &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_vec_n_t.html">VecNT</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_vec_n_t_3_011_00_01_primitive_type_1_1_f_p_01_4.html">VecNT&lt; 1, PrimitiveType::FP &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_vec_n_t_3_0116_00_01_primitive_type_1_1_i_n_t_01_4.html">VecNT&lt; 16, PrimitiveType::INT &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_vec_n_t_3_012_00_01_primitive_type_1_1_f_p_01_4.html">VecNT&lt; 2, PrimitiveType::FP &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_vec_n_t_3_014_00_01_primitive_type_1_1_f_p_01_4.html">VecNT&lt; 4, PrimitiveType::FP &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_vec_n_t_3_014_00_01_primitive_type_1_1_i_n_t_01_4.html">VecNT&lt; 4, PrimitiveType::INT &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_vec_n_t_3_018_00_01_primitive_type_1_1_i_n_t_01_4.html">VecNT&lt; 8, PrimitiveType::INT &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_weight_row.html">WeightRow</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structfbgemm__gpu_1_1_weight_row_accessor.html">WeightRowAccessor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a17e57fc2dca2d6df09e26f3eec69464c" id="r_a17e57fc2dca2d6df09e26f3eec69464c"><td class="memTemplParams" colspan="2">template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">IndexType</a> &gt; </td></tr>
<tr class="memitem:a17e57fc2dca2d6df09e26f3eec69464c"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="#a17e57fc2dca2d6df09e26f3eec69464c">report_embedding_error</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="#aa80cbea4714c980d14626fd87c9287a4">t</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="#adb51b4975da6fe6cd1f6465b56b3b8ab">B</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">b_begin</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">b_end</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">IndexType</a> *<a class="el" href="#a66f41f5ea495c26af7e2007fe0a28edc">offsets_data</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">IndexType</a> *<a class="el" href="#acb7eb1c50758e407a638a81723961f56">indices_data</a>, <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">hash_size</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">allow_minus_one</a>=<a class="el" href="gen__embedding__forward__split__unweighted__kernel_8cu.html#a0ad31f76c1f9349ef8b21ca138e897cc">false</a>)</td></tr>
<tr class="separator:a17e57fc2dca2d6df09e26f3eec69464c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab708b23762a11187eb6a32a36f0e34a3" id="r_gab708b23762a11187eb6a32a36f0e34a3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__cumem-utils.html#gab708b23762a11187eb6a32a36f0e34a3">new_managed_tensor</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">self</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; std::int64_t &gt; &amp;sizes)</td></tr>
<tr class="separator:gab708b23762a11187eb6a32a36f0e34a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga5351c6ec3de203476cf09df330455d91" id="r_ga5351c6ec3de203476cf09df330455d91"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__cumem-utils.html#ga5351c6ec3de203476cf09df330455d91">new_managed_tensor_meta</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">self</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; std::int64_t &gt; &amp;sizes)</td></tr>
<tr class="separator:ga5351c6ec3de203476cf09df330455d91"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga5663643a8ac5de83063d0ff51bb9af17" id="r_ga5663643a8ac5de83063d0ff51bb9af17"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__cumem-utils.html#ga5663643a8ac5de83063d0ff51bb9af17">new_host_mapped_tensor</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">self</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; std::int64_t &gt; &amp;sizes)</td></tr>
<tr class="separator:ga5663643a8ac5de83063d0ff51bb9af17"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6f8847537ea9ed13fc7e2e378bc79b1f" id="r_ga6f8847537ea9ed13fc7e2e378bc79b1f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__cumem-utils.html#ga6f8847537ea9ed13fc7e2e378bc79b1f">new_unified_tensor</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">self</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; std::int64_t &gt; &amp;sizes, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">is_host_mapped</a>)</td></tr>
<tr class="separator:ga6f8847537ea9ed13fc7e2e378bc79b1f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad5e0d2307667c3db5e73f0c0eec15df5" id="r_gad5e0d2307667c3db5e73f0c0eec15df5"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__cumem-utils.html#gad5e0d2307667c3db5e73f0c0eec15df5">new_vanilla_managed_tensor</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">self</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; std::int64_t &gt; &amp;sizes)</td></tr>
<tr class="separator:gad5e0d2307667c3db5e73f0c0eec15df5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga05bf2c435c434904ca454c6992861cb6" id="r_ga05bf2c435c434904ca454c6992861cb6"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__cumem-utils.html#ga05bf2c435c434904ca454c6992861cb6">uvm_storage</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">self</a>)</td></tr>
<tr class="separator:ga05bf2c435c434904ca454c6992861cb6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gacba28ed334d071e79c1ead1792391e9d" id="r_gacba28ed334d071e79c1ead1792391e9d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__cumem-utils.html#gacba28ed334d071e79c1ead1792391e9d">is_uvm_tensor</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">self</a>)</td></tr>
<tr class="separator:gacba28ed334d071e79c1ead1792391e9d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab5a3dab831988b1ce368ccc545b75b48" id="r_gab5a3dab831988b1ce368ccc545b75b48"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__cumem-utils.html#gab5a3dab831988b1ce368ccc545b75b48">uvm_to_cpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">self</a>)</td></tr>
<tr class="separator:gab5a3dab831988b1ce368ccc545b75b48"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaebfedcf8e6017a6d4f6fb16b52c4c04e" id="r_gaebfedcf8e6017a6d4f6fb16b52c4c04e"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__cumem-utils.html#gaebfedcf8e6017a6d4f6fb16b52c4c04e">uvm_to_device</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">self</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">prototype</a>)</td></tr>
<tr class="separator:gaebfedcf8e6017a6d4f6fb16b52c4c04e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae8c724e90d31245756fc4b0d975f9370" id="r_gae8c724e90d31245756fc4b0d975f9370"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__cumem-utils.html#gae8c724e90d31245756fc4b0d975f9370">uvm_cuda_mem_advise</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">self</a>, <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">cuda_memory_advise</a>)</td></tr>
<tr class="separator:gae8c724e90d31245756fc4b0d975f9370"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf060db44e71e3419df6e596614ef2081" id="r_gaf060db44e71e3419df6e596614ef2081"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__cumem-utils.html#gaf060db44e71e3419df6e596614ef2081">uvm_cuda_mem_prefetch_async</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">self</a>, c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">device_t</a>)</td></tr>
<tr class="separator:gaf060db44e71e3419df6e596614ef2081"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga01301ad686f7570c21e81c122d2c7af8" id="r_ga01301ad686f7570c21e81c122d2c7af8"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__cumem-utils.html#ga01301ad686f7570c21e81c122d2c7af8">uvm_mem_advice_dont_fork</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">self</a>)</td></tr>
<tr class="separator:ga01301ad686f7570c21e81c122d2c7af8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga161495e682d9eac3701dca87469930db" id="r_ga161495e682d9eac3701dca87469930db"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__cumem-utils.html#ga161495e682d9eac3701dca87469930db">uvm_to_cpu_clone</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">self</a>)</td></tr>
<tr class="separator:ga161495e682d9eac3701dca87469930db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a54bf7e9b54b5263cf039100cda517c34" id="r_a54bf7e9b54b5263cf039100cda517c34"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a54bf7e9b54b5263cf039100cda517c34">embedding_inplace_update_cuda</a> (<a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel__small_8cu.html#a6d8072fe7f1cbd1cf456e3ea8a440ad3">dev_weights</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> <a class="el" href="gen__embedding__forward__split__unweighted__codegen__cuda_8cu.html#a17f61eb7bf7a7e4089982fbf69116da5">uvm_weights</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> <a class="el" href="gen__embedding__forward__split__unweighted__codegen__cuda_8cu.html#ad4dd9cc51f1eccdf4626318632701868">weights_placements</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel__small_8cu.html#a764f8ae801cd000c2a5cb4bb23f14299">weights_offsets</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">weights_tys</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel__small_8cu.html#a8a3ac708f5fc38ea5ebecdbe685f3c73">D_offsets</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">update_weights</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">update_table_idx</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">update_row_idx</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">update_offsets</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">row_alignment</a>, c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; <a class="el" href="gen__embedding__forward__split__unweighted__codegen__cuda_8cu.html#a0c2527424502280dfcf6276b49b41cdc">lxu_cache_weights</a>=c10::nullopt, c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; <a class="el" href="gen__embedding__forward__split__unweighted__codegen__cuda_8cu.html#a60a1ec59d36df78e844d5cd7a0d34f03">lxu_cache_locations</a>=c10::nullopt)</td></tr>
<tr class="separator:a54bf7e9b54b5263cf039100cda517c34"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adda552b8784184a2f17aa997e10869f9" id="r_adda552b8784184a2f17aa997e10869f9"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#adda552b8784184a2f17aa997e10869f9">pruned_array_lookup_from_row_idx_cuda</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">update_row_indices</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">update_table_indices</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_remappings</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_remappings_offsets</a>)</td></tr>
<tr class="separator:adda552b8784184a2f17aa997e10869f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae86238f4ca864fb4ea41318ece747ab4" id="r_ae86238f4ca864fb4ea41318ece747ab4"><td class="memTemplParams" colspan="2">template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> ITEMS_PER_THREAD, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> NUM_THREADS_PER_BLOCK&gt; </td></tr>
<tr class="memitem:ae86238f4ca864fb4ea41318ece747ab4"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__inline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="#ae86238f4ca864fb4ea41318ece747ab4">inclusive_sum_scan_kernel</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>(&amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">arr</a>)[<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">ITEMS_PER_THREAD</a>], <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> cub::BlockScan&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, <a class="el" href="metric__ops_8cu.html#ac147221d5b74086a08d3623657d16517">NUM_THREADS_PER_BLOCK</a> &gt;::TempStorage &amp;<a class="el" href="#ad0fce99009259dbc5e5c0527eb5b3f64">temp_storage</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">block_flags</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">volatile</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">block_sums</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">block_prev</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">num_entries_per_block</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">block_id</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">is_multi_block</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">signal</a>)</td></tr>
<tr class="separator:ae86238f4ca864fb4ea41318ece747ab4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2402de1c0102b21af5f2bd5a50d30309" id="r_ga2402de1c0102b21af5f2bd5a50d30309"><td class="memItemLeft" align="right" valign="top">at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__sparse-data-cuda.html#ga2402de1c0102b21af5f2bd5a50d30309">expand_into_jagged_permute_cuda</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="#a313d400789ec7e8bf0702c1d06339394">permute</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="#a88aea1b3f2194509bb8bb7105e0d6553">input_offsets</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="#a72822c0cc98165904fdc0110344ecdd5">output_offsets</a>, <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">output_size</a>)</td></tr>
<tr class="separator:ga2402de1c0102b21af5f2bd5a50d30309"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga201bb2241fc9d582d6c0fe968b0e71ca" id="r_ga201bb2241fc9d582d6c0fe968b0e71ca"><td class="memItemLeft" align="right" valign="top">std::tuple&lt; at::Tensor, at::Tensor &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__sparse-data-cpu.html#ga201bb2241fc9d582d6c0fe968b0e71ca">histogram_binning_calibration_cpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">logit</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bin_num_examples</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bin_num_positives</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">positive_weight</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">lower_bound</a>=0.0, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">upper_bound</a>=1.0, <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="#a5306cfe92409d5d6525baade1714a78a">bin_ctr_in_use_after</a>=0, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="#a505eb55e26cb1a63decb22880c93b9fd">bin_ctr_weight_value</a>=1.0)</td></tr>
<tr class="separator:ga201bb2241fc9d582d6c0fe968b0e71ca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaef2a0a8c27e3b8b2d72be5c95ba7539e" id="r_gaef2a0a8c27e3b8b2d72be5c95ba7539e"><td class="memItemLeft" align="right" valign="top">std::tuple&lt; at::Tensor, at::Tensor &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__sparse-data-cpu.html#gaef2a0a8c27e3b8b2d72be5c95ba7539e">generic_histogram_binning_calibration_by_feature_cpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">logit</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">segment_value</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">segment_lengths</a>, <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="#a13adcdfa105d3fe5d68bfeae4df5f017">num_segments</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bin_num_examples</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bin_num_positives</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="#a7d3b870a22caa3968ca55fb89420e970">bin_boundaries</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">positive_weight</a>, <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="#a5306cfe92409d5d6525baade1714a78a">bin_ctr_in_use_after</a>=0, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="#a505eb55e26cb1a63decb22880c93b9fd">bin_ctr_weight_value</a>=1.0)</td></tr>
<tr class="separator:gaef2a0a8c27e3b8b2d72be5c95ba7539e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af01b4023830652f0cc3e99c87f7b4526" id="r_af01b4023830652f0cc3e99c87f7b4526"><td class="memItemLeft" align="right" valign="top">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af01b4023830652f0cc3e99c87f7b4526">padding_fused_tbe_input_combine_with_length_cpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">indices_list</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">lengths_list</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">per_sample_weights</a>, <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="#add6df347839b36aa580f997fddaebf86">batch_size</a>)</td></tr>
<tr class="separator:af01b4023830652f0cc3e99c87f7b4526"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad21c70bdd84772ee2b9b3950c87e9791" id="r_ad21c70bdd84772ee2b9b3950c87e9791"><td class="memTemplParams" colspan="2">template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> NUM_JAGGED_DIM, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">F</a> &gt; </td></tr>
<tr class="memitem:ad21c70bdd84772ee2b9b3950c87e9791"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="#ad21c70bdd84772ee2b9b3950c87e9791">__launch_bounds__</a> (kMaxThreads) <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">jagged_jagged_elementwise_dense_output_kernel_</a>(<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">pta</a></td></tr>
<tr class="separator:ad21c70bdd84772ee2b9b3950c87e9791"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a53a6da74de342260dcb15c68e9bddfd6" id="r_a53a6da74de342260dcb15c68e9bddfd6"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a53a6da74de342260dcb15c68e9bddfd6">jagged_index_add_2d_forward_cuda</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">values</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#aabefe307b5a16f2e2d2c5cc6c74719b6">indices</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#a88aea1b3f2194509bb8bb7105e0d6553">input_offsets</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#a72822c0cc98165904fdc0110344ecdd5">output_offsets</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">num_dense_input_rows</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">num_output_rows</a>)</td></tr>
<tr class="separator:a53a6da74de342260dcb15c68e9bddfd6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb5a744fbd29c8a3a25621c2850686c1" id="r_acb5a744fbd29c8a3a25621c2850686c1"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#acb5a744fbd29c8a3a25621c2850686c1">jagged_index_select_2d_forward_cuda</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">values</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#aabefe307b5a16f2e2d2c5cc6c74719b6">indices</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#a88aea1b3f2194509bb8bb7105e0d6553">input_offsets</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#a72822c0cc98165904fdc0110344ecdd5">output_offsets</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">num_dense_output_rows</a>)</td></tr>
<tr class="separator:acb5a744fbd29c8a3a25621c2850686c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaa797caaa08c70857433ae987d9cf30d7" id="r_gaa797caaa08c70857433ae987d9cf30d7"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__jagged-tensor-ops-cpu.html#gaa797caaa08c70857433ae987d9cf30d7">jagged_dense_elementwise_add</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">x_values</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">x_offsets</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">y</a>)</td></tr>
<tr class="separator:gaa797caaa08c70857433ae987d9cf30d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga1290f40c3ba39837dd009c3006353d7c" id="r_ga1290f40c3ba39837dd009c3006353d7c"><td class="memItemLeft" align="right" valign="top">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__jagged-tensor-ops-cpu.html#ga1290f40c3ba39837dd009c3006353d7c">jagged_dense_elementwise_add_jagged_output</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">x_values</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">x_offsets</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">y</a>)</td></tr>
<tr class="separator:ga1290f40c3ba39837dd009c3006353d7c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca95193cb0cc3db7030f18cb59c6cc33" id="r_aca95193cb0cc3db7030f18cb59c6cc33"><td class="memItemLeft" align="right" valign="top">std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aca95193cb0cc3db7030f18cb59c6cc33">jagged_index_select_2d</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">values</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#acbebb5d71fe9389f7b919325112c1548">lengths</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#aabefe307b5a16f2e2d2c5cc6c74719b6">indices</a>)</td></tr>
<tr class="separator:aca95193cb0cc3db7030f18cb59c6cc33"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a71a54a14d90862afc8e5fe03e0c9ed8f" id="r_a71a54a14d90862afc8e5fe03e0c9ed8f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a71a54a14d90862afc8e5fe03e0c9ed8f">jagged_index_select_2d_forward_cpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">values</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#aabefe307b5a16f2e2d2c5cc6c74719b6">indices</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#a88aea1b3f2194509bb8bb7105e0d6553">input_offsets</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#a72822c0cc98165904fdc0110344ecdd5">output_offsets</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">num_dense_output_rows</a>)</td></tr>
<tr class="separator:a71a54a14d90862afc8e5fe03e0c9ed8f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af80524a7d454f6db1c478808e8a659a6" id="r_af80524a7d454f6db1c478808e8a659a6"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af80524a7d454f6db1c478808e8a659a6">jagged_index_add_2d_forward_cpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">values</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#aabefe307b5a16f2e2d2c5cc6c74719b6">indices</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#a88aea1b3f2194509bb8bb7105e0d6553">input_offsets</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#a72822c0cc98165904fdc0110344ecdd5">output_offsets</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">num_dense_input_rows</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">num_output_rows</a>)</td></tr>
<tr class="separator:af80524a7d454f6db1c478808e8a659a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4e6521d00a6f81ad8ad7f7d38eef1aea" id="r_a4e6521d00a6f81ad8ad7f7d38eef1aea"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a4e6521d00a6f81ad8ad7f7d38eef1aea">jagged_slice_forward_cpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">x_values</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">x_lengths</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">src_start</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">output_lengths</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">tgt_start</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">num_output_rows</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">slice_length</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">fill_zeros</a>)</td></tr>
<tr class="separator:a4e6521d00a6f81ad8ad7f7d38eef1aea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad34ac20d2c9be5a6489c8e8befff7938" id="r_gad34ac20d2c9be5a6489c8e8befff7938"><td class="memItemLeft" align="right" valign="top">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__jagged-tensor-ops-cuda.html#gad34ac20d2c9be5a6489c8e8befff7938">jagged_dense_elementwise_add_jagged_output_cuda</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">x_values</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">x_offsets</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">y</a>)</td></tr>
<tr class="separator:gad34ac20d2c9be5a6489c8e8befff7938"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2f1cc4b6dc6f708324855f94d558cfc1" id="r_ga2f1cc4b6dc6f708324855f94d558cfc1"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__quantize-ops-cuda.html#ga2f1cc4b6dc6f708324855f94d558cfc1">_float_to_bfloat16_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>)</td></tr>
<tr class="separator:ga2f1cc4b6dc6f708324855f94d558cfc1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2076a59fd190690f67c1eddb79b6acc4" id="r_ga2076a59fd190690f67c1eddb79b6acc4"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__quantize-ops-cuda.html#ga2076a59fd190690f67c1eddb79b6acc4">_bfloat16_to_float_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>)</td></tr>
<tr class="separator:ga2076a59fd190690f67c1eddb79b6acc4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab2837424e3774fe34ba255658554a75a" id="r_gab2837424e3774fe34ba255658554a75a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__quantize-ops-cuda.html#gab2837424e3774fe34ba255658554a75a">_float_to_hfp8_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">ebits</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">exponent_bias</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">max_pos</a>)</td></tr>
<tr class="separator:gab2837424e3774fe34ba255658554a75a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga03a8f8825a16c6235b699886fa46e1f6" id="r_ga03a8f8825a16c6235b699886fa46e1f6"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__quantize-ops-cuda.html#ga03a8f8825a16c6235b699886fa46e1f6">_hfp8_to_float_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">ebits</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">exponent_bias</a>)</td></tr>
<tr class="separator:ga03a8f8825a16c6235b699886fa46e1f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga427f81e1d8901e2fafc9611860fbd4d5" id="r_ga427f81e1d8901e2fafc9611860fbd4d5"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__quantize-ops-cuda.html#ga427f81e1d8901e2fafc9611860fbd4d5">_float_to_msfp_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bounding_box_size</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">ebits</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">mbits</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bias</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">min_pos</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">max_pos</a>)</td></tr>
<tr class="separator:ga427f81e1d8901e2fafc9611860fbd4d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gac0c20377454dbfafcc5ac245fe6427ce" id="r_gac0c20377454dbfafcc5ac245fe6427ce"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__quantize-ops-cuda.html#gac0c20377454dbfafcc5ac245fe6427ce">_msfp_to_float_gpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">ebits</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">mbits</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bias</a>)</td></tr>
<tr class="separator:gac0c20377454dbfafcc5ac245fe6427ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96db75aa5b2617976c2937ab051b737e" id="r_a96db75aa5b2617976c2937ab051b737e"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a96db75aa5b2617976c2937ab051b737e">batched_unary_embeddings_forward_cpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#ab1426ad1956909abff1b26d04575767a">weight</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#a114a2ddecfbdbb209bc791977fcb1c0e">table_offsets</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#aad33dfd216d9ea27b505a304ca3e32da">offsets</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#aabefe307b5a16f2e2d2c5cc6c74719b6">indices</a>)</td></tr>
<tr class="separator:a96db75aa5b2617976c2937ab051b737e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a49cb5dd543cc63e932f458e1c79c0d00" id="r_a49cb5dd543cc63e932f458e1c79c0d00"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a49cb5dd543cc63e932f458e1c79c0d00">pack_segments_forward_cpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">t_in</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#acbebb5d71fe9389f7b919325112c1548">lengths</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">max_length</a>)</td></tr>
<tr class="separator:a49cb5dd543cc63e932f458e1c79c0d00"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a51f0921a8e934c6c4d0fca5ebb5d8338" id="r_a51f0921a8e934c6c4d0fca5ebb5d8338"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a51f0921a8e934c6c4d0fca5ebb5d8338">pack_segments_backward_cpu</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="jagged__tensor__ops_2common_8cuh.html#a4f36f56fa6a995a4ad013e16ba311b31">data</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#acbebb5d71fe9389f7b919325112c1548">lengths</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">total_length</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">max_length</a>)</td></tr>
<tr class="separator:a51f0921a8e934c6c4d0fca5ebb5d8338"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaded8e25bef3a32580d71dc2ead25f0c" id="r_aaded8e25bef3a32580d71dc2ead25f0c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aaded8e25bef3a32580d71dc2ead25f0c">pack_segments_backward_cuda</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="jagged__tensor__ops_2common_8cuh.html#a4f36f56fa6a995a4ad013e16ba311b31">data</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#acbebb5d71fe9389f7b919325112c1548">lengths</a>, <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">total_length</a>, <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">max_length</a>)</td></tr>
<tr class="separator:aaded8e25bef3a32580d71dc2ead25f0c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4bec138cb5be2583288d026eb4185646" id="r_a4bec138cb5be2583288d026eb4185646"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a4bec138cb5be2583288d026eb4185646">pack_segments_forward_cuda</a> (<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">t_in</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;<a class="el" href="#acbebb5d71fe9389f7b919325112c1548">lengths</a>, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">max_length</a>)</td></tr>
<tr class="separator:a4bec138cb5be2583288d026eb4185646"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Typedef Documentation</h2>
<a id="aef71de4120929d2410f5d766948f8eaf" name="aef71de4120929d2410f5d766948f8eaf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aef71de4120929d2410f5d766948f8eaf">&#9670;&#160;</a></span>enum_item</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">using</a> <a class="el" href="#aef71de4120929d2410f5d766948f8eaf">enum_item</a> = std::tuple&lt;std::string, <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a>&gt;</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5fdc84ce2202ea07eb2e865847bd8f34" name="a5fdc84ce2202ea07eb2e865847bd8f34"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5fdc84ce2202ea07eb2e865847bd8f34">&#9670;&#160;</a></span>enum_items</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">using</a> <a class="el" href="#a5fdc84ce2202ea07eb2e865847bd8f34">enum_items</a> = std::vector&lt;<a class="el" href="#aef71de4120929d2410f5d766948f8eaf">enum_item</a>&gt;</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="adbdc3251cbd2e995dfa31ffdf2c2df8e" name="adbdc3251cbd2e995dfa31ffdf2c2df8e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adbdc3251cbd2e995dfa31ffdf2c2df8e">&#9670;&#160;</a></span>enum_result</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">using</a> <a class="el" href="#adbdc3251cbd2e995dfa31ffdf2c2df8e">enum_result</a></td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"> std::vector&lt;</div>
<div class="line">    std::tuple&lt;std::string, std::vector&lt;std::tuple&lt;std::string, int64_t&gt;&gt;&gt;&gt;</div>
</div><!-- fragment -->
</div>
</div>
<a id="a4783bbd9753251a335f9f8fa2dd97c8c" name="a4783bbd9753251a335f9f8fa2dd97c8c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4783bbd9753251a335f9f8fa2dd97c8c">&#9670;&#160;</a></span>fint32</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">using</a> <a class="el" href="#a4783bbd9753251a335f9f8fa2dd97c8c">fint32</a></td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"> <span class="keyword">union </span><a class="code hl_typedef" href="#a4783bbd9753251a335f9f8fa2dd97c8c">fint32</a> {</div>
<div class="line">  <a class="code hl_variable" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> I;</div>
<div class="line">  <span class="keywordtype">float</span> F;</div>
<div class="line">}</div>
<div class="ttc" id="agen__embedding__backward__split__grad_8cu_html_abe53421bcec0b67763c3ed41e3a2a2ad"><div class="ttname"><a href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a></div><div class="ttdeci">template __global__ uint32_t</div><div class="ttdef"><b>Definition</b> gen_embedding_backward_split_grad.cu:137</div></div>
<div class="ttc" id="anamespacefbgemm__gpu_html_a4783bbd9753251a335f9f8fa2dd97c8c"><div class="ttname"><a href="#a4783bbd9753251a335f9f8fa2dd97c8c">fbgemm_gpu::fint32</a></div><div class="ttdeci">union fint32 { uint32_t I; float F;} fint32</div><div class="ttdef"><b>Definition</b> quantize_ops_utils.h:24</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a64ee5a7e6df3a95f1d4bdd9f38707c96" name="a64ee5a7e6df3a95f1d4bdd9f38707c96"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a64ee5a7e6df3a95f1d4bdd9f38707c96">&#9670;&#160;</a></span>PackedTensorAccessor32</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">size_t</a> N, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">template</a>&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">U</a> &gt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">class</a> PtrTraits = DefaultPtrTraits&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">using</a> <a class="el" href="#a64ee5a7e6df3a95f1d4bdd9f38707c96">PackedTensorAccessor32</a></td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"> </div>
<div class="line">    GenericPackedTensorAccessor&lt;T, N, PtrTraits, int32_t&gt;</div>
</div><!-- fragment -->
</div>
</div>
<a id="a69b304f75455a9eb7144259c09770877" name="a69b304f75455a9eb7144259c09770877"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a69b304f75455a9eb7144259c09770877">&#9670;&#160;</a></span>PackedTensorAccessor64</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">size_t</a> N, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">template</a>&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">U</a> &gt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">class</a> PtrTraits = DefaultPtrTraits&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">using</a> <a class="el" href="#a69b304f75455a9eb7144259c09770877">PackedTensorAccessor64</a></td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"> </div>
<div class="line">    GenericPackedTensorAccessor&lt;T, N, PtrTraits, int64_t&gt;</div>
</div><!-- fragment -->
</div>
</div>
<a id="ae2016e9bbb2f470174708fc60cd7592f" name="ae2016e9bbb2f470174708fc60cd7592f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae2016e9bbb2f470174708fc60cd7592f">&#9670;&#160;</a></span>Tensor</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typedef</a> at::Tensor <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> = at::Tensor</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae8406b85b19117866badffef9481f3e2" name="ae8406b85b19117866badffef9481f3e2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae8406b85b19117866badffef9481f3e2">&#9670;&#160;</a></span>uoffset_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">using</a> <a class="el" href="#ae8406b85b19117866badffef9481f3e2">uoffset_t</a> = std::make_unsigned_t&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>&gt;</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Enumeration Type Documentation</h2>
<a id="afcbf1cd70ce8ea074c2e799d1559b396" name="afcbf1cd70ce8ea074c2e799d1559b396"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afcbf1cd70ce8ea074c2e799d1559b396">&#9670;&#160;</a></span>args_pos</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">enum</a> <a class="el" href="#afcbf1cd70ce8ea074c2e799d1559b396">args_pos</a></td>
        </tr>
      </table>
</div><div class="memdoc">
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="afcbf1cd70ce8ea074c2e799d1559b396a8ae3847f58b98ba0ff4b0fcdfb4ae8e6" name="afcbf1cd70ce8ea074c2e799d1559b396a8ae3847f58b98ba0ff4b0fcdfb4ae8e6"></a>P_indices_prts&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="afcbf1cd70ce8ea074c2e799d1559b396a66aa4e0ec73344232b5d56ee78ef17b0" name="afcbf1cd70ce8ea074c2e799d1559b396a66aa4e0ec73344232b5d56ee78ef17b0"></a>P_lengths_addrs&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="afcbf1cd70ce8ea074c2e799d1559b396a5f3a87c5dbebfaefd128c19ebbe6c7de" name="afcbf1cd70ce8ea074c2e799d1559b396a5f3a87c5dbebfaefd128c19ebbe6c7de"></a>P_indices_offsets&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="afcbf1cd70ce8ea074c2e799d1559b396ad300b64361a3f3e756bfa78fd0b23b97" name="afcbf1cd70ce8ea074c2e799d1559b396ad300b64361a3f3e756bfa78fd0b23b97"></a>P_lengths_offsets&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="afcbf1cd70ce8ea074c2e799d1559b396ae38edd0733e3ec3ca85cfa8bd9b8ac93" name="afcbf1cd70ce8ea074c2e799d1559b396ae38edd0733e3ec3ca85cfa8bd9b8ac93"></a>P_per_sample_weight&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="afcbf1cd70ce8ea074c2e799d1559b396ac640586328f5125ff8881c6b93fac125" name="afcbf1cd70ce8ea074c2e799d1559b396ac640586328f5125ff8881c6b93fac125"></a>P_indices_is_long&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="afcbf1cd70ce8ea074c2e799d1559b396a1c841401de519f97ca671d064c22250e" name="afcbf1cd70ce8ea074c2e799d1559b396a1c841401de519f97ca671d064c22250e"></a>P_lengths_is_long&#160;</td><td class="fielddoc"></td></tr>
</table>

</div>
</div>
<a id="a70433200cf584e2429434a33d45111ea" name="a70433200cf584e2429434a33d45111ea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a70433200cf584e2429434a33d45111ea">&#9670;&#160;</a></span>BoundsCheckMode</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">enum</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">class</a> <a class="el" href="#a70433200cf584e2429434a33d45111ea">BoundsCheckMode</a> : <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">strong</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="a70433200cf584e2429434a33d45111eaa19da7170bea36556dde582519795f3fc" name="a70433200cf584e2429434a33d45111eaa19da7170bea36556dde582519795f3fc"></a>FATAL&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a70433200cf584e2429434a33d45111eaa059e9861e0400dfbe05c98a841f3f96b" name="a70433200cf584e2429434a33d45111eaa059e9861e0400dfbe05c98a841f3f96b"></a>WARNING&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a70433200cf584e2429434a33d45111eaaa2e843feab94ef623fea888f07c28696" name="a70433200cf584e2429434a33d45111eaaa2e843feab94ef623fea888f07c28696"></a>IGNORE&#160;</td><td class="fielddoc"></td></tr>
</table>

</div>
</div>
<a id="a020b3d9d49f1ff2257534a002d8ebf62" name="a020b3d9d49f1ff2257534a002d8ebf62"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a020b3d9d49f1ff2257534a002d8ebf62">&#9670;&#160;</a></span>cache_conflict_miss_rate</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">enum</a> <a class="el" href="#a020b3d9d49f1ff2257534a002d8ebf62">cache_conflict_miss_rate</a></td>
        </tr>
      </table>
</div><div class="memdoc">
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="a020b3d9d49f1ff2257534a002d8ebf62ab164032fff82a847826b4887d9e7be58" name="a020b3d9d49f1ff2257534a002d8ebf62ab164032fff82a847826b4887d9e7be58"></a>mixed&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a020b3d9d49f1ff2257534a002d8ebf62a8701c301e7c87ec4d4f3aee33c6128d7" name="a020b3d9d49f1ff2257534a002d8ebf62a8701c301e7c87ec4d4f3aee33c6128d7"></a>all&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a020b3d9d49f1ff2257534a002d8ebf62a7b3ef6ceb30a5b0c69691a9574a1b6db" name="a020b3d9d49f1ff2257534a002d8ebf62a7b3ef6ceb30a5b0c69691a9574a1b6db"></a>zero&#160;</td><td class="fielddoc"></td></tr>
</table>

</div>
</div>
<a id="a8f04cbe33fa88d1e420c06b1f8879194" name="a8f04cbe33fa88d1e420c06b1f8879194"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8f04cbe33fa88d1e420c06b1f8879194">&#9670;&#160;</a></span>PlacementType</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">enum</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">class</a> <a class="el" href="#a8f04cbe33fa88d1e420c06b1f8879194">PlacementType</a> : <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">strong</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="a8f04cbe33fa88d1e420c06b1f8879194ae10b6ab6a278644ce40631f62f360b6d" name="a8f04cbe33fa88d1e420c06b1f8879194ae10b6ab6a278644ce40631f62f360b6d"></a>DEVICE&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a8f04cbe33fa88d1e420c06b1f8879194af59a25f2594f469f0bfccad7f8f13744" name="a8f04cbe33fa88d1e420c06b1f8879194af59a25f2594f469f0bfccad7f8f13744"></a>MANAGED&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a8f04cbe33fa88d1e420c06b1f8879194a3664f93edf39a3e7e0a84f3cefb624a6" name="a8f04cbe33fa88d1e420c06b1f8879194a3664f93edf39a3e7e0a84f3cefb624a6"></a>MANAGED_CACHING&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a8f04cbe33fa88d1e420c06b1f8879194ab9361011891280a44d85b967739cc6a5" name="a8f04cbe33fa88d1e420c06b1f8879194ab9361011891280a44d85b967739cc6a5"></a>HOST&#160;</td><td class="fielddoc"></td></tr>
</table>

</div>
</div>
<a id="aa1f721fe0d5e5a710e7a05f788f01f5d" name="aa1f721fe0d5e5a710e7a05f788f01f5d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa1f721fe0d5e5a710e7a05f788f01f5d">&#9670;&#160;</a></span>PoolingMode</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">enum</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">class</a> <a class="el" href="#aa1f721fe0d5e5a710e7a05f788f01f5d">PoolingMode</a> : <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">strong</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="aa1f721fe0d5e5a710e7a05f788f01f5da6970bdc2201030b9c03fbdcf3973858a" name="aa1f721fe0d5e5a710e7a05f788f01f5da6970bdc2201030b9c03fbdcf3973858a"></a>SUM&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="aa1f721fe0d5e5a710e7a05f788f01f5da4ea6d1161ea24d7599365f574aff6610" name="aa1f721fe0d5e5a710e7a05f788f01f5da4ea6d1161ea24d7599365f574aff6610"></a>MEAN&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="aa1f721fe0d5e5a710e7a05f788f01f5dab50339a10e1de285ac99d4c3990b8693" name="aa1f721fe0d5e5a710e7a05f788f01f5dab50339a10e1de285ac99d4c3990b8693"></a>NONE&#160;</td><td class="fielddoc"></td></tr>
</table>

</div>
</div>
<a id="aa7e45742197542f659233c21b883ba60" name="aa7e45742197542f659233c21b883ba60"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa7e45742197542f659233c21b883ba60">&#9670;&#160;</a></span>PrimitiveType</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">enum</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">class</a> <a class="el" href="#aa7e45742197542f659233c21b883ba60">PrimitiveType</a> : <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">strong</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="aa7e45742197542f659233c21b883ba60a4ebada6a2af2bcba53ded1d7b414f081" name="aa7e45742197542f659233c21b883ba60a4ebada6a2af2bcba53ded1d7b414f081"></a>FP&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="aa7e45742197542f659233c21b883ba60a53f93baa3057821107c750323892fa92" name="aa7e45742197542f659233c21b883ba60a53f93baa3057821107c750323892fa92"></a>INT&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="aa7e45742197542f659233c21b883ba60a7b8d2f92148f52cad46e331936922e80" name="aa7e45742197542f659233c21b883ba60a7b8d2f92148f52cad46e331936922e80"></a>BF&#160;</td><td class="fielddoc"></td></tr>
</table>

</div>
</div>
<a id="a47b4476e5f749d63e15d2f8e55be833e" name="a47b4476e5f749d63e15d2f8e55be833e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a47b4476e5f749d63e15d2f8e55be833e">&#9670;&#160;</a></span>SparseType</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">enum</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">class</a> <a class="el" href="#a47b4476e5f749d63e15d2f8e55be833e">SparseType</a> : <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">strong</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="a47b4476e5f749d63e15d2f8e55be833ea693aa0bef84c25fe81c7e62e72f9313d" name="a47b4476e5f749d63e15d2f8e55be833ea693aa0bef84c25fe81c7e62e72f9313d"></a>FP32&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a47b4476e5f749d63e15d2f8e55be833eaa4bf99d6945c25077fd6660d536af8a0" name="a47b4476e5f749d63e15d2f8e55be833eaa4bf99d6945c25077fd6660d536af8a0"></a>FP16&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a47b4476e5f749d63e15d2f8e55be833eaee9d73311ff0658494edfff14c3ec1e3" name="a47b4476e5f749d63e15d2f8e55be833eaee9d73311ff0658494edfff14c3ec1e3"></a>INT8&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a47b4476e5f749d63e15d2f8e55be833ea94635600f8a63640263a5ebc30d79a2a" name="a47b4476e5f749d63e15d2f8e55be833ea94635600f8a63640263a5ebc30d79a2a"></a>INT4&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a47b4476e5f749d63e15d2f8e55be833ea8fbf1fab49398b0d298699ea3ccbebc5" name="a47b4476e5f749d63e15d2f8e55be833ea8fbf1fab49398b0d298699ea3ccbebc5"></a>INT2&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a47b4476e5f749d63e15d2f8e55be833eaf656bbf613964dcf710b771b0918ab30" name="a47b4476e5f749d63e15d2f8e55be833eaf656bbf613964dcf710b771b0918ab30"></a>BF16&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a47b4476e5f749d63e15d2f8e55be833eae32efd813b88548940f8718a61864cf5" name="a47b4476e5f749d63e15d2f8e55be833eae32efd813b88548940f8718a61864cf5"></a>FP8&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a47b4476e5f749d63e15d2f8e55be833eaccc0377a8afbf50e7094f5c23a8af223" name="a47b4476e5f749d63e15d2f8e55be833eaccc0377a8afbf50e7094f5c23a8af223"></a>INVALID&#160;</td><td class="fielddoc"></td></tr>
</table>

</div>
</div>
<a id="aefeeb0d13ba9b557b8d693c43e5a43aa" name="aefeeb0d13ba9b557b8d693c43e5a43aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aefeeb0d13ba9b557b8d693c43e5a43aa">&#9670;&#160;</a></span>uvm_cache_stats_index</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">enum</a> <a class="el" href="#aefeeb0d13ba9b557b8d693c43e5a43aa">uvm_cache_stats_index</a></td>
        </tr>
      </table>
</div><div class="memdoc">
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="aefeeb0d13ba9b557b8d693c43e5a43aaadaf139c74384603431fd1bbb3347aa34" name="aefeeb0d13ba9b557b8d693c43e5a43aaadaf139c74384603431fd1bbb3347aa34"></a>num_calls&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="aefeeb0d13ba9b557b8d693c43e5a43aaacf3fcf7ace9b3a5b4ab424c874b84439" name="aefeeb0d13ba9b557b8d693c43e5a43aaacf3fcf7ace9b3a5b4ab424c874b84439"></a>num_requested_indices&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="aefeeb0d13ba9b557b8d693c43e5a43aaaa555e0f1fe32e24cc25b049fdf3d0afc" name="aefeeb0d13ba9b557b8d693c43e5a43aaaa555e0f1fe32e24cc25b049fdf3d0afc"></a>num_unique_indices&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="aefeeb0d13ba9b557b8d693c43e5a43aaaabea3db589a421890b799e0ac63dfc53" name="aefeeb0d13ba9b557b8d693c43e5a43aaaabea3db589a421890b799e0ac63dfc53"></a>num_unique_misses&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="aefeeb0d13ba9b557b8d693c43e5a43aaa30ee3b3c17bbfefe571f4ea5e99b00d6" name="aefeeb0d13ba9b557b8d693c43e5a43aaa30ee3b3c17bbfefe571f4ea5e99b00d6"></a>num_conflict_unique_misses&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="aefeeb0d13ba9b557b8d693c43e5a43aaac0cd9dffdb3c001656bee52db850d1c6" name="aefeeb0d13ba9b557b8d693c43e5a43aaac0cd9dffdb3c001656bee52db850d1c6"></a>num_conflict_misses&#160;</td><td class="fielddoc"></td></tr>
</table>

</div>
</div>
<h2 class="groupheader">Function Documentation</h2>
<a id="ad5af23eb5e28d14f6089e7a18b0ed0d5" name="ad5af23eb5e28d14f6089e7a18b0ed0d5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad5af23eb5e28d14f6089e7a18b0ed0d5">&#9670;&#160;</a></span>__align__() <span class="overload">[1/4]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">struct</a> __align__ </td>
          <td>(</td>
          <td class="paramtype">16</td>          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9a25aa8cfdd2801c4576fb7111ca1e34" name="a9a25aa8cfdd2801c4576fb7111ca1e34"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9a25aa8cfdd2801c4576fb7111ca1e34">&#9670;&#160;</a></span>__align__() <span class="overload">[2/4]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">struct</a> __align__ </td>
          <td>(</td>
          <td class="paramtype">32</td>          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac5ef7f218ca22e4dd93d4161458006f6" name="ac5ef7f218ca22e4dd93d4161458006f6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac5ef7f218ca22e4dd93d4161458006f6">&#9670;&#160;</a></span>__align__() <span class="overload">[3/4]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">struct</a> __align__ </td>
          <td>(</td>
          <td class="paramtype">64</td>          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5365b81a771afde2d770210e45b73bdb" name="a5365b81a771afde2d770210e45b73bdb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5365b81a771afde2d770210e45b73bdb">&#9670;&#160;</a></span>__align__() <span class="overload">[4/4]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">struct</a> __align__ </td>
          <td>(</td>
          <td class="paramtype">8</td>          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a17d5a2e40c83e6e3f5c68e375bf468f7" name="a17d5a2e40c83e6e3f5c68e375bf468f7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a17d5a2e40c83e6e3f5c68e375bf468f7">&#9670;&#160;</a></span>__launch_bounds__() <span class="overload">[1/7]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__launch_bounds__ </td>
          <td>(</td>
          <td class="paramtype">kMaxThreads</td>          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac59415a66e49753fb42195f0d816c7c2" name="ac59415a66e49753fb42195f0d816c7c2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac59415a66e49753fb42195f0d816c7c2">&#9670;&#160;</a></span>__launch_bounds__() <span class="overload">[2/7]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> sequence, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> has_weight, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> bucketize_pos, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> __launch_bounds__ </td>
          <td>(</td>
          <td class="paramtype">kMaxThreads</td>          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a28846f89e09ae2fc064e73142d83ceef" name="a28846f89e09ae2fc064e73142d83ceef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a28846f89e09ae2fc064e73142d83ceef">&#9670;&#160;</a></span>__launch_bounds__() <span class="overload">[3/7]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> BLOCK_TILE_M, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> BLOCK_TILE_N, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> BLOCK_TILE_K, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> THREAD_TILE_M, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> THREAD_TILE_N, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> __launch_bounds__ </td>
          <td>(</td>
          <td class="paramtype">kMaxThreads</td>          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="afd2e24ffed8f057a2092d699b4cb3cb0" name="afd2e24ffed8f057a2092d699b4cb3cb0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afd2e24ffed8f057a2092d699b4cb3cb0">&#9670;&#160;</a></span>__launch_bounds__() <span class="overload">[4/7]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> __launch_bounds__ </td>
          <td>(</td>
          <td class="paramtype">kMaxThreads</td>          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad21c70bdd84772ee2b9b3950c87e9791" name="ad21c70bdd84772ee2b9b3950c87e9791"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad21c70bdd84772ee2b9b3950c87e9791">&#9670;&#160;</a></span>__launch_bounds__() <span class="overload">[5/7]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> NUM_JAGGED_DIM, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">F</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> __launch_bounds__ </td>
          <td>(</td>
          <td class="paramtype">kMaxThreads</td>          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>output = f(x, y) where x and y are jagged (and share x_offsets), and output is dense.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">padding_value</td><td>padding_value for the output, not for inputs </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ac93e7c311a1d26fbe8815c8b34a6bde4" name="ac93e7c311a1d26fbe8815c8b34a6bde4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac93e7c311a1d26fbe8815c8b34a6bde4">&#9670;&#160;</a></span>__launch_bounds__() <span class="overload">[6/7]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> __launch_bounds__ </td>
          <td>(</td>
          <td class="paramtype">kMaxThreads</td>          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a50af77e9607a7a96addff8aa8e5e4508" name="a50af77e9607a7a96addff8aa8e5e4508"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a50af77e9607a7a96addff8aa8e5e4508">&#9670;&#160;</a></span>__launch_bounds__() <span class="overload">[7/7]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">OffsetType</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">ValueType</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> __launch_bounds__ </td>
          <td>(</td>
          <td class="paramtype">kMaxThreads</td>          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad8c67a657c3008d1d87472f216f7908f" name="ad8c67a657c3008d1d87472f216f7908f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad8c67a657c3008d1d87472f216f7908f">&#9670;&#160;</a></span>_bfloat16_to_float_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _bfloat16_to_float_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="adaf7cd0195ff361555f35a017c018d25" name="adaf7cd0195ff361555f35a017c018d25"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adaf7cd0195ff361555f35a017c018d25">&#9670;&#160;</a></span>_block_bucketize_sparse_features_cpu()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> sequence, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> has_weight, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> _block_bucketize_sparse_features_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>bucketize_pos</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>block_sizes</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>my_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>new_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>new_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;</td>          <td class="paramname"><span class="paramname"><em>new_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;</td>          <td class="paramname"><span class="paramname"><em>new_pos</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>unbucketize_permute</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>batch_size_per_feature</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; std::vector&lt; at::Tensor &gt; &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>block_bucketize_pos</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1f2b214db9aa3f8887c267c0ea9f5edf" name="a1f2b214db9aa3f8887c267c0ea9f5edf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1f2b214db9aa3f8887c267c0ea9f5edf">&#9670;&#160;</a></span>_bucketize_sparse_features_cpu()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> has_weight, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> _bucketize_sparse_features_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; at::Tensor &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>bucketize_pos</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>my_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>new_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>new_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::optional&lt; at::Tensor &gt;</td>          <td class="paramname"><span class="paramname"><em>new_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::optional&lt; at::Tensor &gt;</td>          <td class="paramname"><span class="paramname"><em>new_pos</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="acd8fa4397185c592f5eac101b42504a6" name="acd8fa4397185c592f5eac101b42504a6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acd8fa4397185c592f5eac101b42504a6">&#9670;&#160;</a></span>_cat_int_tensors()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _cat_int_tensors </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>total_num</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>use_pin_memory</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1376d05f5d6efb4fbdb869e391702adf" name="a1376d05f5d6efb4fbdb869e391702adf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1376d05f5d6efb4fbdb869e391702adf">&#9670;&#160;</a></span>_cat_int_tensors_with_padding()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _cat_int_tensors_with_padding </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>total_num</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>use_pin_memory</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>batch_size</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0eec17207e4a69da15dae845d02721e5" name="a0eec17207e4a69da15dae845d02721e5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0eec17207e4a69da15dae845d02721e5">&#9670;&#160;</a></span>_cat_per_sample_weights_list()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _cat_per_sample_weights_list </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>per_sample_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>indices_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>total_num</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>use_pin_memory</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac339123bb72d7421fca2d2b56821f02a" name="ac339123bb72d7421fca2d2b56821f02a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac339123bb72d7421fca2d2b56821f02a">&#9670;&#160;</a></span>_expand_into_jagged_permute_cpu_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> _expand_into_jagged_permute_cpu_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>output_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>permute_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permute</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>output_permute</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a51665269174ef625316e519465a67839" name="a51665269174ef625316e519465a67839"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a51665269174ef625316e519465a67839">&#9670;&#160;</a></span>_float_to_bfloat16_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _float_to_bfloat16_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6c5dca8da7ca5c5f89ecdc816745ba29" name="a6c5dca8da7ca5c5f89ecdc816745ba29"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6c5dca8da7ca5c5f89ecdc816745ba29">&#9670;&#160;</a></span>_float_to_FP8rowwise_gpu_t()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _float_to_FP8rowwise_gpu_t </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>forward</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7f58b5ea1ea6cd38a42f73e5d688bb2c" name="a7f58b5ea1ea6cd38a42f73e5d688bb2c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7f58b5ea1ea6cd38a42f73e5d688bb2c">&#9670;&#160;</a></span>_float_to_fused8bitrowwise_cpu_out_t()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp; _float_to_fused8bitrowwise_cpu_out_t </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a16bbb8557f4229489d966bb1d11bd00c" name="a16bbb8557f4229489d966bb1d11bd00c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a16bbb8557f4229489d966bb1d11bd00c">&#9670;&#160;</a></span>_float_to_fused8bitrowwise_gpu_t()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _float_to_fused8bitrowwise_gpu_t </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a29553ad77238659bb86c14842103d1d5" name="a29553ad77238659bb86c14842103d1d5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a29553ad77238659bb86c14842103d1d5">&#9670;&#160;</a></span>_float_to_fusednbitrowwise_cpu()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">input_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _float_to_fusednbitrowwise_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bit_rate</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a70e9b9692aae9789f0a3804b9d12efe5" name="a70e9b9692aae9789f0a3804b9d12efe5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a70e9b9692aae9789f0a3804b9d12efe5">&#9670;&#160;</a></span>_float_to_hfp8_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _float_to_hfp8_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>ebits</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>exponent_bias</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>max_pos</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1d80140f030f2ca22fd14560e2d8aa42" name="a1d80140f030f2ca22fd14560e2d8aa42"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1d80140f030f2ca22fd14560e2d8aa42">&#9670;&#160;</a></span>_float_to_paddedFP8rowwise_gpu_t()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _float_to_paddedFP8rowwise_gpu_t </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>forward</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>row_dim</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a70d90c85fad4384b23c8958a6c300ce2" name="a70d90c85fad4384b23c8958a6c300ce2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a70d90c85fad4384b23c8958a6c300ce2">&#9670;&#160;</a></span>_FP8rowwise_to_float_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _FP8rowwise_to_float_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>forward</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>output_dtype</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac8931bd574641641dc69eadaae32efe3" name="ac8931bd574641641dc69eadaae32efe3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac8931bd574641641dc69eadaae32efe3">&#9670;&#160;</a></span>_FP8rowwise_to_float_gpu_t()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _FP8rowwise_to_float_gpu_t </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>forward</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>output_dtype</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="acc6b77e9be7ff8c2e5f16297fa6fad38" name="acc6b77e9be7ff8c2e5f16297fa6fad38"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acc6b77e9be7ff8c2e5f16297fa6fad38">&#9670;&#160;</a></span>_fused8bitrowwise_to_float_cpu_out_t()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">output_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp; _fused8bitrowwise_to_float_cpu_out_t </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aab093a380068925d1b267452a1e255c2" name="aab093a380068925d1b267452a1e255c2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aab093a380068925d1b267452a1e255c2">&#9670;&#160;</a></span>_fused8bitrowwise_to_float_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _fused8bitrowwise_to_float_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a25d0793a9d1fe66bccad409791738b7b" name="a25d0793a9d1fe66bccad409791738b7b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a25d0793a9d1fe66bccad409791738b7b">&#9670;&#160;</a></span>_fused8bitrowwise_to_float_gpu_t()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">output_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _fused8bitrowwise_to_float_gpu_t </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3aa2e594cf4bbb5cb5241c4eaa593f8a" name="a3aa2e594cf4bbb5cb5241c4eaa593f8a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3aa2e594cf4bbb5cb5241c4eaa593f8a">&#9670;&#160;</a></span>_fused8bitrowwise_to_half_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _fused8bitrowwise_to_half_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa6141e72712885a0c89d74829be2fe6a" name="aa6141e72712885a0c89d74829be2fe6a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa6141e72712885a0c89d74829be2fe6a">&#9670;&#160;</a></span>_fusednbitrowwise_to_float_cpu()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">output_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _fusednbitrowwise_to_float_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bit_rate</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae0193dd7bbb4e72fc977330cc3f019a4" name="ae0193dd7bbb4e72fc977330cc3f019a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae0193dd7bbb4e72fc977330cc3f019a4">&#9670;&#160;</a></span>_fusednbitrowwise_to_float_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _fusednbitrowwise_to_float_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bit_rate</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="accd75a24d809f4322a18bfb12f47b343" name="accd75a24d809f4322a18bfb12f47b343"></a>
<h2 class="memtitle"><span class="permalink"><a href="#accd75a24d809f4322a18bfb12f47b343">&#9670;&#160;</a></span>_generic_histogram_binning_calibration_by_feature_cpu_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">LogitType</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">SegmentValueType</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> _generic_histogram_binning_calibration_by_feature_cpu_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_logits</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_bins</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_segments</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>recalibrate_value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bin_ctr_in_use_after</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>bin_ctr_weight_value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">LogitType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>logit_data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">SegmentValueType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>dense_segment_value_data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>bin_num_examples_data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>bin_num_positives_data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>bin_boundaries</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">LogitType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>calibrated_prediction_data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>bin_ids_data</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a23bfcbc4afa5dd7d35ee03b7f23840a9" name="a23bfcbc4afa5dd7d35ee03b7f23840a9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a23bfcbc4afa5dd7d35ee03b7f23840a9">&#9670;&#160;</a></span>_half_to_fused8bitrowwise_cpu_out()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp; _half_to_fused8bitrowwise_cpu_out </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="adfeb2fc956b7aa5c2446a00ccbcd058e" name="adfeb2fc956b7aa5c2446a00ccbcd058e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adfeb2fc956b7aa5c2446a00ccbcd058e">&#9670;&#160;</a></span>_half_to_fused8bitrowwise_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _half_to_fused8bitrowwise_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aaa8438f606e84d5cb07827759163bec6" name="aaa8438f606e84d5cb07827759163bec6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaa8438f606e84d5cb07827759163bec6">&#9670;&#160;</a></span>_hfp8_to_float_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _hfp8_to_float_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>ebits</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>exponent_bias</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="adce89aa38a4a22058ec42b5077bbe23a" name="adce89aa38a4a22058ec42b5077bbe23a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adce89aa38a4a22058ec42b5077bbe23a">&#9670;&#160;</a></span>_histogram_binning_calibration_by_feature_cpu_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">LogitType</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">SegmentValueType</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> _histogram_binning_calibration_by_feature_cpu_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_logits</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_bins</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_segments</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>recalibrate_value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>step</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bin_ctr_in_use_after</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>bin_ctr_weight_value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">LogitType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>logit_data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">SegmentValueType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>dense_segment_value_data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>bin_num_examples_data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>bin_num_positives_data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">LogitType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>calibrated_prediction_data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>bin_ids_data</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7639f61a587aa5052c488fbd00d3784b" name="a7639f61a587aa5052c488fbd00d3784b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7639f61a587aa5052c488fbd00d3784b">&#9670;&#160;</a></span>_histogram_binning_calibration_cpu_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> _histogram_binning_calibration_cpu_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_logits</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>recalibrate_value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>step</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bin_ctr_in_use_after</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>bin_ctr_weight_value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>logit_data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>bin_num_examples_data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>bin_num_positives_data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>calibrated_prediction_data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>bin_ids_data</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7a8e9e91365de25b995833c08eb32eff" name="a7a8e9e91365de25b995833c08eb32eff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7a8e9e91365de25b995833c08eb32eff">&#9670;&#160;</a></span>_invert_permute_cpu_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> _invert_permute_cpu_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>permute_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permute</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>inversed_permute</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="afc30bb56977528d8a85e43f9aa5c2cf8" name="afc30bb56977528d8a85e43f9aa5c2cf8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afc30bb56977528d8a85e43f9aa5c2cf8">&#9670;&#160;</a></span>_paddedFP8rowwise_to_float_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> at::Tensor _paddedFP8rowwise_to_float_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>forward</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>row_dim</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>output_last_dim</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>output_dtype</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0c0b93e239757d9564c51f8922f17554" name="a0c0b93e239757d9564c51f8922f17554"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0c0b93e239757d9564c51f8922f17554">&#9670;&#160;</a></span>_paddedFP8rowwise_to_float_gpu_t()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> _paddedFP8rowwise_to_float_gpu_t </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>forward</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>row_dim</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>output_last_dim</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>output_dtype</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af0e07ade6f2b89bf71c344aac8106b59" name="af0e07ade6f2b89bf71c344aac8106b59"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af0e07ade6f2b89bf71c344aac8106b59">&#9670;&#160;</a></span>_permute_1D_indices_weights_kernel_cpu()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> has_weight, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">indices_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">weights_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> _permute_1D_indices_weights_kernel_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">indices_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">weights_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>permuted_lengths_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permute</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permuted_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>output_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">indices_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permuted_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">weights_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permuted_weights</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8dfcdb2c902cf1c4e5d0ed916d5fe779" name="a8dfcdb2c902cf1c4e5d0ed916d5fe779"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8dfcdb2c902cf1c4e5d0ed916d5fe779">&#9670;&#160;</a></span>_permute_1D_lengths_cpu_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> _permute_1D_lengths_cpu_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>permuted_lengths_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permute</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permuted_lengths</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="acad68edeefe7a7710f729cdc56876851" name="acad68edeefe7a7710f729cdc56876851"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acad68edeefe7a7710f729cdc56876851">&#9670;&#160;</a></span>_permute_2D_indices_weights_kernel_cpu()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> has_weight, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">indices_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">weights_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> _permute_2D_indices_weights_kernel_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a></td>          <td class="paramname"><span class="paramname"><em>T</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a></td>          <td class="paramname"><span class="paramname"><em>B</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">indices_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">weights_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permute</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>output_offsets_per_thread_cumsum</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">indices_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permuted_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">weights_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permuted_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permuted_lengths</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a72c447e3b6d38b548d89ebc464e2d469" name="a72c447e3b6d38b548d89ebc464e2d469"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a72c447e3b6d38b548d89ebc464e2d469">&#9670;&#160;</a></span>_permute_2D_lengths_cpu_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> _permute_2D_lengths_cpu_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a></td>          <td class="paramname"><span class="paramname"><em>T</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a></td>          <td class="paramname"><span class="paramname"><em>B</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>lengths_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permute</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permuted_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>output_offsets_per_thread_cumsum</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2fb715b347e075f3331083905cdaadfb" name="a2fb715b347e075f3331083905cdaadfb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2fb715b347e075f3331083905cdaadfb">&#9670;&#160;</a></span>_permute_data_kernel_cpu()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> has_weight, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> _permute_data_kernel_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a></td>          <td class="paramname"><span class="paramname"><em>T</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a></td>          <td class="paramname"><span class="paramname"><em>B</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permute</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>output_offsets_per_thread_cumsum</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permuted_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permuted_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permuted_lengths</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6987e1403a25c256168873616dffbdf6" name="a6987e1403a25c256168873616dffbdf6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6987e1403a25c256168873616dffbdf6">&#9670;&#160;</a></span>_permute_embeddings_kernel_cpu()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> _permute_embeddings_kernel_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a></td>          <td class="paramname"><span class="paramname"><em>T</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a></td>          <td class="paramname"><span class="paramname"><em>B</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>embeddings</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permute</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>output_offsets_per_thread_cumsum</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permuted_embeddings</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permuted_lengths</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4c7749afd2c661b1d302268035fde42b" name="a4c7749afd2c661b1d302268035fde42b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4c7749afd2c661b1d302268035fde42b">&#9670;&#160;</a></span>_permute_lengths_cpu_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> _permute_lengths_cpu_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a></td>          <td class="paramname"><span class="paramname"><em>T</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a></td>          <td class="paramname"><span class="paramname"><em>B</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>lengths_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permute</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permuted_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>output_offsets_per_thread_cumsum</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ade08c8b174b0ecbb99d01ad87b4da0b3" name="ade08c8b174b0ecbb99d01ad87b4da0b3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ade08c8b174b0ecbb99d01ad87b4da0b3">&#9670;&#160;</a></span>_segment_sum_csr_cpu_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> _segment_sum_csr_cpu_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>num_segments</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>batch_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>csr_seg_data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>values_data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>output_data</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3de0ed0985acc3edc0583b6cd56a43f2" name="a3de0ed0985acc3edc0583b6cd56a43f2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3de0ed0985acc3edc0583b6cd56a43f2">&#9670;&#160;</a></span>accumulate_fp16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a> accumulate_fp16 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"><em>acc</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half2</a></td>          <td class="paramname"><span class="paramname"><em>vals</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aeb3ef6437b744f52b29910361f83336c" name="aeb3ef6437b744f52b29910361f83336c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeb3ef6437b744f52b29910361f83336c">&#9670;&#160;</a></span>accumulate_fp32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> accumulate_fp32 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a></td>          <td class="paramname"><span class="paramname"><em>acc</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a></td>          <td class="paramname"><span class="paramname"><em>vals</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="acc596fdaac7efc925d19d7374251e8cb" name="acc596fdaac7efc925d19d7374251e8cb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acc596fdaac7efc925d19d7374251e8cb">&#9670;&#160;</a></span>accumulate_packed_hfp8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float4</a> accumulate_packed_hfp8 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float4</a></td>          <td class="paramname"><span class="paramname"><em>acc</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a></td>          <td class="paramname"><span class="paramname"><em>packedVals</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>exp_bits</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>exp_bias</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a857c58d8bfc412a3901414ef0b0f73c5" name="a857c58d8bfc412a3901414ef0b0f73c5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a857c58d8bfc412a3901414ef0b0f73c5">&#9670;&#160;</a></span>accumulate_packed_int2()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float_16</a> accumulate_packed_int2 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float_16</a></td>          <td class="paramname"><span class="paramname"><em>acc</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a></td>          <td class="paramname"><span class="paramname"><em>packedVals</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half2</a></td>          <td class="paramname"><span class="paramname"><em>shift_scale</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af3478ab6f636e80a75953ffc1d8caed9" name="af3478ab6f636e80a75953ffc1d8caed9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af3478ab6f636e80a75953ffc1d8caed9">&#9670;&#160;</a></span>accumulate_packed_int4()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float8</a> accumulate_packed_int4 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float8</a></td>          <td class="paramname"><span class="paramname"><em>acc</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a></td>          <td class="paramname"><span class="paramname"><em>packedVals</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half2</a></td>          <td class="paramname"><span class="paramname"><em>shift_scale</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a24c22ef27a441cb888d3b32957588794" name="a24c22ef27a441cb888d3b32957588794"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a24c22ef27a441cb888d3b32957588794">&#9670;&#160;</a></span>accumulate_packed_int8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float4</a> accumulate_packed_int8 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float4</a></td>          <td class="paramname"><span class="paramname"><em>acc</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a></td>          <td class="paramname"><span class="paramname"><em>packedVals</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half2</a></td>          <td class="paramname"><span class="paramname"><em>shift_scale</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2700bcf99c82f2491a174d51c462e4e8" name="a2700bcf99c82f2491a174d51c462e4e8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2700bcf99c82f2491a174d51c462e4e8">&#9670;&#160;</a></span>accumulate_weighted_fp16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a> accumulate_weighted_fp16 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"><em>acc</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half2</a></td>          <td class="paramname"><span class="paramname"><em>vals</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a></td>          <td class="paramname"><span class="paramname"><em>weight</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7225f36d3ef25f69273160500bd0b9a7" name="a7225f36d3ef25f69273160500bd0b9a7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7225f36d3ef25f69273160500bd0b9a7">&#9670;&#160;</a></span>accumulate_weighted_fp32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> accumulate_weighted_fp32 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a></td>          <td class="paramname"><span class="paramname"><em>acc</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a></td>          <td class="paramname"><span class="paramname"><em>vals</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a></td>          <td class="paramname"><span class="paramname"><em>weight</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa177a98d987438afcde04f7fc2cba71a" name="aa177a98d987438afcde04f7fc2cba71a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa177a98d987438afcde04f7fc2cba71a">&#9670;&#160;</a></span>accumulate_weighted_packed_hfp8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float4</a> accumulate_weighted_packed_hfp8 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float4</a></td>          <td class="paramname"><span class="paramname"><em>acc</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a></td>          <td class="paramname"><span class="paramname"><em>packedVals</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>exp_bits</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>exp_bias</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a></td>          <td class="paramname"><span class="paramname"><em>weight</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aebe17b37f24d82ea8cfbd296e307d5ab" name="aebe17b37f24d82ea8cfbd296e307d5ab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aebe17b37f24d82ea8cfbd296e307d5ab">&#9670;&#160;</a></span>accumulate_weighted_packed_int2()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float_16</a> accumulate_weighted_packed_int2 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float_16</a></td>          <td class="paramname"><span class="paramname"><em>acc</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a></td>          <td class="paramname"><span class="paramname"><em>packedVals</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half2</a></td>          <td class="paramname"><span class="paramname"><em>shift_scale</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a></td>          <td class="paramname"><span class="paramname"><em>weight</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ade03f1b4099c9ecaf38d7d6a0eb7d595" name="ade03f1b4099c9ecaf38d7d6a0eb7d595"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ade03f1b4099c9ecaf38d7d6a0eb7d595">&#9670;&#160;</a></span>accumulate_weighted_packed_int4()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float8</a> accumulate_weighted_packed_int4 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float8</a></td>          <td class="paramname"><span class="paramname"><em>acc</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a></td>          <td class="paramname"><span class="paramname"><em>packedVals</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half2</a></td>          <td class="paramname"><span class="paramname"><em>shift_scale</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a></td>          <td class="paramname"><span class="paramname"><em>weight</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a80d2d456b1c87f68c9098d5e5d1fd47d" name="a80d2d456b1c87f68c9098d5e5d1fd47d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a80d2d456b1c87f68c9098d5e5d1fd47d">&#9670;&#160;</a></span>accumulate_weighted_packed_int8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float4</a> accumulate_weighted_packed_int8 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float4</a></td>          <td class="paramname"><span class="paramname"><em>acc</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a></td>          <td class="paramname"><span class="paramname"><em>packedVals</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half2</a></td>          <td class="paramname"><span class="paramname"><em>shift_scale</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a></td>          <td class="paramname"><span class="paramname"><em>weight</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6e69d027d43eb7e92ea620d43ae43cb1" name="a6e69d027d43eb7e92ea620d43ae43cb1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6e69d027d43eb7e92ea620d43ae43cb1">&#9670;&#160;</a></span>assign()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> assign </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>assign</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a></td>          <td class="paramname"><span class="paramname"><em>y</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a98effac974dc3fe5bbcc4ce8a75578f7" name="a98effac974dc3fe5bbcc4ce8a75578f7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a98effac974dc3fe5bbcc4ce8a75578f7">&#9670;&#160;</a></span>asynchronous_complete_cumsum_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> asynchronous_complete_cumsum_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>t_in</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1f31ee9922c98ad5d013361368f2f5ac" name="a1f31ee9922c98ad5d013361368f2f5ac"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1f31ee9922c98ad5d013361368f2f5ac">&#9670;&#160;</a></span>asynchronous_complete_cumsum_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> asynchronous_complete_cumsum_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>t_in</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a656bb5222f2a0bc92d5b895ba0fa846c" name="a656bb5222f2a0bc92d5b895ba0fa846c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a656bb5222f2a0bc92d5b895ba0fa846c">&#9670;&#160;</a></span>asynchronous_complete_cumsum_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> asynchronous_complete_cumsum_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>t_in</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a69fe5be794026bdb73b0196be9b345a4" name="a69fe5be794026bdb73b0196be9b345a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a69fe5be794026bdb73b0196be9b345a4">&#9670;&#160;</a></span>asynchronous_exclusive_cumsum_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> asynchronous_exclusive_cumsum_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>t_in</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="afd8b0919b5b3b021a8eb3727e304d5b4" name="afd8b0919b5b3b021a8eb3727e304d5b4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afd8b0919b5b3b021a8eb3727e304d5b4">&#9670;&#160;</a></span>asynchronous_exclusive_cumsum_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> asynchronous_exclusive_cumsum_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>t_in</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae96f1ffdb8ed1efd58561364fbaf3c6a" name="ae96f1ffdb8ed1efd58561364fbaf3c6a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae96f1ffdb8ed1efd58561364fbaf3c6a">&#9670;&#160;</a></span>asynchronous_exclusive_cumsum_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> asynchronous_exclusive_cumsum_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>t_in</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8930419ab36c85750182c12db95baa29" name="a8930419ab36c85750182c12db95baa29"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8930419ab36c85750182c12db95baa29">&#9670;&#160;</a></span>asynchronous_inclusive_cumsum_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> asynchronous_inclusive_cumsum_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>t_in</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="acc0c0e7f6e816900474b2e52756ac891" name="acc0c0e7f6e816900474b2e52756ac891"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acc0c0e7f6e816900474b2e52756ac891">&#9670;&#160;</a></span>asynchronous_inclusive_cumsum_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> asynchronous_inclusive_cumsum_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>t_in</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4bcadae3f465ece7979bf89f0c1cf22a" name="a4bcadae3f465ece7979bf89f0c1cf22a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4bcadae3f465ece7979bf89f0c1cf22a">&#9670;&#160;</a></span>auc_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">label_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">weight_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">acc_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> PADDED_SECTION_SIZE&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> auc_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">acc_t</a> *</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">label_t</a> *</td>          <td class="paramname"><span class="paramname"><em>labels</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">weight_t</a> *</td>          <td class="paramname"><span class="paramname"><em>weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> *</td>          <td class="paramname"><span class="paramname"><em>block_flags</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">acc_t</a> *</td>          <td class="paramname"><span class="paramname"><em>block_sums</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>num_entries</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>last_block_num_entries</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>padded_num_entries_per_block</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>num_blocks</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac9ef3cbe68285c5559d30c5157131e29" name="ac9ef3cbe68285c5559d30c5157131e29"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac9ef3cbe68285c5559d30c5157131e29">&#9670;&#160;</a></span>ballot_sync()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a> ballot_sync </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>predicate</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">unsigned</a></td>          <td class="paramname"><span class="paramname"><em>shfl_sync_mask</em><span class="paramdefsep"> = </span><span class="paramdefval">kFullWarpMask</span></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="abeeb6bd4d39a0e534db2213258704285" name="abeeb6bd4d39a0e534db2213258704285"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abeeb6bd4d39a0e534db2213258704285">&#9670;&#160;</a></span>batch_auc()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor batch_auc </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_tasks</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>labels</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>weights</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae815e5156f29e106f0fcb6054d386afa" name="ae815e5156f29e106f0fcb6054d386afa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae815e5156f29e106f0fcb6054d386afa">&#9670;&#160;</a></span>batched_dense_vec_jagged_2d_mul_backward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; batched_dense_vec_jagged_2d_mul_backward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>grad_output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>v</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>a_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>a_offsets</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af5324c97be6dc5aecbc40e4e3244646f" name="af5324c97be6dc5aecbc40e4e3244646f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af5324c97be6dc5aecbc40e4e3244646f">&#9670;&#160;</a></span>batched_dense_vec_jagged_2d_mul_backward_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; batched_dense_vec_jagged_2d_mul_backward_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>grad_output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>v</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>a_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>a_offsets</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac3080e0008d5cdd9f1f32b33e38aee95" name="ac3080e0008d5cdd9f1f32b33e38aee95"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac3080e0008d5cdd9f1f32b33e38aee95">&#9670;&#160;</a></span>batched_dense_vec_jagged_2d_mul_forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> batched_dense_vec_jagged_2d_mul_forward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>v</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>a_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>a_offsets</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a399af8be70030a7aeaedbdf546efe61a" name="a399af8be70030a7aeaedbdf546efe61a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a399af8be70030a7aeaedbdf546efe61a">&#9670;&#160;</a></span>batched_dense_vec_jagged_2d_mul_forward_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> batched_dense_vec_jagged_2d_mul_forward_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>v</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>a_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>a_offsets</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0e4965515624f44fcd114ff1e5ff0998" name="a0e4965515624f44fcd114ff1e5ff0998"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0e4965515624f44fcd114ff1e5ff0998">&#9670;&#160;</a></span>batched_unary_embeddings_backward_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> batched_unary_embeddings_backward_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>grad_output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>weight</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>table_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a96db75aa5b2617976c2937ab051b737e" name="a96db75aa5b2617976c2937ab051b737e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a96db75aa5b2617976c2937ab051b737e">&#9670;&#160;</a></span>batched_unary_embeddings_forward_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> batched_unary_embeddings_forward_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>weight</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>table_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>CPU version of batched_unary_embeddings forward pass.</p>
<p>Sums up <code>weight</code> embeddings according to <code>offsets</code> and <code>indices</code>. <code>table_offests</code> is a helper struct to quickly navigate through tables in <code>weight</code> &ndash; it is caller's responsibility to keep it in sync with <code>weight</code>. Visualization of op semantics: <a href="https://fburl.com/9a4uktmb">https://fburl.com/9a4uktmb</a></p>
<p>This version is only for numerical verification so not optimized for performance.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">weight</td><td>- Weight for the embeddings. </td></tr>
    <tr><td class="paramname">table_offsets</td><td>- Index offsets for each table entry in <code>weight</code>. </td></tr>
    <tr><td class="paramname">offsets</td><td>- Offsets for the starting point of each summation. </td></tr>
    <tr><td class="paramname">indices</td><td>- Indices for the embeddings to fetch (from <code>weight</code>). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The sumed embeddings. </dd></dl>

</div>
</div>
<a id="a9895cf76445e7258f2464bb037d2c54c" name="a9895cf76445e7258f2464bb037d2c54c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9895cf76445e7258f2464bb037d2c54c">&#9670;&#160;</a></span>batched_unary_embeddings_forward_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> batched_unary_embeddings_forward_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>weight</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>table_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0f1d1afe56f116552e1ca9759e6e0fcc" name="a0f1d1afe56f116552e1ca9759e6e0fcc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0f1d1afe56f116552e1ca9759e6e0fcc">&#9670;&#160;</a></span>BFloat16QuantizedToFloat_ref()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> BFloat16QuantizedToFloat_ref </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::BFloat16 *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">size_t</a></td>          <td class="paramname"><span class="paramname"><em>numel</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>output</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a13b4df4139f3c64ac4d8dbea51a7e7a0" name="a13b4df4139f3c64ac4d8dbea51a7e7a0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a13b4df4139f3c64ac4d8dbea51a7e7a0">&#9670;&#160;</a></span>binary_search_range()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> binary_search_range </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> *</td>          <td class="paramname"><span class="paramname"><em>found</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *</td>          <td class="paramname"><span class="paramname"><em>arr</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a></td>          <td class="paramname"><span class="paramname"><em>target</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>num_entries</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a270e4d8df103fa6c3e6750890608b566" name="a270e4d8df103fa6c3e6750890608b566"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a270e4d8df103fa6c3e6750890608b566">&#9670;&#160;</a></span>block_bucketize_sparse_features_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;, c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;, c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &gt; block_bucketize_sparse_features_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>bucketize_pos</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>sequence</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>block_sizes</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>my_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>batch_size_per_feature</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; std::vector&lt; at::Tensor &gt; &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>block_bucketize_pos</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a293dc249ac4679d97747778a7fb02bd5" name="a293dc249ac4679d97747778a7fb02bd5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a293dc249ac4679d97747778a7fb02bd5">&#9670;&#160;</a></span>block_bucketize_sparse_features_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;, c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;, c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &gt; block_bucketize_sparse_features_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>bucketize_pos</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>sequence</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>block_sizes</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>my_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>batch_size_per_feature</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_B</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; std::vector&lt; at::Tensor &gt; &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>block_bucketize_pos</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a83c70249ce058969210bda8aedf671a4" name="a83c70249ce058969210bda8aedf671a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a83c70249ce058969210bda8aedf671a4">&#9670;&#160;</a></span>bucketize_sparse_features_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; at::Tensor, at::Tensor, c10::optional&lt; at::Tensor &gt;, c10::optional&lt; at::Tensor &gt; &gt; bucketize_sparse_features_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>bucketize_pos</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>my_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; at::Tensor &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>weights</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="abb94f2bd00f8ee054a4a1d2417a093d1" name="abb94f2bd00f8ee054a4a1d2417a093d1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abb94f2bd00f8ee054a4a1d2417a093d1">&#9670;&#160;</a></span>bucketize_sparse_features_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;, c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &gt; bucketize_sparse_features_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>bucketize_pos</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>my_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>weights</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae0656dd690bcffdd8b470d894e25b2d8" name="ae0656dd690bcffdd8b470d894e25b2d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae0656dd690bcffdd8b470d894e25b2d8">&#9670;&#160;</a></span>calc_offsets_range_thread_block()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a>, <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a>, <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> &gt; calc_offsets_range_thread_block </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>output_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_seq</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1ed236113fa360c41a2eb0507c3fc2c7" name="a1ed236113fa360c41a2eb0507c3fc2c7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1ed236113fa360c41a2eb0507c3fc2c7">&#9670;&#160;</a></span>cat_reorder_batched_ad_indices_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> cat_reorder_batched_ad_indices_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>cat_ad_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>ad_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>reordered_cat_ad_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>batch_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_ads_in_batch</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>broadcast_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>total_num_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>pinned_memory</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6b5e65a3f532db97f093037c9dcb3902" name="a6b5e65a3f532db97f093037c9dcb3902"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6b5e65a3f532db97f093037c9dcb3902">&#9670;&#160;</a></span>cat_reorder_batched_ad_indices_cpu_()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> cat_reorder_batched_ad_indices_cpu_ </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>cat_ad_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>ad_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>reordered_cat_ad_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>batch_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_ads_in_batch</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>broadcast_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6b41d7b032eb1abe61eee0bd903d8dfb" name="a6b41d7b032eb1abe61eee0bd903d8dfb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6b41d7b032eb1abe61eee0bd903d8dfb">&#9670;&#160;</a></span>compute_frequency_sequence()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> compute_frequency_sequence </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>start_input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>output_size</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af861e4a8f7b669619744fe59ca2f73a3" name="af861e4a8f7b669619744fe59ca2f73a3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af861e4a8f7b669619744fe59ca2f73a3">&#9670;&#160;</a></span>compute_num_uint64s()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a> compute_num_uint64s </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_elements</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a14c0f0b2b6107f2b17eb472d9be9fb03" name="a14c0f0b2b6107f2b17eb472d9be9fb03"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a14c0f0b2b6107f2b17eb472d9be9fb03">&#9670;&#160;</a></span>CUDA_KERNEL_LOOP() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CUDA_KERNEL_LOOP </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="embedding__forward__split__kernel__template_8cu.html#a1a5ea7b1f265584db8df7ef65698c2dd">b_t</a></td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">lengths_size</a></td>          <td class="paramname"><span class="paramname"></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab331d23c5119efeb513b36fed74c53b0" name="ab331d23c5119efeb513b36fed74c53b0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab331d23c5119efeb513b36fed74c53b0">&#9670;&#160;</a></span>CUDA_KERNEL_LOOP() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CUDA_KERNEL_LOOP </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">r</a></td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">lengths_size</a></td>          <td class="paramname"><span class="paramname"></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa5a76157eb45b9bd4159a548e8a73ce6" name="aa5a76157eb45b9bd4159a548e8a73ce6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa5a76157eb45b9bd4159a548e8a73ce6">&#9670;&#160;</a></span>dense_to_jagged_forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> dense_to_jagged_forward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>dense</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::optional&lt; at::SymInt &gt;</td>          <td class="paramname"><span class="paramname"><em>total_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aee340827dbc6c104a400c30f47f3ee3b" name="aee340827dbc6c104a400c30f47f3ee3b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aee340827dbc6c104a400c30f47f3ee3b">&#9670;&#160;</a></span>dequantize_load() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">dst_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">src_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">Vec4T</a>&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">dst_t</a> &gt; dequantize_load </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">src_t</a> *</td>          <td class="paramname"><span class="paramname"><em>value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a74358134402be54c82696697fe766b9a" name="a74358134402be54c82696697fe766b9a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a74358134402be54c82696697fe766b9a">&#9670;&#160;</a></span>dequantize_load() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">Vec4T</a>&lt; <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> &gt; dequantize_load </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a> *</td>          <td class="paramname"><span class="paramname"><em>value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"><em>qparams</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aaed854f05a4542637ac342bfab57bdc7" name="aaed854f05a4542637ac342bfab57bdc7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaed854f05a4542637ac342bfab57bdc7">&#9670;&#160;</a></span>dequantize_load() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">Vec4T</a>&lt; at::Half &gt; dequantize_load </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a> *</td>          <td class="paramname"><span class="paramname"><em>value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"><em>qparams</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0c388276a962d14b3070dc55202eaf66" name="a0c388276a962d14b3070dc55202eaf66"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0c388276a962d14b3070dc55202eaf66">&#9670;&#160;</a></span>dequantize_packed_hfp8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float4</a> dequantize_packed_hfp8 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a></td>          <td class="paramname"><span class="paramname"><em>vals</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>exp_bits</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>exp_bias</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a96be7f5b4c81d93bf024348e7b85e364" name="a96be7f5b4c81d93bf024348e7b85e364"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a96be7f5b4c81d93bf024348e7b85e364">&#9670;&#160;</a></span>dequantize_permuted_int2()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">half16</a> dequantize_permuted_int2 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a></td>          <td class="paramname"><span class="paramname"><em>packedVals</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half2</a></td>          <td class="paramname"><span class="paramname"><em>shift_scale</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2cf47d59251a0840fd370a95fa371681" name="a2cf47d59251a0840fd370a95fa371681"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2cf47d59251a0840fd370a95fa371681">&#9670;&#160;</a></span>dequantize_permuted_int4()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="jagged__tensor__ops_2common_8cuh.html#a93d30ba34e45e42dfd6b2547b1652cb6">half8</a> dequantize_permuted_int4 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a></td>          <td class="paramname"><span class="paramname"><em>packedVals</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half2</a></td>          <td class="paramname"><span class="paramname"><em>shift_scale</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="adec3504b0909c4380da3c0aac89055de" name="adec3504b0909c4380da3c0aac89055de"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adec3504b0909c4380da3c0aac89055de">&#9670;&#160;</a></span>dequantize_permuted_int8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="jagged__tensor__ops_2common_8cuh.html#ac6142811afa7f90ec76eae1bc05da82b">half4</a> dequantize_permuted_int8 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a></td>          <td class="paramname"><span class="paramname"><em>packedVals</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half2</a></td>          <td class="paramname"><span class="paramname"><em>shift_scale</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac827cf6cd0f063a6747deaff14e4902d" name="ac827cf6cd0f063a6747deaff14e4902d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac827cf6cd0f063a6747deaff14e4902d">&#9670;&#160;</a></span>direct_mapped_lru_cache_populate_byte_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> direct_mapped_lru_cache_populate_byte_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>cache_hash_size_cumsum</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>total_cache_hash_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>cache_index_table_map</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>weights_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>weights_tys</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>D_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>linear_cache_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lxu_cache_state</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lxu_cache_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>time_stamp</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lru_state</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lxu_cache_miss_timestamp</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>row_alignment</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>gather_cache_stats</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;</td>          <td class="paramname"><span class="paramname"><em>uvm_cache_stats</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a03949dd527b81758e43a4b48800c3bc6" name="a03949dd527b81758e43a4b48800c3bc6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a03949dd527b81758e43a4b48800c3bc6">&#9670;&#160;</a></span>direct_mapped_lxu_cache_lookup_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> direct_mapped_lxu_cache_lookup_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>linear_cache_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lxu_cache_state</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>invalid_index</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>gather_cache_stats</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;</td>          <td class="paramname"><span class="paramname"><em>uvm_cache_stats</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1e5f0f7703057bbda166a7723b16e6ef" name="a1e5f0f7703057bbda166a7723b16e6ef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1e5f0f7703057bbda166a7723b16e6ef">&#9670;&#160;</a></span>div_round_up()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__host__</a> <a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> div_round_up </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a></td>          <td class="paramname"><span class="paramname"><em>a</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a></td>          <td class="paramname"><span class="paramname"><em>b</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aef6bada16cf81832eb1e594eb47875d8" name="aef6bada16cf81832eb1e594eb47875d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aef6bada16cf81832eb1e594eb47875d8">&#9670;&#160;</a></span>DivMod()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#a8d2f3cd432a3bf2de49086fb33ef71cb">fd_num_warps_per_list</a> DivMod </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__embedding__forward__split__unweighted__v2__kernel_8cu.html#a53d1bd761ca2346d5b9bcc60d1c43be6">global_warp_id</a></td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">reinterpret_cast</a>&lt; <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> * &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>list_id</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">reinterpret_cast</a>&lt; <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> * &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>warp_id</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a86a8cc18b54f6986ec4faeec0b223907" name="a86a8cc18b54f6986ec4faeec0b223907"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a86a8cc18b54f6986ec4faeec0b223907">&#9670;&#160;</a></span>dummy_packed_accessor32()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> ndim, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">template</a>&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">U</a> &gt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">class</a> PtrTraits = at::DefaultPtrTraits&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">at::PackedTensorAccessor32&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, ndim, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">PtrTraits</a> &gt; dummy_packed_accessor32 </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aeb6f64d8ceb0189b03aa6808b97e8b16" name="aeb6f64d8ceb0189b03aa6808b97e8b16"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeb6f64d8ceb0189b03aa6808b97e8b16">&#9670;&#160;</a></span>dummy_packed_accessor64()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> ndim, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">template</a>&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">U</a> &gt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">class</a> PtrTraits = at::DefaultPtrTraits&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">at::PackedTensorAccessor64&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, ndim, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">PtrTraits</a> &gt; dummy_packed_accessor64 </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae586c9948dba8a67abf44ada58425fba" name="ae586c9948dba8a67abf44ada58425fba"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae586c9948dba8a67abf44ada58425fba">&#9670;&#160;</a></span>embedding_bag_rowwise_prune()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; embedding_bag_rowwise_prune </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indicator</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>threshold</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">at::ScalarType</td>          <td class="paramname"><span class="paramname"><em>compressed_indices_dtype</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>abs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>min_non_pruned_rows</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>min_save_ratio</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aaa1807fa25793e61743b75d27db063cc" name="aaa1807fa25793e61743b75d27db063cc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaa1807fa25793e61743b75d27db063cc">&#9670;&#160;</a></span>embedding_inplace_update_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> embedding_inplace_update_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>dev_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>uvm_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>weights_placements</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>weights_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>weights_tys</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>D_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>update_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>update_table_idx</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>update_row_idx</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>update_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>row_alignment</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;</td>          <td class="paramname"><span class="paramname"><em>lxu_cache_weights</em><span class="paramdefsep"> = </span><span class="paramdefval">c10::nullopt</span>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;</td>          <td class="paramname"><span class="paramname"><em>lxu_cache_locations</em><span class="paramdefsep"> = </span><span class="paramdefval">c10::nullopt</span></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af3e9e1ce0f6340f233ef6ae8934454cf" name="af3e9e1ce0f6340f233ef6ae8934454cf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af3e9e1ce0f6340f233ef6ae8934454cf">&#9670;&#160;</a></span>embedding_inplace_update_cpu_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> embedding_inplace_update_cpu_kernel </td>
          <td>(</td>
          <td class="paramtype">at::TensorAccessor&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a>, 1 &gt;</td>          <td class="paramname"><span class="paramname"><em>dev_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">at::TensorAccessor&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a>, 1 &gt;</td>          <td class="paramname"><span class="paramname"><em>uvm_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>weights_placements</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>weights_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>weights_tys</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>D_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>update_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>update_table_idx</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>update_row_idx</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>update_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>row_alignment</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a54bf7e9b54b5263cf039100cda517c34" name="a54bf7e9b54b5263cf039100cda517c34"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a54bf7e9b54b5263cf039100cda517c34">&#9670;&#160;</a></span>embedding_inplace_update_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> embedding_inplace_update_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>dev_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>uvm_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>weights_placements</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>weights_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>weights_tys</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>D_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>update_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>update_table_idx</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>update_row_idx</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>update_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>row_alignment</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;</td>          <td class="paramname"><span class="paramname"><em>lxu_cache_weights</em><span class="paramdefsep"> = </span><span class="paramdefval">c10::nullopt</span>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;</td>          <td class="paramname"><span class="paramname"><em>lxu_cache_locations</em><span class="paramdefsep"> = </span><span class="paramdefval">c10::nullopt</span></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Embedding tables inplace updates with absolute values (idempotent guarantee)</p>
<p>dev_weights: the loaded tables on device in TBE format uvm_weights: the loaded tables on UVM in TBE format weights_placements: placements for each table weights_offsets: physical offsets for each table weights_tys: weight types for each table D_offsets: table dimensions update_weights: new update weights tensor in TBE format update_table_idx: table indices for every new row update_row_idx: row indices for every new row update_offsets: offsets of new update weights row_alignment: alignment byte for embedding row lxu_cache_weights: the loaded cache weights lxu_cache_locations: the loaded cache location info</p>
<p>it's guaranteed from upper service level that each row of table will only receive one update at a time.</p>
<p>This function has embedding update parameters (update_weights, update_table_idx, updata_offsets) and delta embedding weights on the CUDA devices. </p>

</div>
</div>
<a id="aa8eb0fcd765dc4580084f6d098604e0d" name="aa8eb0fcd765dc4580084f6d098604e0d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa8eb0fcd765dc4580084f6d098604e0d">&#9670;&#160;</a></span>exclusive_scan_ptrs_cpu()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">class</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">class</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">U</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">U</a> exclusive_scan_ptrs_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>N</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">U</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>output</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a02fab30a12d9d6ee6e6ae68bc8041481" name="a02fab30a12d9d6ee6e6ae68bc8041481"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a02fab30a12d9d6ee6e6ae68bc8041481">&#9670;&#160;</a></span>expand_into_jagged_permute_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> expand_into_jagged_permute_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>permute</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>output_size</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0e41e402bfba1e346c6dcc610252e94b" name="a0e41e402bfba1e346c6dcc610252e94b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0e41e402bfba1e346c6dcc610252e94b">&#9670;&#160;</a></span>FBGEMM_GPU_ENUM_REGISTER_START()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">FBGEMM_GPU_ENUM_REGISTER_START </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uvm</a></td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">cudaMemory</a></td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">Advise</a></td>          <td class="paramname"><span class="paramname"></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="acb046dd929c4c4190894087e0952b6ad" name="acb046dd929c4c4190894087e0952b6ad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acb046dd929c4c4190894087e0952b6ad">&#9670;&#160;</a></span>float16_max()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> float16_max </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float_16</a></td>          <td class="paramname"><span class="paramname"><em>val</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aab696723995ed599860851113bfdae05" name="aab696723995ed599860851113bfdae05"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aab696723995ed599860851113bfdae05">&#9670;&#160;</a></span>float16_min()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> float16_min </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float_16</a></td>          <td class="paramname"><span class="paramname"><em>val</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a245cd4874d44db0533c14f1e5da13b0d" name="a245cd4874d44db0533c14f1e5da13b0d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a245cd4874d44db0533c14f1e5da13b0d">&#9670;&#160;</a></span>float1_max()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> float1_max </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a></td>          <td class="paramname"><span class="paramname"><em>val</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3ec9af370f9f9997a31175d653701b82" name="a3ec9af370f9f9997a31175d653701b82"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3ec9af370f9f9997a31175d653701b82">&#9670;&#160;</a></span>float1_min()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> float1_min </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a></td>          <td class="paramname"><span class="paramname"><em>val</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a75186b0bdaba58d01566eec48d2f6602" name="a75186b0bdaba58d01566eec48d2f6602"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a75186b0bdaba58d01566eec48d2f6602">&#9670;&#160;</a></span>float2_max()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> float2_max </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"><em>val</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa0397156c968ae38da1e433bfd50d3a3" name="aa0397156c968ae38da1e433bfd50d3a3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa0397156c968ae38da1e433bfd50d3a3">&#9670;&#160;</a></span>float2_min()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> float2_min </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"><em>val</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7aaeb2b2ad68d85c51fb2b8697c70cc4" name="a7aaeb2b2ad68d85c51fb2b8697c70cc4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7aaeb2b2ad68d85c51fb2b8697c70cc4">&#9670;&#160;</a></span>float4_max()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> float4_max </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float4</a></td>          <td class="paramname"><span class="paramname"><em>val</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="adf07e886eabd113338425ed288c06a7b" name="adf07e886eabd113338425ed288c06a7b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adf07e886eabd113338425ed288c06a7b">&#9670;&#160;</a></span>float4_min()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> float4_min </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float4</a></td>          <td class="paramname"><span class="paramname"><em>val</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa292f064d1126228ac0d10457722616c" name="aa292f064d1126228ac0d10457722616c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa292f064d1126228ac0d10457722616c">&#9670;&#160;</a></span>float8_max()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> float8_max </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float8</a></td>          <td class="paramname"><span class="paramname"><em>val</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="abca50cf5035e82d7992586eac7b744cf" name="abca50cf5035e82d7992586eac7b744cf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abca50cf5035e82d7992586eac7b744cf">&#9670;&#160;</a></span>float8_min()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> float8_min </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float8</a></td>          <td class="paramname"><span class="paramname"><em>val</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae983a889f16302029fcc4e5fcd5ce34f" name="ae983a889f16302029fcc4e5fcd5ce34f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae983a889f16302029fcc4e5fcd5ce34f">&#9670;&#160;</a></span>float_or_half_to_fusednbitrowwise_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> float_or_half_to_fusednbitrowwise_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bit_rate</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9330d767d66b257d1ffa28c67775b38e" name="a9330d767d66b257d1ffa28c67775b38e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9330d767d66b257d1ffa28c67775b38e">&#9670;&#160;</a></span>float_to_fusednbitrowwise_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> float_to_fusednbitrowwise_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bit_rate</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9710845f2dffae8b40b17d49c169976b" name="a9710845f2dffae8b40b17d49c169976b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9710845f2dffae8b40b17d49c169976b">&#9670;&#160;</a></span>float_to_hfp8()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">C10_HOST_DEVICE</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a> float_to_hfp8 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a></td>          <td class="paramname"><span class="paramname"><em>val_fp</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>ebits</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>exponent_bias</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a></td>          <td class="paramname"><span class="paramname"><em>max_pos</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a46f430eb3d28bcd3fed6fbc61dec3bda" name="a46f430eb3d28bcd3fed6fbc61dec3bda"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a46f430eb3d28bcd3fed6fbc61dec3bda">&#9670;&#160;</a></span>FloatToBFloat16Quantized_ref()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> FloatToBFloat16Quantized_ref </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">size_t</a></td>          <td class="paramname"><span class="paramname"><em>numel</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint16_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>output</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5a525ef518134e136f23ab964d45dc23" name="a5a525ef518134e136f23ab964d45dc23"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5a525ef518134e136f23ab964d45dc23">&#9670;&#160;</a></span>FloatToFP8RowwiseQuantized_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> FloatToFP8RowwiseQuantized_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>forward</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af2287d510f303567f2d28d743aa716b6" name="af2287d510f303567f2d28d743aa716b6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af2287d510f303567f2d28d743aa716b6">&#9670;&#160;</a></span>for()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">for </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae7fdacc8f9e0ec9e1ede8102876ab537" name="ae7fdacc8f9e0ec9e1ede8102876ab537"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae7fdacc8f9e0ec9e1ede8102876ab537">&#9670;&#160;</a></span>FP8rowwise_to_float_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> FP8rowwise_to_float_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>forward</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>output_dtype</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a389ed2b83ea0f408fe19fbb46770c610" name="a389ed2b83ea0f408fe19fbb46770c610"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a389ed2b83ea0f408fe19fbb46770c610">&#9670;&#160;</a></span>fused8bitrowwise_to_half_cpu_out()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp; fused8bitrowwise_to_half_cpu_out </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af9209d9d3ea127b5941dcab75bbfd39c" name="af9209d9d3ea127b5941dcab75bbfd39c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af9209d9d3ea127b5941dcab75bbfd39c">&#9670;&#160;</a></span>generic_histogram_binning_calibration_by_feature_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; generic_histogram_binning_calibration_by_feature_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>logit</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>segment_value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>segment_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_segments</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>bin_num_examples</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>bin_num_positives</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>bin_boundaries</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>positive_weight</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bin_ctr_in_use_after</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>bin_ctr_weight_value</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4296f0fdcb9a3dcfdd67549340e8f38c" name="a4296f0fdcb9a3dcfdd67549340e8f38c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4296f0fdcb9a3dcfdd67549340e8f38c">&#9670;&#160;</a></span>get_group_index_select_cols_per_warp()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> get_group_index_select_cols_per_warp </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae554e4e9d8789449846323c52f840fe8" name="ae554e4e9d8789449846323c52f840fe8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae554e4e9d8789449846323c52f840fe8">&#9670;&#160;</a></span>get_nvlink_matrix()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="topology__utils_8h.html#ada7183ec06808ddb73d8f1a65cd8f7ae">AdjacencyMatrix</a>&lt; <a class="el" href="topology__utils_8h.html#a434a916b92f4caf48f14d480c6aa845a">Links</a> &gt; get_nvlink_matrix </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac7d6b4d86c0ce57c3af88ea03123fdb4" name="ac7d6b4d86c0ce57c3af88ea03123fdb4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac7d6b4d86c0ce57c3af88ea03123fdb4">&#9670;&#160;</a></span>getScalarType()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">at::ScalarType getScalarType </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#a47b4476e5f749d63e15d2f8e55be833e">SparseType</a></td>          <td class="paramname"><span class="paramname"><em>dtype</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a7dbc3a3bde83bfe7a18b720197f0f830" name="a7dbc3a3bde83bfe7a18b720197f0f830"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7dbc3a3bde83bfe7a18b720197f0f830">&#9670;&#160;</a></span>getSparseType()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#a47b4476e5f749d63e15d2f8e55be833e">SparseType</a> getSparseType </td>
          <td>(</td>
          <td class="paramtype">at::ScalarType</td>          <td class="paramname"><span class="paramname"><em>dtype</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a33cd874aab109dc15436869064c3d689" name="a33cd874aab109dc15436869064c3d689"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a33cd874aab109dc15436869064c3d689">&#9670;&#160;</a></span>group_index_select_dim0_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">torch::autograd::variable_list group_index_select_dim0_gpu </td>
          <td>(</td>
          <td class="paramtype">at::TensorList</td>          <td class="paramname"><span class="paramname"><em>input_group</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">at::TensorList</td>          <td class="paramname"><span class="paramname"><em>indices_group</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a213539d8845a20efd90e93fed16f1090" name="a213539d8845a20efd90e93fed16f1090"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a213539d8845a20efd90e93fed16f1090">&#9670;&#160;</a></span>group_index_select_dim0_gpu_backward_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">torch::autograd::variable_list group_index_select_dim0_gpu_backward_meta </td>
          <td>(</td>
          <td class="paramtype">at::TensorList</td>          <td class="paramname"><span class="paramname"><em>all_inputs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::SymIntArrayRef</td>          <td class="paramname"><span class="paramname"><em>output_shape_group_ref</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="abda14dada6ae2b39b175ed52824dbfa5" name="abda14dada6ae2b39b175ed52824dbfa5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abda14dada6ae2b39b175ed52824dbfa5">&#9670;&#160;</a></span>group_index_select_dim0_gpu_impl()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">torch::autograd::variable_list group_index_select_dim0_gpu_impl </td>
          <td>(</td>
          <td class="paramtype">at::TensorList</td>          <td class="paramname"><span class="paramname"><em>all_indices_input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>group_size</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8d89670eae5b860788cb14175f01ce7e" name="a8d89670eae5b860788cb14175f01ce7e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8d89670eae5b860788cb14175f01ce7e">&#9670;&#160;</a></span>group_index_select_dim0_gpu_impl_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">torch::autograd::variable_list group_index_select_dim0_gpu_impl_meta </td>
          <td>(</td>
          <td class="paramtype">at::TensorList</td>          <td class="paramname"><span class="paramname"><em>all_indices_input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>group_size</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac4851777dc16c28c94a2cc9b58d3923c" name="ac4851777dc16c28c94a2cc9b58d3923c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac4851777dc16c28c94a2cc9b58d3923c">&#9670;&#160;</a></span>group_index_select_dim0_unpack()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::pair&lt; std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;, std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &gt; group_index_select_dim0_unpack </td>
          <td>(</td>
          <td class="paramtype">at::TensorList</td>          <td class="paramname"><span class="paramname"><em>all_indices_input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>group_size</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a394db33cacde2480607d48fe227274ef" name="a394db33cacde2480607d48fe227274ef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a394db33cacde2480607d48fe227274ef">&#9670;&#160;</a></span>group_index_select_or_add_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> group_index_select_or_add_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> *</td>          <td class="paramname"><span class="paramname"><em>input_ptrs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> *</td>          <td class="paramname"><span class="paramname"><em>output_ptrs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> *</td>          <td class="paramname"><span class="paramname"><em>indices_ptrs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> *</td>          <td class="paramname"><span class="paramname"><em>warp_offsets_group</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> *</td>          <td class="paramname"><span class="paramname"><em>num_cols_group</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::ScalarType &amp;</td>          <td class="paramname"><span class="paramname"><em>input_scalar_type</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::ScalarType &amp;</td>          <td class="paramname"><span class="paramname"><em>indices_scalar_type</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::DeviceIndex &amp;</td>          <td class="paramname"><span class="paramname"><em>device</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>num_work_rows</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>total_num_warps</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>group_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>use_index_select</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>use_var_cols</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a545dc5567b0a08c31f65e2fc7ae21749" name="a545dc5567b0a08c31f65e2fc7ae21749"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a545dc5567b0a08c31f65e2fc7ae21749">&#9670;&#160;</a></span>half_to_fusednbitrowwise_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> half_to_fusednbitrowwise_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bit_rate</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3ff3d0d7b40d8f2909fa6b35d64d250d" name="a3ff3d0d7b40d8f2909fa6b35d64d250d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3ff3d0d7b40d8f2909fa6b35d64d250d">&#9670;&#160;</a></span>hfma2()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half2</a> hfma2 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half2</a></td>          <td class="paramname"><span class="paramname"><em>a</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half2</a></td>          <td class="paramname"><span class="paramname"><em>b</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half2</a></td>          <td class="paramname"><span class="paramname"><em>c</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1f35a2d3a2ede2e58e7986f8c2c757ec" name="a1f35a2d3a2ede2e58e7986f8c2c757ec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1f35a2d3a2ede2e58e7986f8c2c757ec">&#9670;&#160;</a></span>hfp8_to_float()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">C10_HOST_DEVICE</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> hfp8_to_float </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a></td>          <td class="paramname"><span class="paramname"><em>hfp8_val</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>ebits</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>exponent_bias</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a499764d7156d294219e3ae2629ae229f" name="a499764d7156d294219e3ae2629ae229f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a499764d7156d294219e3ae2629ae229f">&#9670;&#160;</a></span>histogram_binning_calibration_by_feature_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; histogram_binning_calibration_by_feature_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>logit</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>segment_value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>segment_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_segments</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>bin_num_examples</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>bin_num_positives</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_bins</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>positive_weight</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>lower_bound</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>upper_bound</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bin_ctr_in_use_after</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>bin_ctr_weight_value</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac639ce2e71982d5d1da0a30c92858aa8" name="ac639ce2e71982d5d1da0a30c92858aa8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac639ce2e71982d5d1da0a30c92858aa8">&#9670;&#160;</a></span>histogram_binning_calibration_by_feature_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; histogram_binning_calibration_by_feature_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>logit</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>segment_value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>segment_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_segments</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>bin_num_examples</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>bin_num_positives</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_bins</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>positive_weight</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>lower_bound</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>upper_bound</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bin_ctr_in_use_after</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>bin_ctr_weight_value</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1b19059704ba1911efbedf4adcbb0ee3" name="a1b19059704ba1911efbedf4adcbb0ee3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1b19059704ba1911efbedf4adcbb0ee3">&#9670;&#160;</a></span>histogram_binning_calibration_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; histogram_binning_calibration_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>logit</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>bin_num_examples</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>bin_num_positives</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>positive_weight</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>lower_bound</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>upper_bound</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>bin_ctr_in_use_after</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>bin_ctr_weight_value</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab50e28187eb7fdf5b8cd74cd8150b025" name="ab50e28187eb7fdf5b8cd74cd8150b025"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab50e28187eb7fdf5b8cd74cd8150b025">&#9670;&#160;</a></span>hmul()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">half</a> hmul </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">half</a></td>          <td class="paramname"><span class="paramname"><em>a</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">half</a></td>          <td class="paramname"><span class="paramname"><em>b</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a257181e3db25da8e4d1b4ef73976271d" name="a257181e3db25da8e4d1b4ef73976271d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a257181e3db25da8e4d1b4ef73976271d">&#9670;&#160;</a></span>hmul_short2()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__forceinline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half2</a> hmul_short2 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a></td>          <td class="paramname"><span class="paramname"><em>lhs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half</a></td>          <td class="paramname"><span class="paramname"><em>rhs</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6080a87e4588877fbbdd8a03d16d927d" name="a6080a87e4588877fbbdd8a03d16d927d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6080a87e4588877fbbdd8a03d16d927d">&#9670;&#160;</a></span>if() <span class="overload">[1/14]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">if </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ab540864a8f4d5cfb95d168df6ff1ac51">b</a> &gt;=</td>          <td class="paramname"><span class="paramname"><em>B</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a32dace4feb1fa305053fd440163ba422" name="a32dace4feb1fa305053fd440163ba422"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a32dace4feb1fa305053fd440163ba422">&#9670;&#160;</a></span>if() <span class="overload">[2/14]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">if </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#afce91df3fd14c65d1d464b891004b1da">curr_bin_num_examples</a></td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#a5306cfe92409d5d6525baade1714a78a">bin_ctr_in_use_after</a></td>          <td class="paramname"><span class="paramname"></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae198c10fa781aa859c0e8666fc10063b" name="ae198c10fa781aa859c0e8666fc10063b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae198c10fa781aa859c0e8666fc10063b">&#9670;&#160;</a></span>if() <span class="overload">[3/14]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">if </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">i</a> &gt;=</td>          <td class="paramname"><span class="paramname"><em>input_size</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4b4f7604af9accc2a43a8e060b6145e7" name="a4b4f7604af9accc2a43a8e060b6145e7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4b4f7604af9accc2a43a8e060b6145e7">&#9670;&#160;</a></span>if() <span class="overload">[4/14]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">if </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index</a> &gt;=<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">num_lengths</a> -</td>          <td class="paramname"><span class="paramname"><em>1</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a29ef435892df0dc6cd3fa9769486e659" name="a29ef435892df0dc6cd3fa9769486e659"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a29ef435892df0dc6cd3fa9769486e659">&#9670;&#160;</a></span>if() <span class="overload">[5/14]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">if </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index</a> &gt;=</td>          <td class="paramname"><span class="paramname"><em>num_logits</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1d72e092775be40f6a57865b410d55e9" name="a1d72e092775be40f6a57865b410d55e9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1d72e092775be40f6a57865b410d55e9">&#9670;&#160;</a></span>if() <span class="overload">[6/14]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">if </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#a07403af74afe12cdace7e1ec4ff38e72">list_id</a> &gt;=</td>          <td class="paramname"><span class="paramname"><em>num_lists</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9e204163946d36c19beef5443a1b71b6" name="a9e204163946d36c19beef5443a1b71b6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9e204163946d36c19beef5443a1b71b6">&#9670;&#160;</a></span>if() <span class="overload">[7/14]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">if </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#a4e34aefb3cc5403a07c020131077100a">n</a> &gt;=</td>          <td class="paramname"><span class="paramname"><em>N</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac2276128422f0c744cc68659b731d53a" name="ac2276128422f0c744cc68659b731d53a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac2276128422f0c744cc68659b731d53a">&#9670;&#160;</a></span>if() <span class="overload">[8/14]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">if </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ac588c52c993fa6f169cb54d418ea584c">next_offset</a></td>          <td class="paramname"><span class="paramname"><span class="paramdefsep"> = </span><span class="paramdefval">=&#160;<a class="el" href="#a5774000010ec731b390787b3b5f72868">curr_offset</a>&#160;+&#160;1</span></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa41e0708c4b465d4a89e0c1de6a60dd1" name="aa41e0708c4b465d4a89e0c1de6a60dd1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa41e0708c4b465d4a89e0c1de6a60dd1">&#9670;&#160;</a></span>if() <span class="overload">[9/14]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">if </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#a34e6956031d1fc5c0f8df5fb432bcfbd">per_sample_weights_addrs</a></td>          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad0904756703f278e8c03d0be1918211b" name="ad0904756703f278e8c03d0be1918211b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad0904756703f278e8c03d0be1918211b">&#9670;&#160;</a></span>if() <span class="overload">[10/14]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">if </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">run_id</a> &gt;=</td>          <td class="paramname"><span class="paramname"><em>sorted_linear_indices_num_runs</em>[0]</span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa6453091b8359fcc2da599396bb27f52" name="aa6453091b8359fcc2da599396bb27f52"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa6453091b8359fcc2da599396bb27f52">&#9670;&#160;</a></span>if() <span class="overload">[11/14]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">if </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">run_id</a> &gt;=sorted_linear_indices_run.</td>          <td class="paramname"><span class="paramname"><em>size</em>0</span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aaf49df4f26b7eff1308265a096c0c768" name="aaf49df4f26b7eff1308265a096c0c768"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaf49df4f26b7eff1308265a096c0c768">&#9670;&#160;</a></span>if() <span class="overload">[12/14]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">if </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#a4478543eef2b1a98a328e4c634b5f6ad">SL</a></td>          <td class="paramname"><span class="paramname"><span class="paramdefsep"> = </span><span class="paramdefval">=&#160;0</span></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a426625b7d5c06c4059e34784c1fdd74f" name="a426625b7d5c06c4059e34784c1fdd74f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a426625b7d5c06c4059e34784c1fdd74f">&#9670;&#160;</a></span>if() <span class="overload">[13/14]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">if </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#aa80cbea4714c980d14626fd87c9287a4">t</a> &gt;=<a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a>||<a class="el" href="#ab540864a8f4d5cfb95d168df6ff1ac51">b</a> &gt;=</td>          <td class="paramname"><span class="paramname"><em>batch_size_per_feature</em>[t]</span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1958ec7365ff8575f7973e15353c0121" name="a1958ec7365ff8575f7973e15353c0121"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1958ec7365ff8575f7973e15353c0121">&#9670;&#160;</a></span>if() <span class="overload">[14/14]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">if </td>
          <td>(</td>
          <td class="paramtype">threadIdx.</td>          <td class="paramname"><span class="paramname"><em>x</em><span class="paramdefsep"> = </span><span class="paramdefval">=&#160;0</span></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae86238f4ca864fb4ea41318ece747ab4" name="ae86238f4ca864fb4ea41318ece747ab4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae86238f4ca864fb4ea41318ece747ab4">&#9670;&#160;</a></span>inclusive_sum_scan_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> ITEMS_PER_THREAD, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> NUM_THREADS_PER_BLOCK&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__inline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> inclusive_sum_scan_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>(&amp;)</td>          <td class="paramname"><span class="paramname"><em>arr</em>[ITEMS_PER_THREAD], </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> cub::BlockScan&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, <a class="el" href="metric__ops_8cu.html#ac147221d5b74086a08d3623657d16517">NUM_THREADS_PER_BLOCK</a> &gt;::TempStorage &amp;</td>          <td class="paramname"><span class="paramname"><em>temp_storage</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> *</td>          <td class="paramname"><span class="paramname"><em>block_flags</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">volatile</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *</td>          <td class="paramname"><span class="paramname"><em>block_sums</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *</td>          <td class="paramname"><span class="paramname"><em>block_prev</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>num_entries_per_block</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>block_id</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>is_multi_block</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>signal</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>inclusive_sum_scan_kernel performs intra- and inter-thread block sum scan (i.e., prefix sum scan). We use cub::BlockScan to do inclusive sum within thread block and use a waterfall sync method to perform prefix sum across thread block.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">arr</td><td>an array of input values. Its length must be fixed to ITEMS_PER_THREAD </td></tr>
    <tr><td class="paramname">temp_storage</td><td>a shared memory struct for cub::BlockScan </td></tr>
    <tr><td class="paramname">block_flags</td><td>a global flag buffer for inter-block sync (must be initialized with zeros) </td></tr>
    <tr><td class="paramname">block_sums</td><td>a global sum buffer for inter-block sync </td></tr>
    <tr><td class="paramname">block_prev</td><td>a shared memory pointer for sharing sum from the previous block within a block </td></tr>
    <tr><td class="paramname">num_entries_per_block</td><td>a number of input entries for this block </td></tr>
    <tr><td class="paramname">block_id</td><td>a relative thread block ID (the first block that contains the first set of input entries has block_id = 0) </td></tr>
    <tr><td class="paramname">is_multi_block</td><td>a boolean to indicate if inter-block sum scan has to be performed </td></tr>
    <tr><td class="paramname">signal</td><td>If the value of block_flags of the previous block is equal to signal, it means that the previous block has written its sum to block_sums. We have thread blocks increment the value of block_flags by one after they write their sums to block_sums. We increment the flag instead of setting the flag to a single value to support multiple sequential inclusive_sum_scan_kernel calls (e.g., in the AUC kernel). signal is the order that inclusive_sum_scan_kernel is called. Since we intialize block_flags with zeros, the signal of the first call should be one. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a80e08c6c5c1ebf2b34c6490eee0e8415" name="a80e08c6c5c1ebf2b34c6490eee0e8415"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a80e08c6c5c1ebf2b34c6490eee0e8415">&#9670;&#160;</a></span>index_add_with_unique_indices_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> index_add_with_unique_indices_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>grad_output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>sorted_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>orig_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>input_shape</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>consecutive_range_start</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>consecutive_range_length</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a543ba161110516ef84a9fbeb83c7af5c" name="a543ba161110516ef84a9fbeb83c7af5c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a543ba161110516ef84a9fbeb83c7af5c">&#9670;&#160;</a></span>index_select_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> index_select_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>orig_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>indices_sorted</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a170ff30798a3bcf42cc3f0669f938450" name="a170ff30798a3bcf42cc3f0669f938450"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a170ff30798a3bcf42cc3f0669f938450">&#9670;&#160;</a></span>index_select_dim0_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> index_select_dim0_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::optional&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt;</td>          <td class="paramname"><span class="paramname"><em>consecutive_range_start</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::optional&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt;</td>          <td class="paramname"><span class="paramname"><em>consecutive_range_length</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::optional&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> &gt;</td>          <td class="paramname"><span class="paramname"><em>skip_indices_sorting_fwd</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa762379def70fcfe1f15ff2a347af4a9" name="aa762379def70fcfe1f15ff2a347af4a9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa762379def70fcfe1f15ff2a347af4a9">&#9670;&#160;</a></span>index_select_scalar_cumsum_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">acc_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> NUM_THREADS_PER_BLOCK, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> MAX_ENTRIES_PER_BLOCK&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> index_select_scalar_cumsum_kernel </td>
          <td>(</td>
          <td class="paramtype">at::PackedTensorAccessor32&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 1, at::RestrictPtrTraits &gt;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">at::PackedTensorAccessor32&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">acc_t</a>, 1, at::RestrictPtrTraits &gt;</td>          <td class="paramname"><span class="paramname"><em>output_cumsum</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::PackedTensorAccessor32&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 1, at::RestrictPtrTraits &gt;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::PackedTensorAccessor32&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>, 1, at::RestrictPtrTraits &gt;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>num_batches</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>input_batch_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>last_block_num_entries</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> *</td>          <td class="paramname"><span class="paramname"><em>block_flags</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">acc_t</a> *</td>          <td class="paramname"><span class="paramname"><em>block_sums</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa79c3b125ba955f02e8ee2e70b1bbd32" name="aa79c3b125ba955f02e8ee2e70b1bbd32"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa79c3b125ba955f02e8ee2e70b1bbd32">&#9670;&#160;</a></span>invert_permute_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> invert_permute_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>permute</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae24b9318a63a9532f426abc0b0e94819" name="ae24b9318a63a9532f426abc0b0e94819"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae24b9318a63a9532f426abc0b0e94819">&#9670;&#160;</a></span>is_aligned()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">class</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> is_aligned </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> *</td>          <td class="paramname"><span class="paramname"><em>ptr</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="afdde1bd5a99cc5bcdfaf27b4c42cad7b" name="afdde1bd5a99cc5bcdfaf27b4c42cad7b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afdde1bd5a99cc5bcdfaf27b4c42cad7b">&#9670;&#160;</a></span>jagged_1d_to_dense_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_1d_to_dense_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::SymInt</td>          <td class="paramname"><span class="paramname"><em>max_L</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>padding_value</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a70d2cdc82d96c9c4298b57133393a800" name="a70d2cdc82d96c9c4298b57133393a800"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a70d2cdc82d96c9c4298b57133393a800">&#9670;&#160;</a></span>jagged_2d_to_dense_forward_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_2d_to_dense_forward_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7c104248a9abcdcdac6bdcac571930a4" name="a7c104248a9abcdcdac6bdcac571930a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7c104248a9abcdcdac6bdcac571930a4">&#9670;&#160;</a></span>jagged_2d_to_dense_gpu_backward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_2d_to_dense_gpu_backward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>grad_output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">at::Tensor</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_lengths</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a56c28427858ea272148bdbfb9f373191" name="a56c28427858ea272148bdbfb9f373191"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a56c28427858ea272148bdbfb9f373191">&#9670;&#160;</a></span>jagged_2d_to_dense_gpu_forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_2d_to_dense_gpu_forward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_sequence_length</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a67b19e389f869540bd35510d4e8e7908" name="a67b19e389f869540bd35510d4e8e7908"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a67b19e389f869540bd35510d4e8e7908">&#9670;&#160;</a></span>jagged_2d_to_dense_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_2d_to_dense_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::SymInt</td>          <td class="paramname"><span class="paramname"><em>max_sequence_length</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aed181c3885f392fec8c38cdf10266d68" name="aed181c3885f392fec8c38cdf10266d68"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aed181c3885f392fec8c38cdf10266d68">&#9670;&#160;</a></span>jagged_dense_bmm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; jagged_dense_bmm </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3eec1622180be9b7a31891d5e9f2ba71" name="a3eec1622180be9b7a31891d5e9f2ba71"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3eec1622180be9b7a31891d5e9f2ba71">&#9670;&#160;</a></span>jagged_dense_bmm_forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_dense_bmm_forward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4961acd2615018dff4fdf1390158f0a4" name="a4961acd2615018dff4fdf1390158f0a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4961acd2615018dff4fdf1390158f0a4">&#9670;&#160;</a></span>jagged_dense_bmm_forward_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_dense_bmm_forward_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a022cdaaee01f619cf0cb7b29d80cbc65" name="a022cdaaee01f619cf0cb7b29d80cbc65"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a022cdaaee01f619cf0cb7b29d80cbc65">&#9670;&#160;</a></span>jagged_dense_bmm_forward_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_dense_bmm_forward_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6c32f4b4ccfdef9cf63d463cb235ec38" name="a6c32f4b4ccfdef9cf63d463cb235ec38"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6c32f4b4ccfdef9cf63d463cb235ec38">&#9670;&#160;</a></span>jagged_dense_bmm_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> jagged_dense_bmm_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 2 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 3 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>y</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 2 &gt;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a47e4d714a08316066470d979f97f1d81" name="a47e4d714a08316066470d979f97f1d81"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a47e4d714a08316066470d979f97f1d81">&#9670;&#160;</a></span>jagged_dense_dense_elementwise_add_jagged_output()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &gt; jagged_dense_dense_elementwise_add_jagged_output </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y_0</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y_1</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a10611541bdce9c65bfe48a01474d1725" name="a10611541bdce9c65bfe48a01474d1725"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a10611541bdce9c65bfe48a01474d1725">&#9670;&#160;</a></span>jagged_dense_dense_elementwise_add_jagged_output_forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_dense_dense_elementwise_add_jagged_output_forward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>dense_0</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>dense_1</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a56cac54ea3d7672c629010018ba59568" name="a56cac54ea3d7672c629010018ba59568"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a56cac54ea3d7672c629010018ba59568">&#9670;&#160;</a></span>jagged_dense_dense_elementwise_add_jagged_output_forward_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_dense_dense_elementwise_add_jagged_output_forward_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; at::Tensor &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>y_0</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>y_1</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab421ce372347f826b7e7ff9e35f26c93" name="ab421ce372347f826b7e7ff9e35f26c93"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab421ce372347f826b7e7ff9e35f26c93">&#9670;&#160;</a></span>jagged_dense_dense_elementwise_add_jagged_output_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &gt; jagged_dense_dense_elementwise_add_jagged_output_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; at::Tensor &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>y_0</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a319b3f5f33bec0aff79f0ee990483f3d" name="a319b3f5f33bec0aff79f0ee990483f3d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a319b3f5f33bec0aff79f0ee990483f3d">&#9670;&#160;</a></span>jagged_dense_dense_elementwise_jagged_output_()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">F</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> jagged_dense_dense_elementwise_jagged_output_ </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y_0</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y_1</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">F</a></td>          <td class="paramname"><span class="paramname"><em>f</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="adfb04060c9eecdadcf59b3c15d5bca08" name="adfb04060c9eecdadcf59b3c15d5bca08"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adfb04060c9eecdadcf59b3c15d5bca08">&#9670;&#160;</a></span>jagged_dense_dense_elementwise_jagged_output_matches_opt()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> jagged_dense_dense_elementwise_jagged_output_matches_opt </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>num_jagged_dim</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y_0_reshaped</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y_1_reshaped</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output_values</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="aac40d60c62b0d176a962cdad964e34f6" name="aac40d60c62b0d176a962cdad964e34f6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aac40d60c62b0d176a962cdad964e34f6">&#9670;&#160;</a></span>jagged_dense_dense_elementwise_jagged_output_opt_()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">F</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> jagged_dense_dense_elementwise_jagged_output_opt_ </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y_0</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y_1</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">F</a></td>          <td class="paramname"><span class="paramname"><em>f</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a16d84a11c2e32cb0064721354fb190b7" name="a16d84a11c2e32cb0064721354fb190b7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a16d84a11c2e32cb0064721354fb190b7">&#9670;&#160;</a></span>jagged_dense_elementwise_add_jagged_output_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &gt; jagged_dense_elementwise_add_jagged_output_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; at::Tensor &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aff88b44d096bd7a039dca72a5855198c" name="aff88b44d096bd7a039dca72a5855198c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aff88b44d096bd7a039dca72a5855198c">&#9670;&#160;</a></span>jagged_dense_elementwise_add_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_dense_elementwise_add_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a124d128a82ffb0342ce597d0325060fb" name="a124d128a82ffb0342ce597d0325060fb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a124d128a82ffb0342ce597d0325060fb">&#9670;&#160;</a></span>jagged_dense_elementwise_jagged_output_()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">F</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> jagged_dense_elementwise_jagged_output_ </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">F</a></td>          <td class="paramname"><span class="paramname"><em>f</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aded7d8ce8ffbcce568c498fb32a7d071" name="aded7d8ce8ffbcce568c498fb32a7d071"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aded7d8ce8ffbcce568c498fb32a7d071">&#9670;&#160;</a></span>jagged_dense_elementwise_jagged_output_opt_()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">F</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> jagged_dense_elementwise_jagged_output_opt_ </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">F</a></td>          <td class="paramname"><span class="paramname"><em>f</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6de8f2f64f7d90ab1997df02470a9564" name="a6de8f2f64f7d90ab1997df02470a9564"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6de8f2f64f7d90ab1997df02470a9564">&#9670;&#160;</a></span>jagged_dense_elementwise_mul_backward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; jagged_dense_elementwise_mul_backward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>grad_output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="abfbf6c239d283084ed1c68f18ea24af5" name="abfbf6c239d283084ed1c68f18ea24af5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abfbf6c239d283084ed1c68f18ea24af5">&#9670;&#160;</a></span>jagged_dense_elementwise_mul_backward_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; jagged_dense_elementwise_mul_backward_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>grad_output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aaa297ab58f55125d7eb7b040cc4c254b" name="aaa297ab58f55125d7eb7b040cc4c254b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaa297ab58f55125d7eb7b040cc4c254b">&#9670;&#160;</a></span>jagged_dense_elementwise_mul_forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_dense_elementwise_mul_forward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac30cb8e7e035c24bf4f6ac15bf1b623a" name="ac30cb8e7e035c24bf4f6ac15bf1b623a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac30cb8e7e035c24bf4f6ac15bf1b623a">&#9670;&#160;</a></span>jagged_dense_elementwise_mul_forward_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_dense_elementwise_mul_forward_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aaeeacda7f3587bfe9bf2ecf376dd635e" name="aaeeacda7f3587bfe9bf2ecf376dd635e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaeeacda7f3587bfe9bf2ecf376dd635e">&#9670;&#160;</a></span>jagged_dense_elementwise_mul_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &gt; jagged_dense_elementwise_mul_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aabd8b530d0ac7e5cb96cf19c7eb517e9" name="aabd8b530d0ac7e5cb96cf19c7eb517e9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aabd8b530d0ac7e5cb96cf19c7eb517e9">&#9670;&#160;</a></span>jagged_hash_size_cumsum_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; jagged_hash_size_cumsum_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>batch_size</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af80524a7d454f6db1c478808e8a659a6" name="af80524a7d454f6db1c478808e8a659a6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af80524a7d454f6db1c478808e8a659a6">&#9670;&#160;</a></span>jagged_index_add_2d_forward_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_index_add_2d_forward_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_dense_input_rows</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_output_rows</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Add sequences from input jagged tensor to output jagged tensor based on indices specified in the indices tensor (this function invokes jagged_index_add_2d_kernel) </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">values</td><td>2D dense value tensor of input jagged tensor </td></tr>
    <tr><td class="paramname">indices</td><td>1D tensor that contains indices to be added in output jagged tensor </td></tr>
    <tr><td class="paramname">input_offsets</td><td>1D tensor that contains offsets of input jagged tensor </td></tr>
    <tr><td class="paramname">output_offsets</td><td>1D tensor that contains offsets of output jagged tensor </td></tr>
    <tr><td class="paramname">num_dense_input_rows</td><td>The total number of rows in the 2D dense value tensor of input jagged tensor </td></tr>
    <tr><td class="paramname">num_output_rows</td><td>The number of sequences in jagged output tensor </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a53a6da74de342260dcb15c68e9bddfd6" name="a53a6da74de342260dcb15c68e9bddfd6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a53a6da74de342260dcb15c68e9bddfd6">&#9670;&#160;</a></span>jagged_index_add_2d_forward_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_index_add_2d_forward_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_dense_input_rows</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_output_rows</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Add sequences from input jagged tensor to output jagged tensor based on indices specified in the indices tensor (host function for dispatching jagged_index_add_2d_kernel to GPU) </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">values</td><td>2D dense value tensor of input jagged tensor </td></tr>
    <tr><td class="paramname">indices</td><td>1D tensor that contains indices to be added in output jagged tensor </td></tr>
    <tr><td class="paramname">input_offsets</td><td>1D tensor that contains offsets of input jagged tensor </td></tr>
    <tr><td class="paramname">output_offsets</td><td>1D tensor that contains offsets of output jagged tensor </td></tr>
    <tr><td class="paramname">num_dense_input_rows</td><td>The total number of rows in the 2D dense value tensor of input jagged tensor </td></tr>
    <tr><td class="paramname">num_output_rows</td><td>The number of sequences in jagged output tensor </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a8e1ed94256304ab16b948117d5315ee2" name="a8e1ed94256304ab16b948117d5315ee2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8e1ed94256304ab16b948117d5315ee2">&#9670;&#160;</a></span>jagged_index_add_2d_forward_v2_impl()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_index_add_2d_forward_v2_impl </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_output_rows</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab571c6d5519c86bddfe58835c8209a4c" name="ab571c6d5519c86bddfe58835c8209a4c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab571c6d5519c86bddfe58835c8209a4c">&#9670;&#160;</a></span>jagged_index_add_2d_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> jagged_index_add_2d_kernel </td>
          <td>(</td>
          <td class="paramtype">at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 2 &gt;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 2 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>output_offsets</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aca95193cb0cc3db7030f18cb59c6cc33" name="aca95193cb0cc3db7030f18cb59c6cc33"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aca95193cb0cc3db7030f18cb59c6cc33">&#9670;&#160;</a></span>jagged_index_select_2d()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; jagged_index_select_2d </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Call the autograd function of jagged_index_select_2d</p>
<p>Forward: Copy sequences from input jagged tensor based on indices specified in the indices tensor to output jagged tensor</p>
<p>Backward: Add sequences from output gradient jagged tensor to input gradient jagged tensor based on indices specified in the indices tensor</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">values</td><td>2D dense value of input jagged tensor </td></tr>
    <tr><td class="paramname">lengths</td><td>1D tensor that contains sequence lengths of input jagged tensor </td></tr>
    <tr><td class="paramname">indices</td><td>1D tensor that contains indices to be selected from input jagged tensor </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a71a54a14d90862afc8e5fe03e0c9ed8f" name="a71a54a14d90862afc8e5fe03e0c9ed8f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a71a54a14d90862afc8e5fe03e0c9ed8f">&#9670;&#160;</a></span>jagged_index_select_2d_forward_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_index_select_2d_forward_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_dense_output_rows</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Copy sequences from input jagged tensor based on indices specified in the indices tensor to output jagged tensor (this function invokes jagged_index_select_2d_kernel) </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">values</td><td>2D dense value tensor of input jagged tensor </td></tr>
    <tr><td class="paramname">indices</td><td>1D tensor that contains indices to be selected from input jagged tensor </td></tr>
    <tr><td class="paramname">input_offsets</td><td>1D tensor that contains offsets of input jagged tensor </td></tr>
    <tr><td class="paramname">output_offsets</td><td>1D tensor that contains offsets of output jagged tensor </td></tr>
    <tr><td class="paramname">num_dense_output_rows</td><td>The total number of rows in the 2D dense value tensor of output jagged tensor </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="acb5a744fbd29c8a3a25621c2850686c1" name="acb5a744fbd29c8a3a25621c2850686c1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acb5a744fbd29c8a3a25621c2850686c1">&#9670;&#160;</a></span>jagged_index_select_2d_forward_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_index_select_2d_forward_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_dense_output_rows</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Copy sequences from input jagged tensor based on indices specified in the indices tensor to an output jagged tensor (host function for dispatching jagged_index_select_2d_kernel to GPU) </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">values</td><td>2D dense value tensor of input jagged tensor </td></tr>
    <tr><td class="paramname">indices</td><td>1D tensor that contains indices to be selected from output jagged tensor </td></tr>
    <tr><td class="paramname">input_offsets</td><td>1D tensor that contains offsets of input jagged tensor </td></tr>
    <tr><td class="paramname">output_offsets</td><td>1D tensor that contains offsets of output jagged tensor </td></tr>
    <tr><td class="paramname">num_dense_output_rows</td><td>The total number of rows in the 2D dense value tensor of output jagged tensor </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="acd9af0fd221ab3fc330ca9f278433a3f" name="acd9af0fd221ab3fc330ca9f278433a3f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acd9af0fd221ab3fc330ca9f278433a3f">&#9670;&#160;</a></span>jagged_index_select_2d_forward_v2_impl()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_index_select_2d_forward_v2_impl </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output_offsets</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab1228b502a424869c5a7353f9fe52316" name="ab1228b502a424869c5a7353f9fe52316"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab1228b502a424869c5a7353f9fe52316">&#9670;&#160;</a></span>jagged_index_select_2d_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> jagged_index_select_2d_kernel </td>
          <td>(</td>
          <td class="paramtype">at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 2 &gt;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 2 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>output_offsets</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae94c97196a7c392695b64f0db906ff4c" name="ae94c97196a7c392695b64f0db906ff4c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae94c97196a7c392695b64f0db906ff4c">&#9670;&#160;</a></span>jagged_jagged_bmm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_jagged_bmm </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5b01fcfb83764115f38eeab21c28a6a3" name="a5b01fcfb83764115f38eeab21c28a6a3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5b01fcfb83764115f38eeab21c28a6a3">&#9670;&#160;</a></span>jagged_jagged_bmm_forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_jagged_bmm_forward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0793a1a7b328d1351b6036d0be6a9c3d" name="a0793a1a7b328d1351b6036d0be6a9c3d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0793a1a7b328d1351b6036d0be6a9c3d">&#9670;&#160;</a></span>jagged_jagged_bmm_forward_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_jagged_bmm_forward_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2722fce931f20d923aba071236be4c87" name="a2722fce931f20d923aba071236be4c87"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2722fce931f20d923aba071236be4c87">&#9670;&#160;</a></span>jagged_jagged_bmm_forward_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_jagged_bmm_forward_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a33c7044a13254607610928c6825738b1" name="a33c7044a13254607610928c6825738b1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a33c7044a13254607610928c6825738b1">&#9670;&#160;</a></span>jagged_jagged_bmm_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> jagged_jagged_bmm_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 2 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 2 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>y_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 3 &gt;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8fa5d329cfcc18c3304ba018919004ff" name="a8fa5d329cfcc18c3304ba018919004ff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8fa5d329cfcc18c3304ba018919004ff">&#9670;&#160;</a></span>jagged_jagged_elementwise_dense_output_()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">F</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> jagged_jagged_elementwise_dense_output_ </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>x_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>y_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">F</a></td>          <td class="paramname"><span class="paramname"><em>f</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a></td>          <td class="paramname"><span class="paramname"><em>padding_value</em><span class="paramdefsep"> = </span><span class="paramdefval"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">static_cast</a>&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>&gt;(0)</span></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab17aab73b431292434fd0d642a538960" name="ab17aab73b431292434fd0d642a538960"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab17aab73b431292434fd0d642a538960">&#9670;&#160;</a></span>jagged_slice()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; jagged_slice </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>start</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>slice_length</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4e6521d00a6f81ad8ad7f7d38eef1aea" name="a4e6521d00a6f81ad8ad7f7d38eef1aea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4e6521d00a6f81ad8ad7f7d38eef1aea">&#9670;&#160;</a></span>jagged_slice_forward_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_slice_forward_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>x_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>src_start</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tgt_start</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_output_rows</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>slice_length</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>fill_zeros</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Slice the jagged dim to max length from slice_length, from start point <code>start</code>. This is a jagged -&gt; jagged op </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x_values</td><td>- X values of shape B * J_DIM where J_DIM is jagged dim </td></tr>
    <tr><td class="paramname">x_lengths</td><td>- length along jagged dim </td></tr>
    <tr><td class="paramname">src_start</td><td>- start of slice operation from the src tensor </td></tr>
    <tr><td class="paramname">output_lengths</td><td>- length of jagged dim for output tensor </td></tr>
    <tr><td class="paramname">tgt_start</td><td>- position to start filling in sliced values from source </td></tr>
    <tr><td class="paramname">num_output_rows</td><td>- output dense dim </td></tr>
    <tr><td class="paramname">slice_length</td><td>- length of jagged dim to slice </td></tr>
    <tr><td class="paramname">fill_zeros</td><td>- option exists as an optimization, we can reuse the same code path for forward &amp; backward. For backward we need to fill zeros in output tensor but fwd we don't. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a284b652fdac146671fc324ac57d2ad5d" name="a284b652fdac146671fc324ac57d2ad5d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a284b652fdac146671fc324ac57d2ad5d">&#9670;&#160;</a></span>jagged_slice_forward_cpu_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> jagged_slice_forward_cpu_kernel </td>
          <td>(</td>
          <td class="paramtype">at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 1 &gt;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>output_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>output_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tgt_start</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>input_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>src_start</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>slice_length</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a069ed261b53e7051b85f3e572cad7f7e" name="a069ed261b53e7051b85f3e572cad7f7e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a069ed261b53e7051b85f3e572cad7f7e">&#9670;&#160;</a></span>jagged_softmax()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; jagged_softmax </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7ba518434a034920e1092bf6d73879fd" name="a7ba518434a034920e1092bf6d73879fd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7ba518434a034920e1092bf6d73879fd">&#9670;&#160;</a></span>jagged_softmax_backward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_softmax_backward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>grad_output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a305d9969e73060e49580aab1456ceb35" name="a305d9969e73060e49580aab1456ceb35"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a305d9969e73060e49580aab1456ceb35">&#9670;&#160;</a></span>jagged_softmax_backward_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_softmax_backward_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>grad_output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7101ddaed8357d824a9eeeaff67e5c4c" name="a7101ddaed8357d824a9eeeaff67e5c4c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7101ddaed8357d824a9eeeaff67e5c4c">&#9670;&#160;</a></span>jagged_softmax_backward_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> jagged_softmax_backward_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 2 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>grad_output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 2 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 2 &gt;</td>          <td class="paramname"><span class="paramname"><em>grad_input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aad25e4e44afa7169c17e48d726ee0477" name="aad25e4e44afa7169c17e48d726ee0477"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aad25e4e44afa7169c17e48d726ee0477">&#9670;&#160;</a></span>jagged_softmax_backward_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_softmax_backward_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>grad_output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a023a8d9db48d27efcd2e77ede6366f5d" name="a023a8d9db48d27efcd2e77ede6366f5d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a023a8d9db48d27efcd2e77ede6366f5d">&#9670;&#160;</a></span>jagged_softmax_forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_softmax_forward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab117510dd56fd42f3d774d22633b107f" name="ab117510dd56fd42f3d774d22633b107f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab117510dd56fd42f3d774d22633b107f">&#9670;&#160;</a></span>jagged_softmax_forward_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_softmax_forward_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac14e78d89697f34bcaa7c0a725c8a04a" name="ac14e78d89697f34bcaa7c0a725c8a04a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac14e78d89697f34bcaa7c0a725c8a04a">&#9670;&#160;</a></span>jagged_softmax_forward_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_softmax_forward_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a20e3d96daba045e321717b025f4124cc" name="a20e3d96daba045e321717b025f4124cc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a20e3d96daba045e321717b025f4124cc">&#9670;&#160;</a></span>jagged_softmax_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> jagged_softmax_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 2 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">at::TensorAccessor&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 2 &gt;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a861454c4383e6a0869a6c007fc498eed" name="a861454c4383e6a0869a6c007fc498eed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a861454c4383e6a0869a6c007fc498eed">&#9670;&#160;</a></span>jagged_to_padded_dense_backward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor jagged_to_padded_dense_backward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>grad_output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">at::SymInt</td>          <td class="paramname"><span class="paramname"><em>total_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8663dcc9727a468507eb75a849ae5820" name="a8663dcc9727a468507eb75a849ae5820"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8663dcc9727a468507eb75a849ae5820">&#9670;&#160;</a></span>jagged_to_padded_dense_backward_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_to_padded_dense_backward_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>grad_output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">at::SymInt</td>          <td class="paramname"><span class="paramname"><em>total_L</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4fc6df6df430f9f9a20d7fe9d88dd009" name="a4fc6df6df430f9f9a20d7fe9d88dd009"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4fc6df6df430f9f9a20d7fe9d88dd009">&#9670;&#160;</a></span>jagged_to_padded_dense_forward_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_to_padded_dense_forward_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::SymIntArrayRef</td>          <td class="paramname"><span class="paramname"><em>max_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>padding_value</em><span class="paramdefsep"> = </span><span class="paramdefval">0</span></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae45c299345273bf31be20e4893f58c28" name="ae45c299345273bf31be20e4893f58c28"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae45c299345273bf31be20e4893f58c28">&#9670;&#160;</a></span>jagged_to_padded_dense_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> jagged_to_padded_dense_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::SymIntArrayRef</td>          <td class="paramname"><span class="paramname"><em>max_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>padding_value</em><span class="paramdefsep"> = </span><span class="paramdefval">0</span></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a006273b56cd5a2efd001ad71d801a551" name="a006273b56cd5a2efd001ad71d801a551"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a006273b56cd5a2efd001ad71d801a551">&#9670;&#160;</a></span>jagged_unique_indices_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; jagged_unique_indices_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>hash_size_cumsum</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>hash_size_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7d13c6946f45ae31d20aaecbd2316fec" name="a7d13c6946f45ae31d20aaecbd2316fec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7d13c6946f45ae31d20aaecbd2316fec">&#9670;&#160;</a></span>keyed_jagged_index_add_dim1_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> keyed_jagged_index_add_dim1_kernel </td>
          <td>(</td>
          <td class="paramtype">at::PackedTensorAccessor64&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 1, at::RestrictPtrTraits &gt;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::PackedTensorAccessor64&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 1, at::RestrictPtrTraits &gt;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::PackedTensorAccessor32&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>, 1, at::RestrictPtrTraits &gt;</td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::PackedTensorAccessor32&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>, 1, at::RestrictPtrTraits &gt;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::PackedTensorAccessor32&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>, 1, at::RestrictPtrTraits &gt;</td>          <td class="paramname"><span class="paramname"><em>output_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>num_batches</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>output_batch_size</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0a518ef8f85868c32ac832576f8504d9" name="a0a518ef8f85868c32ac832576f8504d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0a518ef8f85868c32ac832576f8504d9">&#9670;&#160;</a></span>keyed_jagged_index_select_dim1_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">weight_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> has_weights&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> keyed_jagged_index_select_dim1_kernel </td>
          <td>(</td>
          <td class="paramtype">at::PackedTensorAccessor64&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 1, at::RestrictPtrTraits &gt;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">at::PackedTensorAccessor64&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">weight_t</a>, 1, at::RestrictPtrTraits &gt;</td>          <td class="paramname"><span class="paramname"><em>output_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::PackedTensorAccessor64&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, 1, at::RestrictPtrTraits &gt;</td>          <td class="paramname"><span class="paramname"><em>input</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::PackedTensorAccessor64&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">weight_t</a>, 1, at::RestrictPtrTraits &gt;</td>          <td class="paramname"><span class="paramname"><em>weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::PackedTensorAccessor32&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>, 1, at::RestrictPtrTraits &gt;</td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::PackedTensorAccessor32&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>, 1, at::RestrictPtrTraits &gt;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::PackedTensorAccessor32&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>, 1, at::RestrictPtrTraits &gt;</td>          <td class="paramname"><span class="paramname"><em>output_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>num_batches</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>input_batch_size</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a50a64d97045199097d3ff83edaf56a1a" name="a50a64d97045199097d3ff83edaf56a1a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a50a64d97045199097d3ff83edaf56a1a">&#9670;&#160;</a></span>keyed_jagged_index_select_dim_1_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; keyed_jagged_index_select_dim_1_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>batch_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>weights</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9599d315f833a6d562ee1d25d4ee5923" name="a9599d315f833a6d562ee1d25d4ee5923"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9599d315f833a6d562ee1d25d4ee5923">&#9670;&#160;</a></span>lengths_range()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> lengths_range </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>t_in</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; std::vector&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt; &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>shape</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ace0a963a484e5501c50533122cdecc3c" name="ace0a963a484e5501c50533122cdecc3c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ace0a963a484e5501c50533122cdecc3c">&#9670;&#160;</a></span>lengths_range_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> lengths_range_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>t_in</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; std::vector&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt; &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>shape</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a19280a435704ff4093b148460c37bc84" name="a19280a435704ff4093b148460c37bc84"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a19280a435704ff4093b148460c37bc84">&#9670;&#160;</a></span>lengths_range_out()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp; lengths_range_out </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>t_in</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; std::vector&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt; &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>shape</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9e8721a4003045038e10d3a4c8258c96" name="a9e8721a4003045038e10d3a4c8258c96"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9e8721a4003045038e10d3a4c8258c96">&#9670;&#160;</a></span>lfu_cache_find_uncached_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::pair&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; lfu_cache_find_uncached_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>unique_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>unique_indices_length</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lxu_cache_state</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lfu_state</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a45bb3081a2688f09448ffda6bc5d5f2e" name="a45bb3081a2688f09448ffda6bc5d5f2e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a45bb3081a2688f09448ffda6bc5d5f2e">&#9670;&#160;</a></span>lfu_cache_populate_byte_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> lfu_cache_populate_byte_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>cache_hash_size_cumsum</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>total_cache_hash_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>cache_index_table_map</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>weights_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>weights_tys</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>D_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>linear_cache_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lxu_cache_state</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lxu_cache_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lfu_state</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>row_alignment</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aca510adc64caa635df004e9b419bbb1b" name="aca510adc64caa635df004e9b419bbb1b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aca510adc64caa635df004e9b419bbb1b">&#9670;&#160;</a></span>lfu_update_counts_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> lfu_update_counts_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>unique_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>unique_indices_length</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>unique_indices_count</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lfu_state</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6eaeebeb996c343db6d076fce7952133" name="a6eaeebeb996c343db6d076fce7952133"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6eaeebeb996c343db6d076fce7952133">&#9670;&#160;</a></span>linearize_cache_indices_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> linearize_cache_indices_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>cache_hash_size_cumsum</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>offsets</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9c7ab59a89fd36f5c07b9c86bdc891c8" name="a9c7ab59a89fd36f5c07b9c86bdc891c8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9c7ab59a89fd36f5c07b9c86bdc891c8">&#9670;&#160;</a></span>linearize_cache_indices_from_row_idx_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> linearize_cache_indices_from_row_idx_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>cache_hash_size_cumsum</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>update_table_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>update_row_indices</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a003948b9ad61509936564075f2cead23" name="a003948b9ad61509936564075f2cead23"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a003948b9ad61509936564075f2cead23">&#9670;&#160;</a></span>load_qparams_from_row()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">emb_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a> load_qparams_from_row </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">emb_t</a> *</td>          <td class="paramname"><span class="paramname"><em>qparam_ptr</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a74ffde7bbe921424bef364880c5d57ea" name="a74ffde7bbe921424bef364880c5d57ea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a74ffde7bbe921424bef364880c5d57ea">&#9670;&#160;</a></span>lookup_batched_unary_embedding_function()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> lookup_batched_unary_embedding_function </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>weight</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>table_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8d6ac45089730a607c2a46a265ac8b7b" name="a8d6ac45089730a607c2a46a265ac8b7b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8d6ac45089730a607c2a46a265ac8b7b">&#9670;&#160;</a></span>lru_cache_populate_byte_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> lru_cache_populate_byte_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>cache_hash_size_cumsum</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>total_cache_hash_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>cache_index_table_map</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>weights_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>weights_tys</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>D_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>linear_cache_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lxu_cache_state</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lxu_cache_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>time_stamp</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lru_state</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>row_alignment</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>gather_cache_stats</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;</td>          <td class="paramname"><span class="paramname"><em>uvm_cache_stats</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab26f1a83ce47d5510deed9bc9e9d6d9a" name="ab26f1a83ce47d5510deed9bc9e9d6d9a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab26f1a83ce47d5510deed9bc9e9d6d9a">&#9670;&#160;</a></span>lxu_cache_lookup_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> lxu_cache_lookup_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>linear_cache_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lxu_cache_state</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>invalid_index</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>gather_cache_stats</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;</td>          <td class="paramname"><span class="paramname"><em>uvm_cache_stats</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;</td>          <td class="paramname"><span class="paramname"><em>num_uniq_cache_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;</td>          <td class="paramname"><span class="paramname"><em>lxu_cache_locations_output</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a25e94d75c07b4c2bc5427fe771f2d60d" name="a25e94d75c07b4c2bc5427fe771f2d60d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a25e94d75c07b4c2bc5427fe771f2d60d">&#9670;&#160;</a></span>make_zero_float2()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a> make_zero_float2 </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="afca9b335bed360fc1ec3e239183a792f" name="afca9b335bed360fc1ec3e239183a792f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afca9b335bed360fc1ec3e239183a792f">&#9670;&#160;</a></span>make_zero_float4()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float4</a> make_zero_float4 </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a66822cc23f92dbb8c18c596511b2a917" name="a66822cc23f92dbb8c18c596511b2a917"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a66822cc23f92dbb8c18c596511b2a917">&#9670;&#160;</a></span>make_zero_float8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float8</a> make_zero_float8 </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7dcc205dbf44fb2e80d62bf47eb6c4c4" name="a7dcc205dbf44fb2e80d62bf47eb6c4c4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7dcc205dbf44fb2e80d62bf47eb6c4c4">&#9670;&#160;</a></span>make_zero_float_16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float_16</a> make_zero_float_16 </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0223abaee318471a5e42318a1b7056b6" name="a0223abaee318471a5e42318a1b7056b6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0223abaee318471a5e42318a1b7056b6">&#9670;&#160;</a></span>masked_select_jagged_1d()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; masked_select_jagged_1d </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>mask</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5f0a51933b0e3b1a96d8806d702ff82e" name="a5f0a51933b0e3b1a96d8806d702ff82e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5f0a51933b0e3b1a96d8806d702ff82e">&#9670;&#160;</a></span>max()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> max </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> *</td>          <td class="paramname"><span class="paramname"><em>from</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> *</td>          <td class="paramname"><span class="paramname"><em>to</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a25ca3ce57c9101b878431d46cc049b50" name="a25ca3ce57c9101b878431d46cc049b50"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a25ca3ce57c9101b878431d46cc049b50">&#9670;&#160;</a></span>merge_pooled_embeddings()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> merge_pooled_embeddings </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;</td>          <td class="paramname"><span class="paramname"><em>pooled_embeddings</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>uncat_dim_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">at::Device</td>          <td class="paramname"><span class="paramname"><em>target_device</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>cat_dim</em><span class="paramdefsep"> = </span><span class="paramdefval">1</span></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aad2aea0289bc3c5d135846ee32e0638c" name="aad2aea0289bc3c5d135846ee32e0638c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aad2aea0289bc3c5d135846ee32e0638c">&#9670;&#160;</a></span>merge_pooled_embeddings_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> merge_pooled_embeddings_cpu </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;</td>          <td class="paramname"><span class="paramname"><em>pooled_embeddings</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">at::Device</td>          <td class="paramname"><span class="paramname"><em>target_device</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>cat_dim</em><span class="paramdefsep"> = </span><span class="paramdefval">1</span></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5b62c5028106dcf10b450a8f178338ad" name="a5b62c5028106dcf10b450a8f178338ad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5b62c5028106dcf10b450a8f178338ad">&#9670;&#160;</a></span>min()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> min </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> *</td>          <td class="paramname"><span class="paramname"><em>from</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> *</td>          <td class="paramname"><span class="paramname"><em>to</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a2f18d44e708cafd185e02defd95fb774" name="a2f18d44e708cafd185e02defd95fb774"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2f18d44e708cafd185e02defd95fb774">&#9670;&#160;</a></span>native_empty_like()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> native_empty_like </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>self</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a94744dd15c8d4ffa9c5cf581e499f1ca" name="a94744dd15c8d4ffa9c5cf581e499f1ca"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a94744dd15c8d4ffa9c5cf581e499f1ca">&#9670;&#160;</a></span>nearest_rounding_vector() <span class="overload">[1/4]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">dst_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">src_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> nearest_rounding_vector </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">dst_t</a> *</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">Vec4T</a>&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">src_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aefcbaad4af03b4a72b15ca0ca40bc50f" name="aefcbaad4af03b4a72b15ca0ca40bc50f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aefcbaad4af03b4a72b15ca0ca40bc50f">&#9670;&#160;</a></span>nearest_rounding_vector() <span class="overload">[2/4]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> nearest_rounding_vector </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a> *</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">Vec4T</a>&lt; at::Half &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"><em>qparams</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa8fa436e2338f97218eff8a48c94d8a4" name="aa8fa436e2338f97218eff8a48c94d8a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa8fa436e2338f97218eff8a48c94d8a4">&#9670;&#160;</a></span>nearest_rounding_vector() <span class="overload">[3/4]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> nearest_rounding_vector </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a> *</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">Vec4T</a>&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"><em>qparams</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa56064f3d743f7535d59a1baca06dc1f" name="aa56064f3d743f7535d59a1baca06dc1f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa56064f3d743f7535d59a1baca06dc1f">&#9670;&#160;</a></span>nearest_rounding_vector() <span class="overload">[4/4]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> nearest_rounding_vector </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a> *</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">Vec4T</a>&lt; <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"><em>qparams</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aad6847fe2dc2433889aeb2dddf14f496" name="aad6847fe2dc2433889aeb2dddf14f496"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aad6847fe2dc2433889aeb2dddf14f496">&#9670;&#160;</a></span>new_unified_tensor_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> new_unified_tensor_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>self</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; std::int64_t &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>sizes</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>is_host_mapped</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab6871043c7881b5434de1e8eea491c80" name="ab6871043c7881b5434de1e8eea491c80"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab6871043c7881b5434de1e8eea491c80">&#9670;&#160;</a></span>offset_tbe_input_combine_with_length_args()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> offset_tbe_input_combine_with_length_args </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a> **</td>          <td class="paramname"><span class="paramname"><em>indices_addrs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a> **</td>          <td class="paramname"><span class="paramname"><em>lengths_addrs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a> **</td>          <td class="paramname"><span class="paramname"><em>indices_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a> **</td>          <td class="paramname"><span class="paramname"><em>lengths_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a> **</td>          <td class="paramname"><span class="paramname"><em>per_sample_weights_addrs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> **</td>          <td class="paramname"><span class="paramname"><em>indices_is_long</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> **</td>          <td class="paramname"><span class="paramname"><em>lengths_is_long</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a> *</td>          <td class="paramname"><span class="paramname"><em>base_addr</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>ptr_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>need_weights</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5aff23a0a3b0bc872ba44a0045b6e350" name="a5aff23a0a3b0bc872ba44a0045b6e350"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5aff23a0a3b0bc872ba44a0045b6e350">&#9670;&#160;</a></span>offsets_range_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> offsets_range_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>range_size</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3d88da2f7a769565c9ebdc070467eabe" name="a3d88da2f7a769565c9ebdc070467eabe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3d88da2f7a769565c9ebdc070467eabe">&#9670;&#160;</a></span>offsets_range_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> offsets_range_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>range_size</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a24fd2f4efa543ea716010c3fc1832587" name="a24fd2f4efa543ea716010c3fc1832587"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a24fd2f4efa543ea716010c3fc1832587">&#9670;&#160;</a></span>pack_segments_autograd()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> pack_segments_autograd </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>t_in</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::SymInt</td>          <td class="paramname"><span class="paramname"><em>max_length</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a51f0921a8e934c6c4d0fca5ebb5d8338" name="a51f0921a8e934c6c4d0fca5ebb5d8338"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a51f0921a8e934c6c4d0fca5ebb5d8338">&#9670;&#160;</a></span>pack_segments_backward_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> pack_segments_backward_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>total_length</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_length</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Map N+1 dim tensor to N dim based on lengths tensor Sequences that are shorter than the longest sequence are padded with zeros. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">data</td><td>N+1 dim Tensor. </td></tr>
    <tr><td class="paramname">lengths</td><td>1D int/long tensor contains the length in each of the input. </td></tr>
    <tr><td class="paramname">total_length</td><td>Sum of elements in the 1D tensor legnths </td></tr>
    <tr><td class="paramname">max_length</td><td>The pre-defined max_length for the packed segments. -1 means autodetect </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>unpacked_tensor N-dimensional tensor </dd></dl>

</div>
</div>
<a id="aaded8e25bef3a32580d71dc2ead25f0c" name="aaded8e25bef3a32580d71dc2ead25f0c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaded8e25bef3a32580d71dc2ead25f0c">&#9670;&#160;</a></span>pack_segments_backward_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> pack_segments_backward_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>total_length</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_length</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Map N+1 dim tensor to N dim based on lengths tensor Sequences that are shorter than the longest sequence are padded with zeros. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">data</td><td>N+1 dim Tensor. </td></tr>
    <tr><td class="paramname">lengths</td><td>1D int/long tensor contains the length in each of the input. </td></tr>
    <tr><td class="paramname">total_length</td><td>Sum of elements in the 1D tensor legnths </td></tr>
    <tr><td class="paramname">max_length</td><td>The pre-defined max_length for the packed segments. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>unpacked_tensor N-dimensional tensor </dd></dl>

</div>
</div>
<a id="a01151883c1840f280f4f9c083677c8b5" name="a01151883c1840f280f4f9c083677c8b5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a01151883c1840f280f4f9c083677c8b5">&#9670;&#160;</a></span>pack_segments_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> pack_segments_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>t_in</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_length</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a049c248a78797b27f5e053809c13b88e" name="a049c248a78797b27f5e053809c13b88e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a049c248a78797b27f5e053809c13b88e">&#9670;&#160;</a></span>pack_segments_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> pack_segments_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>t_in</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_length</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3ff1eed5a38a10b4da916f9ec154f225" name="a3ff1eed5a38a10b4da916f9ec154f225"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3ff1eed5a38a10b4da916f9ec154f225">&#9670;&#160;</a></span>pack_segments_cuda_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">Length_T</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">Data_T</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> pack_segments_cuda_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">Data_T</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>data_ptr</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>data_size_0</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">Length_T</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>lengths_ptr</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">Length_T</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>lengths_cum_sum</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">Length_T</a></td>          <td class="paramname"><span class="paramname"><em>max_length</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_seq</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>cell_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">Data_T</a></td>          <td class="paramname"><span class="paramname"><em>padding</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">Data_T</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>out_ptr</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">TORCH_DSA_KERNEL_ARGS</a></td>          <td class="paramname"><span class="paramname"></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a49cb5dd543cc63e932f458e1c79c0d00" name="a49cb5dd543cc63e932f458e1c79c0d00"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a49cb5dd543cc63e932f458e1c79c0d00">&#9670;&#160;</a></span>pack_segments_forward_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> pack_segments_forward_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>t_in</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_length</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Map N dim tensor to N+1 dim based on lengths tensor. Sequences that are shorter than the longest sequence are padded with zeros. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">t_in</td><td>N dim Tensor. </td></tr>
    <tr><td class="paramname">lengths</td><td>1D int/long tensor contains the length in each of the output. </td></tr>
    <tr><td class="paramname">max_length</td><td>The pre-defined max_length for the packed segments. -1 means autodetect </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>packed_tensor packed_tensor N + 1 dim Tensor where dim(1) is the max length, dim(0) is the batch size. </dd></dl>

</div>
</div>
<a id="a4bec138cb5be2583288d026eb4185646" name="a4bec138cb5be2583288d026eb4185646"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4bec138cb5be2583288d026eb4185646">&#9670;&#160;</a></span>pack_segments_forward_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> pack_segments_forward_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>t_in</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_length</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Map N dim tensor to N+1 dim based on lengths tensor. Sequences that are shorter than the longest sequence are padded with zeros. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">t_in</td><td>N dim Tensor. </td></tr>
    <tr><td class="paramname">lengths</td><td>1D int/long tensor contains the length in each of the output. </td></tr>
    <tr><td class="paramname">max_length</td><td>The pre-defined max_length for the packed segments. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>packed_tensor packed_tensor N + 1 dim Tensor where dim(1) is the max length, dim(0) is the batch size. </dd></dl>

</div>
</div>
<a id="af01b4023830652f0cc3e99c87f7b4526" name="af01b4023830652f0cc3e99c87f7b4526"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af01b4023830652f0cc3e99c87f7b4526">&#9670;&#160;</a></span>padding_fused_tbe_input_combine_with_length_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; padding_fused_tbe_input_combine_with_length_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>indices_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>per_sample_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>batch_size</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>padding_fused_tbe_input_combine_with_length_cpu is similar to tbe_input_combine_with_length_cpu, but padding all the lengths to the size specified by batch_size.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">indices_list</td><td>list of indices. </td></tr>
    <tr><td class="paramname">lengths_list</td><td>list of lengths. </td></tr>
    <tr><td class="paramname">per_sample_weights</td><td>list of per_sample_weights </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>tuple of combined indices, lengths, and per_sample_weights </dd></dl>

</div>
</div>
<a id="ab8d862f0ffee51a4d276f3989f0ab24b" name="ab8d862f0ffee51a4d276f3989f0ab24b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab8d862f0ffee51a4d276f3989f0ab24b">&#9670;&#160;</a></span>permute102_baddbmm_permute102_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> permute102_baddbmm_permute102_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>bias</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>A</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>B</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0c3f53164eb98c0b45b5aaef3e99a172" name="a0c3f53164eb98c0b45b5aaef3e99a172"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0c3f53164eb98c0b45b5aaef3e99a172">&#9670;&#160;</a></span>permute102_baddbmm_permute102_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> permute102_baddbmm_permute102_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>bias</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>A</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>B</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a22758d46158e49801e876ab269855736" name="a22758d46158e49801e876ab269855736"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a22758d46158e49801e876ab269855736">&#9670;&#160;</a></span>permute_1D_sparse_data_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &gt; permute_1D_sparse_data_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>permute</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>permuted_lengths_sum</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a83da584464d49a223941e4b926b9676a" name="a83da584464d49a223941e4b926b9676a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a83da584464d49a223941e4b926b9676a">&#9670;&#160;</a></span>permute_2D_sparse_data_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &gt; permute_2D_sparse_data_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>permute</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>permuted_lengths_sum</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aeabdb24bef8b30a2b80b94a676b2b5fb" name="aeabdb24bef8b30a2b80b94a676b2b5fb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeabdb24bef8b30a2b80b94a676b2b5fb">&#9670;&#160;</a></span>permute_duplicate_pooled_embs_auto_grad_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor permute_duplicate_pooled_embs_auto_grad_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>pooled_embs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>permute_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_permute_list</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a242a088c94da1f0b016087bef8460622" name="a242a088c94da1f0b016087bef8460622"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a242a088c94da1f0b016087bef8460622">&#9670;&#160;</a></span>permute_duplicate_pooled_embs_auto_grad_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> permute_duplicate_pooled_embs_auto_grad_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>pooled_embs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>permute_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_permute_list</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af0cdb20f76a1c62644ad644e4c7210ad" name="af0cdb20f76a1c62644ad644e4c7210ad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af0cdb20f76a1c62644ad644e4c7210ad">&#9670;&#160;</a></span>permute_duplicate_pooled_embs_auto_grad_split_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> permute_duplicate_pooled_embs_auto_grad_split_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>pooled_embs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>permute_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_permute_list</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a276c76fa5487668edb8477a844ca1704" name="a276c76fa5487668edb8477a844ca1704"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a276c76fa5487668edb8477a844ca1704">&#9670;&#160;</a></span>permute_duplicate_pooled_embs_auto_grad_split_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> permute_duplicate_pooled_embs_auto_grad_split_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>pooled_embs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>permute_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_permute_list</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="acc5af8d2639bda183a7758a7fb4d4e9a" name="acc5af8d2639bda183a7758a7fb4d4e9a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acc5af8d2639bda183a7758a7fb4d4e9a">&#9670;&#160;</a></span>permute_duplicate_pooled_embs_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor permute_duplicate_pooled_embs_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>pooled_embs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>permute_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_permute_list</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aecf7e9c2b36bb349c98294b9abfcf7c1" name="aecf7e9c2b36bb349c98294b9abfcf7c1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aecf7e9c2b36bb349c98294b9abfcf7c1">&#9670;&#160;</a></span>permute_duplicate_pooled_embs_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> permute_duplicate_pooled_embs_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>pooled_embs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>permute_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_permute_list</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a286571e933b530189672faaa53ee20e6" name="a286571e933b530189672faaa53ee20e6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a286571e933b530189672faaa53ee20e6">&#9670;&#160;</a></span>permute_duplicate_pooled_embs_split_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> permute_duplicate_pooled_embs_split_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>pooled_embs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>permute_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_permute_list</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a34e792da7d58bd96fc1c9d4c0b1b3a2a" name="a34e792da7d58bd96fc1c9d4c0b1b3a2a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a34e792da7d58bd96fc1c9d4c0b1b3a2a">&#9670;&#160;</a></span>permute_duplicate_pooled_embs_split_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> permute_duplicate_pooled_embs_split_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>pooled_embs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>permute_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_permute_list</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2b00efff9050b6bec363081afc5c3c2f" name="a2b00efff9050b6bec363081afc5c3c2f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2b00efff9050b6bec363081afc5c3c2f">&#9670;&#160;</a></span>permute_embeddings_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> permute_embeddings_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a></td>          <td class="paramname"><span class="paramname"><em>len</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a></td>          <td class="paramname"><span class="paramname"><em>T</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a></td>          <td class="paramname"><span class="paramname"><em>B</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>embeddings</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permute</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>input_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>output_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>permuted_embeddings</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4381e6e500aad1cf049aa509fc17b16b" name="a4381e6e500aad1cf049aa509fc17b16b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4381e6e500aad1cf049aa509fc17b16b">&#9670;&#160;</a></span>permute_pooled_embs_auto_grad_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor permute_pooled_embs_auto_grad_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>pooled_embs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa321302401045119810e93f42a361f1f" name="aa321302401045119810e93f42a361f1f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa321302401045119810e93f42a361f1f">&#9670;&#160;</a></span>permute_pooled_embs_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor permute_pooled_embs_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>pooled_embs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>permute_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_permute_list</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9b4a18abd526ab3e9c95f782d87afbbb" name="a9b4a18abd526ab3e9c95f782d87afbbb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9b4a18abd526ab3e9c95f782d87afbbb">&#9670;&#160;</a></span>permute_pooled_embs_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> permute_pooled_embs_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>pooled_embs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>permute_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_permute_list</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aca0e73083114d9eea99129e54b89fa23" name="aca0e73083114d9eea99129e54b89fa23"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aca0e73083114d9eea99129e54b89fa23">&#9670;&#160;</a></span>permute_pooled_embs_gpu_impl()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> permute_pooled_embs_gpu_impl </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>pooled_embs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>permute_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_permute_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>allow_duplicates</em><span class="paramdefsep"> = </span><span class="paramdefval"><a class="el" href="gen__embedding__forward__split__unweighted__kernel_8cu.html#a0ad31f76c1f9349ef8b21ca138e897cc">false</a></span></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1183d2ce4456d290df04c32b215fc22e" name="a1183d2ce4456d290df04c32b215fc22e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1183d2ce4456d290df04c32b215fc22e">&#9670;&#160;</a></span>permute_pooled_embs_meta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor permute_pooled_embs_meta </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>pooled_embs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9ce974f08ff3cb46289f39af5ea7fcec" name="a9ce974f08ff3cb46289f39af5ea7fcec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9ce974f08ff3cb46289f39af5ea7fcec">&#9670;&#160;</a></span>permute_pooled_embs_split_cpu_impl()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> permute_pooled_embs_split_cpu_impl </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>pooled_embs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>permute_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_permute_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>allow_duplicates</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0d587655a374b11bb6b7febcabe0f403" name="a0d587655a374b11bb6b7febcabe0f403"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0d587655a374b11bb6b7febcabe0f403">&#9670;&#160;</a></span>permute_pooled_embs_split_gpu_impl()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> permute_pooled_embs_split_gpu_impl </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>pooled_embs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>permute_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_offset_dim_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>inv_permute_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>allow_duplicates</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6c601604b9a15b45176ad42d4ca04d7d" name="a6c601604b9a15b45176ad42d4ca04d7d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6c601604b9a15b45176ad42d4ca04d7d">&#9670;&#160;</a></span>permute_sequence_embeddings_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; permute_sequence_embeddings_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>permute</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>embeddings</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a713a7245a4295a57007802212dca05ee" name="a713a7245a4295a57007802212dca05ee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a713a7245a4295a57007802212dca05ee">&#9670;&#160;</a></span>permute_sequence_embeddings_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; permute_sequence_embeddings_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>permute</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>embeddings</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7eec8c74f87d4204857061b761a17ede" name="a7eec8c74f87d4204857061b761a17ede"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7eec8c74f87d4204857061b761a17ede">&#9670;&#160;</a></span>permute_sparse_features_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &gt; permute_sparse_features_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>permute</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::optional&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>weights</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a82c664395e6340a5878c867fcf278bfc" name="a82c664395e6340a5878c867fcf278bfc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a82c664395e6340a5878c867fcf278bfc">&#9670;&#160;</a></span>prefix_sum()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> prefix_sum </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>length</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>array</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>presum</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab57019812325465b62248776bb200885" name="ab57019812325465b62248776bb200885"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab57019812325465b62248776bb200885">&#9670;&#160;</a></span>pruned_array_lookup_from_row_idx_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> pruned_array_lookup_from_row_idx_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>update_row_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>update_table_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>index_remappings</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>index_remappings_offsets</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="adda552b8784184a2f17aa997e10869f9" name="adda552b8784184a2f17aa997e10869f9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adda552b8784184a2f17aa997e10869f9">&#9670;&#160;</a></span>pruned_array_lookup_from_row_idx_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> pruned_array_lookup_from_row_idx_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>update_row_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>update_table_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>index_remappings</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>index_remappings_offsets</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Index remapping function that returns the remapped indices.</p>
<p>Args: update_row_indices: row indices for every new row update_table_indices: table indices for every new row index_remappings: concated index remapping for every embedding table index_remappings_offsets: offset for each embedding table</p>
<p>Returns: remapped indices for each new row. </p>

</div>
</div>
<a id="af5bbc85156e52ab097bb0f770a2f63e7" name="af5bbc85156e52ab097bb0f770a2f63e7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af5bbc85156e52ab097bb0f770a2f63e7">&#9670;&#160;</a></span>quantize_store()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">dst_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">src_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> quantize_store </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">dst_t</a> *</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">Vec4T</a>&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">src_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structfbgemm__gpu_1_1_stochastic_rounding_r_n_g_state.html">StochasticRoundingRNGState</a> *</td>          <td class="paramname"><span class="paramname"><em>state</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"><em>qparams</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a71657f0dff28b74e6cb71f2e70adba96" name="a71657f0dff28b74e6cb71f2e70adba96"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a71657f0dff28b74e6cb71f2e70adba96">&#9670;&#160;</a></span>reorder_batched_ad_indices_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> reorder_batched_ad_indices_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>cat_ad_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>cat_ad_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>reordered_cat_ad_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>batch_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_ads_in_batch</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>broadcast_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_indices_after_broadcast</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="abe2eef805cfc20b2d3ba69e3db973688" name="abe2eef805cfc20b2d3ba69e3db973688"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abe2eef805cfc20b2d3ba69e3db973688">&#9670;&#160;</a></span>reorder_batched_ad_indices_cpu_()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> reorder_batched_ad_indices_cpu_ </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>cat_ad_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>cat_ad_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>reordered_cat_ad_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>batch_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_ads_in_batch</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>broadcast_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a10ae2e750abd260fb3dc2deb5e6a10a6" name="a10ae2e750abd260fb3dc2deb5e6a10a6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a10ae2e750abd260fb3dc2deb5e6a10a6">&#9670;&#160;</a></span>reorder_batched_ad_indices_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> reorder_batched_ad_indices_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>cat_ad_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>cat_ad_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>reordered_cat_ad_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>batch_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_ads_in_batch</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>broadcast_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_indices_after_broadcast</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a87472f171b785c3735bc88d72c8ddd9e" name="a87472f171b785c3735bc88d72c8ddd9e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a87472f171b785c3735bc88d72c8ddd9e">&#9670;&#160;</a></span>reorder_batched_ad_lengths_()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> reorder_batched_ad_lengths_ </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>cat_ad_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>batch_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_ads_in_batch</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>broadcast_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>output</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aee6a046b2315137787cced8d9942a248" name="aee6a046b2315137787cced8d9942a248"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aee6a046b2315137787cced8d9942a248">&#9670;&#160;</a></span>reorder_batched_ad_lengths_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> reorder_batched_ad_lengths_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>cat_ad_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>batch_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_ads_in_batch</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>broadcast_lengths</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af398efd1fa34f78e6882f7691aa99fa9" name="af398efd1fa34f78e6882f7691aa99fa9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af398efd1fa34f78e6882f7691aa99fa9">&#9670;&#160;</a></span>reorder_batched_ad_lengths_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> reorder_batched_ad_lengths_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>cat_ad_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>batch_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_ads_in_batch</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>broadcast_lengths</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a17e57fc2dca2d6df09e26f3eec69464c" name="a17e57fc2dca2d6df09e26f3eec69464c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a17e57fc2dca2d6df09e26f3eec69464c">&#9670;&#160;</a></span>report_embedding_error()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">IndexType</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> report_embedding_error </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>t</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>B</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>b_begin</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>b_end</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">IndexType</a> *</td>          <td class="paramname"><span class="paramname"><em>offsets_data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">IndexType</a> *</td>          <td class="paramname"><span class="paramname"><em>indices_data</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>hash_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a></td>          <td class="paramname"><span class="paramname"><em>allow_minus_one</em><span class="paramdefsep"> = </span><span class="paramdefval"><a class="el" href="gen__embedding__forward__split__unweighted__kernel_8cu.html#a0ad31f76c1f9349ef8b21ca138e897cc">false</a></span></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>report error from fbgemm cpu embedding lookup kernels @params allow_minus_one true for embedding kernels generated with scale_bias_last == false that can take -1 indices (output from pruned embedding id mapping) </p>

</div>
</div>
<a id="af9dc4afe0a87b2326caf53649eee20eb" name="af9dc4afe0a87b2326caf53649eee20eb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af9dc4afe0a87b2326caf53649eee20eb">&#9670;&#160;</a></span>rk_double()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> rk_double </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structfbgemm__gpu_1_1rk__state.html">rk_state</a> *</td>          <td class="paramname"><span class="paramname"><em>state</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3914fbd6fed76ebe8d05a1967ec5ccb9" name="a3914fbd6fed76ebe8d05a1967ec5ccb9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3914fbd6fed76ebe8d05a1967ec5ccb9">&#9670;&#160;</a></span>rk_random()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">unsigned</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">long</a> rk_random </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structfbgemm__gpu_1_1rk__state.html">rk_state</a> *</td>          <td class="paramname"><span class="paramname"><em>state</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad56b0e8dd76a57dcc1e268831fe58abb" name="ad56b0e8dd76a57dcc1e268831fe58abb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad56b0e8dd76a57dcc1e268831fe58abb">&#9670;&#160;</a></span>rk_seed()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> rk_seed </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">unsigned</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">long</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">long</a></td>          <td class="paramname"><span class="paramname"><em>s</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structfbgemm__gpu_1_1rk__state.html">rk_state</a> *</td>          <td class="paramname"><span class="paramname"><em>state</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac4468c32ea6dc23cc2d7bded57a53119" name="ac4468c32ea6dc23cc2d7bded57a53119"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac4468c32ea6dc23cc2d7bded57a53119">&#9670;&#160;</a></span>rk_zipf()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">long</a> rk_zipf </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structfbgemm__gpu_1_1rk__state.html">rk_state</a> *</td>          <td class="paramname"><span class="paramname"><em>state</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>a</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="afad69123afbd407f6cd94913da47680e" name="afad69123afbd407f6cd94913da47680e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afad69123afbd407f6cd94913da47680e">&#9670;&#160;</a></span>round_down()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__host__</a> <a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> round_down </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a></td>          <td class="paramname"><span class="paramname"><em>a</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a></td>          <td class="paramname"><span class="paramname"><em>b</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a678327561759694192908f1f111424f7" name="a678327561759694192908f1f111424f7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a678327561759694192908f1f111424f7">&#9670;&#160;</a></span>segment_sum_csr_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> segment_sum_csr_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>batch_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>csr_seg</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8ae9711da44e5cd4a81f95a762b41180" name="a8ae9711da44e5cd4a81f95a762b41180"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8ae9711da44e5cd4a81f95a762b41180">&#9670;&#160;</a></span>segment_sum_csr_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> segment_sum_csr_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>batch_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>csr_seg</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a52eb62356a603284f18652bc195274ea" name="a52eb62356a603284f18652bc195274ea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a52eb62356a603284f18652bc195274ea">&#9670;&#160;</a></span>shfl_down_sync()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> shfl_down_sync </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a></td>          <td class="paramname"><span class="paramname"><em>val</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">unsigned</a></td>          <td class="paramname"><span class="paramname"><em>delta</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>width</em><span class="paramdefsep"> = </span><span class="paramdefval">kWarpSize</span>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">unsigned</a></td>          <td class="paramname"><span class="paramname"><em>shfl_sync_mask</em><span class="paramdefsep"> = </span><span class="paramdefval">kFullWarpMask</span></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9b3fcf49a28b6524c8db8c7c523e1798" name="a9b3fcf49a28b6524c8db8c7c523e1798"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9b3fcf49a28b6524c8db8c7c523e1798">&#9670;&#160;</a></span>shfl_sync()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> shfl_sync </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a></td>          <td class="paramname"><span class="paramname"><em>val</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>srcLane</em><span class="paramdefsep"> = </span><span class="paramdefval">0</span>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>width</em><span class="paramdefsep"> = </span><span class="paramdefval">kWarpSize</span>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">unsigned</a></td>          <td class="paramname"><span class="paramname"><em>shfl_sync_mask</em><span class="paramdefsep"> = </span><span class="paramdefval">kFullWarpMask</span></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a17b07e8668ed9b29a8b37d21a829723d" name="a17b07e8668ed9b29a8b37d21a829723d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a17b07e8668ed9b29a8b37d21a829723d">&#9670;&#160;</a></span>shfl_xor()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> shfl_xor </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a></td>          <td class="paramname"><span class="paramname"><em>val</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>laneMask</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>width</em><span class="paramdefsep"> = </span><span class="paramdefval">kWarpSize</span>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">unsigned</a></td>          <td class="paramname"><span class="paramname"><em>shfl_sync_mask</em><span class="paramdefsep"> = </span><span class="paramdefval">kFullWarpMask</span></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4ae09e478c1e9d6a414935fb6cf60f99" name="a4ae09e478c1e9d6a414935fb6cf60f99"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4ae09e478c1e9d6a414935fb6cf60f99">&#9670;&#160;</a></span>should_prune()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> should_prune </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_rows_kept</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>min_save_ratio</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa5ada0472a8306dea17df0d7d1d42abc" name="aa5ada0472a8306dea17df0d7d1d42abc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa5ada0472a8306dea17df0d7d1d42abc">&#9670;&#160;</a></span>splitmix64_stateless()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__host__</a> <a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a> splitmix64_stateless </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a></td>          <td class="paramname"><span class="paramname"><em>index</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6ac9f6d81bff1b8572a380dbe1af00fb" name="a6ac9f6d81bff1b8572a380dbe1af00fb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6ac9f6d81bff1b8572a380dbe1af00fb">&#9670;&#160;</a></span>stacked_jagged_1d_to_dense_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; stacked_jagged_1d_to_dense_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_per_key</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>max_lengths_per_key</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>padding_value</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="adf7f39b1a3dd7c2797fd11e740d6269f" name="adf7f39b1a3dd7c2797fd11e740d6269f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adf7f39b1a3dd7c2797fd11e740d6269f">&#9670;&#160;</a></span>stacked_jagged_1d_to_dense_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; stacked_jagged_1d_to_dense_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_per_key</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>max_lengths_per_key</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>padding_value</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a442efbf57b46780a07ac4759ac1866ee" name="a442efbf57b46780a07ac4759ac1866ee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a442efbf57b46780a07ac4759ac1866ee">&#9670;&#160;</a></span>stacked_jagged_2d_to_dense_backward_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> stacked_jagged_2d_to_dense_backward_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>B</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>D</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>total_L</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>grad_padded_values_per_key</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets_tensor_per_key</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_per_key</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab45e5e415a8929cbd0021eae37e1d881" name="ab45e5e415a8929cbd0021eae37e1d881"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab45e5e415a8929cbd0021eae37e1d881">&#9670;&#160;</a></span>stacked_jagged_2d_to_dense_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; stacked_jagged_2d_to_dense_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_per_key</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>max_lengths_per_key</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>padding_value</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5de1d5c177df840f2fa7ab0cdda2aa02" name="a5de1d5c177df840f2fa7ab0cdda2aa02"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5de1d5c177df840f2fa7ab0cdda2aa02">&#9670;&#160;</a></span>stacked_jagged_2d_to_dense_forward_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;, std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &gt; stacked_jagged_2d_to_dense_forward_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_per_key</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>max_lengths_per_key</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>padding_value</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aaac575e676d094aba1367e9eaf3489bc" name="aaac575e676d094aba1367e9eaf3489bc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaac575e676d094aba1367e9eaf3489bc">&#9670;&#160;</a></span>stacked_jagged_2d_to_dense_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; stacked_jagged_2d_to_dense_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>values</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a></td>          <td class="paramname"><span class="paramname"><em>lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>offset_per_key</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>max_lengths_per_key</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>padding_value</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="afe523b46c92c9009410f173e4ac434db" name="afe523b46c92c9009410f173e4ac434db"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afe523b46c92c9009410f173e4ac434db">&#9670;&#160;</a></span>stochastic_rounding_init()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> stochastic_rounding_init </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a></td>          <td class="paramname"><span class="paramname"><em>s0</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a></td>          <td class="paramname"><span class="paramname"><em>s1</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structfbgemm__gpu_1_1_stochastic_rounding_r_n_g_state.html">StochasticRoundingRNGState</a> *</td>          <td class="paramname"><span class="paramname"><em>state</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af0b19e6751891f43372768335cc3c468" name="af0b19e6751891f43372768335cc3c468"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af0b19e6751891f43372768335cc3c468">&#9670;&#160;</a></span>stochastic_rounding_rand4()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint4</a> stochastic_rounding_rand4 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structfbgemm__gpu_1_1_stochastic_rounding_r_n_g_state.html">StochasticRoundingRNGState</a> *</td>          <td class="paramname"><span class="paramname"><em>state</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a06c37bb32cb18b8846cf689db8ed94fb" name="a06c37bb32cb18b8846cf689db8ed94fb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a06c37bb32cb18b8846cf689db8ed94fb">&#9670;&#160;</a></span>stochastic_rounding_vector() <span class="overload">[1/5]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> stochastic_rounding_vector </td>
          <td>(</td>
          <td class="paramtype">at::Half *</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">Vec4T</a>&lt; at::Half &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structfbgemm__gpu_1_1_stochastic_rounding_r_n_g_state.html">StochasticRoundingRNGState</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>state</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7d41dbbfc3106c8fd5ff37cefbffbc38" name="a7d41dbbfc3106c8fd5ff37cefbffbc38"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7d41dbbfc3106c8fd5ff37cefbffbc38">&#9670;&#160;</a></span>stochastic_rounding_vector() <span class="overload">[2/5]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> stochastic_rounding_vector </td>
          <td>(</td>
          <td class="paramtype">at::Half *</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">Vec4T</a>&lt; <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structfbgemm__gpu_1_1_stochastic_rounding_r_n_g_state.html">StochasticRoundingRNGState</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>state</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aec7be9515265c4db67d205f8a3a39822" name="aec7be9515265c4db67d205f8a3a39822"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aec7be9515265c4db67d205f8a3a39822">&#9670;&#160;</a></span>stochastic_rounding_vector() <span class="overload">[3/5]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">dst_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">src_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> stochastic_rounding_vector </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">dst_t</a> *</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">Vec4T</a>&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">src_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structfbgemm__gpu_1_1_stochastic_rounding_r_n_g_state.html">StochasticRoundingRNGState</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>state</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a44ed26caaddd852d96ee453ea6cc2e07" name="a44ed26caaddd852d96ee453ea6cc2e07"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a44ed26caaddd852d96ee453ea6cc2e07">&#9670;&#160;</a></span>stochastic_rounding_vector() <span class="overload">[4/5]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> stochastic_rounding_vector </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a> *</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">Vec4T</a>&lt; at::Half &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structfbgemm__gpu_1_1_stochastic_rounding_r_n_g_state.html">StochasticRoundingRNGState</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>state</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"><em>qparams</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3313b5c0af7bd07d6e47253a24a27ce7" name="a3313b5c0af7bd07d6e47253a24a27ce7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3313b5c0af7bd07d6e47253a24a27ce7">&#9670;&#160;</a></span>stochastic_rounding_vector() <span class="overload">[5/5]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> stochastic_rounding_vector </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a> *</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">Vec4T</a>&lt; <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>value</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structfbgemm__gpu_1_1_stochastic_rounding_r_n_g_state.html">StochasticRoundingRNGState</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>state</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"><em>qparams</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8afc4c2510a6db3d420fc1025d3ac30b" name="a8afc4c2510a6db3d420fc1025d3ac30b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8afc4c2510a6db3d420fc1025d3ac30b">&#9670;&#160;</a></span>store_qparams_to_row() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">emb_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> store_qparams_to_row </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">emb_t</a> *</td>          <td class="paramname"><span class="paramname"><em>ptr</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"><em>qparams</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af4ec15f5d6826c016c46b5d7cae62d72" name="af4ec15f5d6826c016c46b5d7cae62d72"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af4ec15f5d6826c016c46b5d7cae62d72">&#9670;&#160;</a></span>store_qparams_to_row() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> store_qparams_to_row </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#a1360e7840ee58417b26bf9445f94c59d">uint8_t</a> *</td>          <td class="paramname"><span class="paramname"><em>ptr</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"><em>qparams</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa7f73354e0c76fbc0584c3250dadc98e" name="aa7f73354e0c76fbc0584c3250dadc98e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa7f73354e0c76fbc0584c3250dadc98e">&#9670;&#160;</a></span>sum_reduce_to_one_device()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> sum_reduce_to_one_device </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt;</td>          <td class="paramname"><span class="paramname"><em>input_tensors</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">at::Device</td>          <td class="paramname"><span class="paramname"><em>target_device</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab776b7b9076d17238d502b2746135ace" name="ab776b7b9076d17238d502b2746135ace"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab776b7b9076d17238d502b2746135ace">&#9670;&#160;</a></span>syncwarp()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> syncwarp </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a56da764643d07d366219d69333e6f9de" name="a56da764643d07d366219d69333e6f9de"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a56da764643d07d366219d69333e6f9de">&#9670;&#160;</a></span>tbe_input_combine_with_length_cpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; tbe_input_combine_with_length_cpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>indices_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>per_sample_weights</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae818a54243bd2ea4c0841088f07ff327" name="ae818a54243bd2ea4c0841088f07ff327"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae818a54243bd2ea4c0841088f07ff327">&#9670;&#160;</a></span>tbe_input_combine_with_length_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; tbe_input_combine_with_length_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>indices_addrs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>lengths_addrs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>per_sample_weights_addrs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>indices_is_long</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>lengths_is_long</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>indices_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>lengths_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_lists</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a></td>          <td class="paramname"><span class="paramname"><em>total_indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a></td>          <td class="paramname"><span class="paramname"><em>total_lengths</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_list_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> c10::DeviceIndex &amp;</td>          <td class="paramname"><span class="paramname"><em>device</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af7db32b23d955e760c7dfb4b29a13ca1" name="af7db32b23d955e760c7dfb4b29a13ca1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af7db32b23d955e760c7dfb4b29a13ca1">&#9670;&#160;</a></span>tbe_input_combine_with_length_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a>, <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; tbe_input_combine_with_length_gpu </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>indices_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>lengths_list</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> std::vector&lt; <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>per_sample_weights</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8145ebe65a5242bd7a3a15de0d69a70b" name="a8145ebe65a5242bd7a3a15de0d69a70b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8145ebe65a5242bd7a3a15de0d69a70b">&#9670;&#160;</a></span>thrust_find_qparams() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a> thrust_find_qparams </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">fbgemm_gpu::Vec4T</a>&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; *</td>          <td class="paramname"><span class="paramname"><em>input_row</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>D</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6c54f589eee05a58cebd4cf7cf8b1086" name="a6c54f589eee05a58cebd4cf7cf8b1086"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6c54f589eee05a58cebd4cf7cf8b1086">&#9670;&#160;</a></span>thrust_find_qparams() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a> thrust_find_qparams </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *</td>          <td class="paramname"><span class="paramname"><em>input_row</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>D</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9d1e20705b5c1c16dd554c81b3766b93" name="a9d1e20705b5c1c16dd554c81b3766b93"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9d1e20705b5c1c16dd554c81b3766b93">&#9670;&#160;</a></span>to_bfloat16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__nv_bfloat16</a> to_bfloat16 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a></td>          <td class="paramname"><span class="paramname"><em>v</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3f6b99cce95aa3d297e4b824e577d62d" name="a3f6b99cce95aa3d297e4b824e577d62d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3f6b99cce95aa3d297e4b824e577d62d">&#9670;&#160;</a></span>to_bfloat16_16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bfloat16_16</a> to_bfloat16_16 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float_16</a></td>          <td class="paramname"><span class="paramname"><em>v</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2b8a7fb1619f338df717ef075fe513e4" name="a2b8a7fb1619f338df717ef075fe513e4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2b8a7fb1619f338df717ef075fe513e4">&#9670;&#160;</a></span>to_bfloat16_2()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__nv_bfloat162</a> to_bfloat16_2 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"><em>v</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7d0d7114d05a683328a782804ef2bef9" name="a7d0d7114d05a683328a782804ef2bef9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7d0d7114d05a683328a782804ef2bef9">&#9670;&#160;</a></span>to_bfloat16_4()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bfloat16_4</a> to_bfloat16_4 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float4</a></td>          <td class="paramname"><span class="paramname"><em>v</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a74f150a063fed3144f6d99cde2d46069" name="a74f150a063fed3144f6d99cde2d46069"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a74f150a063fed3144f6d99cde2d46069">&#9670;&#160;</a></span>to_bfloat16_8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bfloat16_8</a> to_bfloat16_8 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float8</a></td>          <td class="paramname"><span class="paramname"><em>v</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3e13c4ba1e371f3bcabf7f6f74ac103e" name="a3e13c4ba1e371f3bcabf7f6f74ac103e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3e13c4ba1e371f3bcabf7f6f74ac103e">&#9670;&#160;</a></span>to_half()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half</a> to_half </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a></td>          <td class="paramname"><span class="paramname"><em>v</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a776872b9c8f667b7d05aea83e7287d5d" name="a776872b9c8f667b7d05aea83e7287d5d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a776872b9c8f667b7d05aea83e7287d5d">&#9670;&#160;</a></span>to_half16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">half16</a> to_half16 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float_16</a></td>          <td class="paramname"><span class="paramname"><em>v</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aaed7807ac8eef0fb786324d5935c4aca" name="aaed7807ac8eef0fb786324d5935c4aca"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaed7807ac8eef0fb786324d5935c4aca">&#9670;&#160;</a></span>to_half2()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__half2</a> to_half2 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a></td>          <td class="paramname"><span class="paramname"><em>v</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aee1f23de5e5847146cd821595d1978ae" name="aee1f23de5e5847146cd821595d1978ae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aee1f23de5e5847146cd821595d1978ae">&#9670;&#160;</a></span>to_half4()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="jagged__tensor__ops_2common_8cuh.html#ac6142811afa7f90ec76eae1bc05da82b">half4</a> to_half4 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float4</a></td>          <td class="paramname"><span class="paramname"><em>v</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a40088f5e88d0985b0c9b08808c40e1dd" name="a40088f5e88d0985b0c9b08808c40e1dd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a40088f5e88d0985b0c9b08808c40e1dd">&#9670;&#160;</a></span>to_half8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="jagged__tensor__ops_2common_8cuh.html#a93d30ba34e45e42dfd6b2547b1652cb6">half8</a> to_half8 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float8</a></td>          <td class="paramname"><span class="paramname"><em>v</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af53d2b0e9d8aeadd7d5094bd03ea25cc" name="af53d2b0e9d8aeadd7d5094bd03ea25cc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af53d2b0e9d8aeadd7d5094bd03ea25cc">&#9670;&#160;</a></span>TORCH_LIBRARY_FRAGMENT()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">TORCH_LIBRARY_FRAGMENT </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">fbgemm</a></td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">m</a></td>          <td class="paramname"><span class="paramname"></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a257a9d9e0a71b3a1299af6ef9c6c3a78" name="a257a9d9e0a71b3a1299af6ef9c6c3a78"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a257a9d9e0a71b3a1299af6ef9c6c3a78">&#9670;&#160;</a></span>TORCH_LIBRARY_IMPL()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">TORCH_LIBRARY_IMPL </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">fbgemm</a></td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">CUDA</a></td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">m</a></td>          <td class="paramname"><span class="paramname"></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a45142e19fe831c9d085bb097b7d946b2" name="a45142e19fe831c9d085bb097b7d946b2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a45142e19fe831c9d085bb097b7d946b2">&#9670;&#160;</a></span>trapz_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__inline__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> trapz_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *</td>          <td class="paramname"><span class="paramname"><em>output</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *</td>          <td class="paramname"><span class="paramname"><em>y</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *</td>          <td class="paramname"><span class="paramname"><em>x</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *</td>          <td class="paramname"><span class="paramname"><em>block_y</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *</td>          <td class="paramname"><span class="paramname"><em>block_x</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>num_entries_per_block</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a></td>          <td class="paramname"><span class="paramname"><em>block_id</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0ca17769ee2a4593b447a78e3d3fe429" name="a0ca17769ee2a4593b447a78e3d3fe429"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0ca17769ee2a4593b447a78e3d3fe429">&#9670;&#160;</a></span>unpack_segments_cuda_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">Length_T</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">Data_T</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> unpack_segments_cuda_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">Data_T</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>data_ptr</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">Length_T</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>lengths_ptr</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">Length_T</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>lengths_cum_sum</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">Length_T</a></td>          <td class="paramname"><span class="paramname"><em>max_length</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>num_seq</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>cell_size</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">Data_T</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a></td>          <td class="paramname"><span class="paramname"><em>out_ptr</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab2a027e4907e39797b913faa6b4e7270" name="ab2a027e4907e39797b913faa6b4e7270"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab2a027e4907e39797b913faa6b4e7270">&#9670;&#160;</a></span>vec4_acc()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">Vec4T</a>&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; vec4_acc </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">Vec4T</a>&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>lhs</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">Vec4T</a>&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>rhs</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a635410cfe229b71efb90199b72107f86" name="a635410cfe229b71efb90199b72107f86"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a635410cfe229b71efb90199b72107f86">&#9670;&#160;</a></span>vec4_max()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> vec4_max </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">fbgemm_gpu::Vec4T</a>&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>vec4</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae8a02a5464fb9156400157b45a947c58" name="ae8a02a5464fb9156400157b45a947c58"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae8a02a5464fb9156400157b45a947c58">&#9670;&#160;</a></span>vec4_min()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> vec4_min </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="structfbgemm__gpu_1_1_vec4_t.html">fbgemm_gpu::Vec4T</a>&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>vec4</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8c639f9912105390e4083332e01ecc57" name="a8c639f9912105390e4083332e01ecc57"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8c639f9912105390e4083332e01ecc57">&#9670;&#160;</a></span>vec_copy_with_implicit_type_cast()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">src_t</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">dst_t</a> , <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> VEC_WIDTH&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> vec_copy_with_implicit_type_cast </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">dst_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a></td>          <td class="paramname"><span class="paramname"><em>dst</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a></td>          <td class="paramname"><span class="paramname"><em>src_addr</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a></td>          <td class="paramname"><span class="paramname"><em>src_offset</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a></td>          <td class="paramname"><span class="paramname"><em>dst_offset</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a></td>          <td class="paramname"><span class="paramname"><em>src_bound</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a14fea42ceabd6ac042ad0d2fe5452762" name="a14fea42ceabd6ac042ad0d2fe5452762"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a14fea42ceabd6ac042ad0d2fe5452762">&#9670;&#160;</a></span>VEC_WIDTH() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#a3d08a36103c24a910afe1dbfa89e3060">indices_is_long</a> &amp;[<a class="el" href="#a96187c00fa81aaf4d6404cc915a5d7b7">is_long_idx</a>] <a class="el" href="#ace5ac8a87afdca35747d5c9bd8e33e73">is_long_mask</a> VEC_WIDTH </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">combined_indices</a></td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#a192b4d5303123cf4b57b1491cd42e36e">indices_addrs</a></td>          <td class="paramname"><span class="paramname">[list_id], </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#a119724f55ff744b85a20a870b5da4152">src_idx</a></td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#a43255cb54bbd791afb26a23af02acfec">indices_start</a>+</td>          <td class="paramname"><span class="paramname"><em>src_idx</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#ac7c7ecdd5162f325b65a6b5c5c6c40ca">indices_end</a> -</td>          <td class="paramname"><span class="paramname"><em>indices_start</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5aef253d76748f681c0e5d7e1620c8c9" name="a5aef253d76748f681c0e5d7e1620c8c9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5aef253d76748f681c0e5d7e1620c8c9">&#9670;&#160;</a></span>VEC_WIDTH() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ad8b8d41e5b0a7f0f67d18d46f561eef8">lengths_is_long</a> &amp;[<a class="el" href="#a96187c00fa81aaf4d6404cc915a5d7b7">is_long_idx</a>] <a class="el" href="#ace5ac8a87afdca35747d5c9bd8e33e73">is_long_mask</a> VEC_WIDTH </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#a176c2b8769558803ba0614bc04b7995f">combined_lengths</a></td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#a2b15eac55dd0239102e264b41febb49f">lengths_addrs</a></td>          <td class="paramname"><span class="paramname">[list_id], </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#a119724f55ff744b85a20a870b5da4152">src_idx</a></td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#a332f5a97c570870675755b52b91919d6">lengths_start</a>+</td>          <td class="paramname"><span class="paramname"><em>src_idx</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#a80de4cfcf0b435f1edbf9ba9cb999695">lengths_end</a> -</td>          <td class="paramname"><span class="paramname"><em>lengths_start</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a78a26de691da2f45a0e4ddaeda75009d" name="a78a26de691da2f45a0e4ddaeda75009d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a78a26de691da2f45a0e4ddaeda75009d">&#9670;&#160;</a></span>warp_find_qparams()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">float2</a> warp_find_qparams </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a></td>          <td class="paramname"><span class="paramname"><em>local_min</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a></td>          <td class="paramname"><span class="paramname"><em>local_max</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="acddba9c219634f979df1c8b943ac5e88" name="acddba9c219634f979df1c8b943ac5e88"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acddba9c219634f979df1c8b943ac5e88">&#9670;&#160;</a></span>warp_reduce_max()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> ReduceWidth = kWarpSize&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> warp_reduce_max </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a></td>          <td class="paramname"><span class="paramname"><em>val</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af554571b877e978f495835af1920f4fb" name="af554571b877e978f495835af1920f4fb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af554571b877e978f495835af1920f4fb">&#9670;&#160;</a></span>warp_reduce_min()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> ReduceWidth = kWarpSize&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> warp_reduce_min </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a></td>          <td class="paramname"><span class="paramname"><em>val</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9bd92b10074adc4fc58e4671a1d1d576" name="a9bd92b10074adc4fc58e4671a1d1d576"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9bd92b10074adc4fc58e4671a1d1d576">&#9670;&#160;</a></span>warpBitonicMergeLE16()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> K , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">V</a> , <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> L, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> Dir, <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">Comp</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">bool</a> IsBitonic&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__device__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> warpBitonicMergeLE16 </td>
          <td>(</td>
          <td class="paramtype">K &amp;</td>          <td class="paramname"><span class="paramname"><em>k</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">V</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>v</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="ad47dc8c3cfd941ea7a92b1cb677abf8e" name="ad47dc8c3cfd941ea7a92b1cb677abf8e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad47dc8c3cfd941ea7a92b1cb677abf8e">&#9670;&#160;</a></span>warpReduceAllSum()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">typename</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> , <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> ReduceWidth = kWarpSize&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="fbgemm__cuda__utils_8cuh.html#a8888b6e919f4a14975d3110a7425407d">DEVICE_INLINE</a> <a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a> warpReduceAllSum </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a></td>          <td class="paramname"><span class="paramname"><em>val</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">unsigned</a></td>          <td class="paramname"><span class="paramname"><em>shfl_sync_mask</em><span class="paramdefsep"> = </span><span class="paramdefval">kFullWarpMask</span></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Sums a register value across all warp threads. </p>

</div>
</div>
<a id="a44128eca539acfe55bdf792616e8b5b6" name="a44128eca539acfe55bdf792616e8b5b6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a44128eca539acfe55bdf792616e8b5b6">&#9670;&#160;</a></span>while()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">while </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ad8f5e19e19f12974c9713e920ec54331">left</a> !</td>          <td class="paramname"><span class="paramname"><span class="paramdefsep"> = </span><span class="paramdefval"><a class="el" href="#a2f54f8b71f0d765e2b7dbd9a8b9774ff">right</a></span></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a957e5dced6114b32a6d2e5e62011adbf" name="a957e5dced6114b32a6d2e5e62011adbf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a957e5dced6114b32a6d2e5e62011adbf">&#9670;&#160;</a></span>zipf_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ops__utils_8h.html#a29047de4dfe891435d8254535634ac1d">DLL_PUBLIC</a> <a class="el" href="#ae2016e9bbb2f470174708fc60cd7592f">Tensor</a> zipf_cuda </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>a</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>n</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>seed</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6991817ca1213e7cc0eba3bad689c03a" name="a6991817ca1213e7cc0eba3bad689c03a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6991817ca1213e7cc0eba3bad689c03a">&#9670;&#160;</a></span>zipf_kernel()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">void</a> zipf_kernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a></td>          <td class="paramname"><span class="paramname"><em>a</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>seed</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">at::PackedTensorAccessor64&lt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">long</a>, 1, at::RestrictPtrTraits &gt;</td>          <td class="paramname"><span class="paramname"><em>y</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="adb51b4975da6fe6cd1f6465b56b3b8ab" name="adb51b4975da6fe6cd1f6465b56b3b8ab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adb51b4975da6fe6cd1f6465b56b3b8ab">&#9670;&#160;</a></span>B</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> B</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab540864a8f4d5cfb95d168df6ff1ac51" name="ab540864a8f4d5cfb95d168df6ff1ac51"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab540864a8f4d5cfb95d168df6ff1ac51">&#9670;&#160;</a></span>b</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">auto</a> b = blockIdx.x * blockDim.x + threadIdx.x</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="add6df347839b36aa580f997fddaebf86" name="add6df347839b36aa580f997fddaebf86"></a>
<h2 class="memtitle"><span class="permalink"><a href="#add6df347839b36aa580f997fddaebf86">&#9670;&#160;</a></span>batch_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> batch_size</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="afba1f0bf46d421e1e2834949792290e0" name="afba1f0bf46d421e1e2834949792290e0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afba1f0bf46d421e1e2834949792290e0">&#9670;&#160;</a></span>batch_size_offsets</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> batch_size_offsets</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a34cfcac7aff478aac7e03c48a25b0447" name="a34cfcac7aff478aac7e03c48a25b0447"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a34cfcac7aff478aac7e03c48a25b0447">&#9670;&#160;</a></span>batch_size_per_feature</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> batch_size_per_feature</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7d3b870a22caa3968ca55fb89420e970" name="a7d3b870a22caa3968ca55fb89420e970"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7d3b870a22caa3968ca55fb89420e970">&#9670;&#160;</a></span>bin_boundaries</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">LogitType</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">SegmentValueType</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> bin_boundaries</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5306cfe92409d5d6525baade1714a78a" name="a5306cfe92409d5d6525baade1714a78a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5306cfe92409d5d6525baade1714a78a">&#9670;&#160;</a></span>bin_ctr_in_use_after</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> bin_ctr_in_use_after</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a505eb55e26cb1a63decb22880c93b9fd" name="a505eb55e26cb1a63decb22880c93b9fd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a505eb55e26cb1a63decb22880c93b9fd">&#9670;&#160;</a></span>bin_ctr_weight_value</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> bin_ctr_weight_value</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a24c7d1d72baa0efece963a4ed4db9c17" name="a24c7d1d72baa0efece963a4ed4db9c17"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a24c7d1d72baa0efece963a4ed4db9c17">&#9670;&#160;</a></span>bin_ids_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">LogitType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">SegmentValueType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">LogitType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> bin_ids_data</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div>
<div class="line">  <span class="keyword">const</span> <a class="code hl_variable" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> index = blockIdx.x * blockDim.x + threadIdx.x</div>
<div class="ttc" id="anamespacefbgemm__gpu_html_a112ef14feafbe22a3b70fd5ddcefcf99"><div class="ttname"><a href="#a112ef14feafbe22a3b70fd5ddcefcf99">fbgemm_gpu::int32_t</a></div><div class="ttdeci">indices_is_long &amp;[is_long_idx] is_long_mask int32_t</div><div class="ttdef"><b>Definition</b> input_combine.cu:73</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="ad09ae93c92bfe0fe061460cfe4acd611" name="ad09ae93c92bfe0fe061460cfe4acd611"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad09ae93c92bfe0fe061460cfe4acd611">&#9670;&#160;</a></span>bin_num_examples_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">LogitType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">SegmentValueType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> bin_num_examples_data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6cf3109a8de0f8ef7a818474a2fec845" name="a6cf3109a8de0f8ef7a818474a2fec845"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6cf3109a8de0f8ef7a818474a2fec845">&#9670;&#160;</a></span>bin_num_positives_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">LogitType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">SegmentValueType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> bin_num_positives_data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="acc943f4a5b9448babdf4b36ff9095dff" name="acc943f4a5b9448babdf4b36ff9095dff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acc943f4a5b9448babdf4b36ff9095dff">&#9670;&#160;</a></span>block_bucketize_pos_concat</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> block_bucketize_pos_concat</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7caa87d119b6ee26ae8fe2b66671215c" name="a7caa87d119b6ee26ae8fe2b66671215c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7caa87d119b6ee26ae8fe2b66671215c">&#9670;&#160;</a></span>block_bucketize_pos_offsets</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> block_bucketize_pos_offsets</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab2cdb48bca4ebe95f2cdeedea09f549f" name="ab2cdb48bca4ebe95f2cdeedea09f549f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab2cdb48bca4ebe95f2cdeedea09f549f">&#9670;&#160;</a></span>block_sizes_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> block_sizes_data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5a04eca282d6278fd065294a91065404" name="a5a04eca282d6278fd065294a91065404"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5a04eca282d6278fd065294a91065404">&#9670;&#160;</a></span>calibrated_prediction_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">LogitType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">SegmentValueType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">LogitType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> calibrated_prediction_data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a176c2b8769558803ba0614bc04b7995f" name="a176c2b8769558803ba0614bc04b7995f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a176c2b8769558803ba0614bc04b7995f">&#9670;&#160;</a></span>combined_lengths</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> combined_lengths</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a426e281c9c2dd29c0abe399f17ba8d6f" name="a426e281c9c2dd29c0abe399f17ba8d6f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a426e281c9c2dd29c0abe399f17ba8d6f">&#9670;&#160;</a></span>combined_weights</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> combined_weights</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0523b0079ced4e8a092ec1f3e5b5a193" name="a0523b0079ced4e8a092ec1f3e5b5a193"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0523b0079ced4e8a092ec1f3e5b5a193">&#9670;&#160;</a></span>csr_seg_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a>* csr_seg_data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa80c593013706e17927a0cedd1d6dbb0" name="aa80c593013706e17927a0cedd1d6dbb0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa80c593013706e17927a0cedd1d6dbb0">&#9670;&#160;</a></span>curr_bin_id</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> curr_bin_id = <a class="el" href="#ad8f5e19e19f12974c9713e920ec54331">left</a></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="afce91df3fd14c65d1d464b891004b1da" name="afce91df3fd14c65d1d464b891004b1da"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afce91df3fd14c65d1d464b891004b1da">&#9670;&#160;</a></span>curr_bin_num_examples</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">auto</a> curr_bin_num_examples = <a class="el" href="#ad09ae93c92bfe0fe061460cfe4acd611">bin_num_examples_data</a>[<a class="el" href="#a24c7d1d72baa0efece963a4ed4db9c17">bin_ids_data</a>[<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index</a>]]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5774000010ec731b390787b3b5f72868" name="a5774000010ec731b390787b3b5f72868"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5774000010ec731b390787b3b5f72868">&#9670;&#160;</a></span>curr_offset</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">auto</a> curr_offset = <a class="el" href="#a091bd2259a1e959d0052ad2fa399065f">segment_offsets_data</a>[<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index</a>]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a216663a22f5311b9ecf7c9bc64ee047d" name="a216663a22f5311b9ecf7c9bc64ee047d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a216663a22f5311b9ecf7c9bc64ee047d">&#9670;&#160;</a></span>curr_segment_value</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> curr_segment_value</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=</div>
<div class="line">      <a class="code hl_variable" href="#a2f93c0df9186a239cfd59505a464fc36">dense_segment_value_data</a>[index] &gt; <a class="code hl_variable" href="#a13adcdfa105d3fe5d68bfeae4df5f017">num_segments</a></div>
<div class="line">      ? 0</div>
<div class="line">      : std::max(0<a class="code hl_variable" href="gen__embedding__forward__split__unweighted__v2__kernel_8cu.html#a71a77dfc9561ca59031082dfd57dd5ca">L</a>, dense_segment_value_data[index] * num_bins)</div>
<div class="ttc" id="agen__embedding__forward__split__unweighted__v2__kernel_8cu_html_a71a77dfc9561ca59031082dfd57dd5ca"><div class="ttname"><a href="gen__embedding__forward__split__unweighted__v2__kernel_8cu.html#a71a77dfc9561ca59031082dfd57dd5ca">L</a></div><div class="ttdeci">uint32_t L</div><div class="ttdef"><b>Definition</b> gen_embedding_forward_split_unweighted_v2_kernel.cu:746</div></div>
<div class="ttc" id="anamespacefbgemm__gpu_html_a13adcdfa105d3fe5d68bfeae4df5f017"><div class="ttname"><a href="#a13adcdfa105d3fe5d68bfeae4df5f017">fbgemm_gpu::num_segments</a></div><div class="ttdeci">__global__ const int64_t const int64_t num_segments</div><div class="ttdef"><b>Definition</b> histogram_binning_calibration_ops.cu:135</div></div>
<div class="ttc" id="anamespacefbgemm__gpu_html_a2f93c0df9186a239cfd59505a464fc36"><div class="ttname"><a href="#a2f93c0df9186a239cfd59505a464fc36">fbgemm_gpu::dense_segment_value_data</a></div><div class="ttdeci">__global__ const ValueType *const const OffsetType *const ValueType *const dense_segment_value_data</div><div class="ttdef"><b>Definition</b> histogram_binning_calibration_ops.cu:113</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a2f93c0df9186a239cfd59505a464fc36" name="a2f93c0df9186a239cfd59505a464fc36"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2f93c0df9186a239cfd59505a464fc36">&#9670;&#160;</a></span>dense_segment_value_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">LogitType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">SegmentValueType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> dense_segment_value_data</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div>
<div class="line">  <span class="keyword">const</span> <a class="code hl_variable" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> index = blockIdx.x * blockDim.x + threadIdx.x</div>
</div><!-- fragment -->
</div>
</div>
<a id="a0544c3fe466e421738dae463968b70ba" name="a0544c3fe466e421738dae463968b70ba"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0544c3fe466e421738dae463968b70ba">&#9670;&#160;</a></span>else</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">else</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div>
<div class="line">    <a class="code hl_variable" href="#a5a04eca282d6278fd065294a91065404">calibrated_prediction_data</a>[index] = <a class="code hl_variable" href="#a7b13aa0c4501d0593484a73afe8786c2">uncalibrated</a></div>
<div class="ttc" id="anamespacefbgemm__gpu_html_a5a04eca282d6278fd065294a91065404"><div class="ttname"><a href="#a5a04eca282d6278fd065294a91065404">fbgemm_gpu::calibrated_prediction_data</a></div><div class="ttdeci">__global__ const int64_t const double const double const int64_t const double const T *const const double *const const double *const T *const calibrated_prediction_data</div><div class="ttdef"><b>Definition</b> histogram_binning_calibration_ops.cu:31</div></div>
<div class="ttc" id="anamespacefbgemm__gpu_html_a7b13aa0c4501d0593484a73afe8786c2"><div class="ttname"><a href="#a7b13aa0c4501d0593484a73afe8786c2">fbgemm_gpu::uncalibrated</a></div><div class="ttdeci">const double uncalibrated</div><div class="ttdef"><b>Definition</b> histogram_binning_calibration_ops.cu:39</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a8d2f3cd432a3bf2de49086fb33ef71cb" name="a8d2f3cd432a3bf2de49086fb33ef71cb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8d2f3cd432a3bf2de49086fb33ef71cb">&#9670;&#160;</a></span>fd_num_warps_per_list</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_fixed_divisor.html">FixedDivisor</a> fd_num_warps_per_list</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div>
<div class="line">  <span class="keyword">const</span> <span class="keyword">auto</span> <a class="code hl_variable" href="gen__embedding__forward__split__unweighted__v2__kernel_8cu.html#a53d1bd761ca2346d5b9bcc60d1c43be6">global_warp_id</a> = blockIdx.x * blockDim.y + threadIdx.y</div>
<div class="ttc" id="agen__embedding__forward__split__unweighted__v2__kernel_8cu_html_a53d1bd761ca2346d5b9bcc60d1c43be6"><div class="ttname"><a href="gen__embedding__forward__split__unweighted__v2__kernel_8cu.html#a53d1bd761ca2346d5b9bcc60d1c43be6">global_warp_id</a></div><div class="ttdeci">const int32_t global_warp_id</div><div class="ttdef"><b>Definition</b> gen_embedding_forward_split_unweighted_v2_kernel.cu:678</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a2a24c1ec3db68358edcac4561d38a0d1" name="a2a24c1ec3db68358edcac4561d38a0d1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2a24c1ec3db68358edcac4561d38a0d1">&#9670;&#160;</a></span>grad_output</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> grad_output</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae1519b6699f9dca1080e9230f3d95245" name="ae1519b6699f9dca1080e9230f3d95245"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae1519b6699f9dca1080e9230f3d95245">&#9670;&#160;</a></span>grad_sum</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::acc_type&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>, <a class="el" href="gen__embedding__forward__split__unweighted__kernel_8cu.html#acc5baa8672e7ddf3cefb150e4660d86a">true</a>&gt; grad_sum = 0.0</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5b80925f60fbc21517ec3a2e137b78bd" name="a5b80925f60fbc21517ec3a2e137b78bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5b80925f60fbc21517ec3a2e137b78bd">&#9670;&#160;</a></span>grad_weight</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">grad_weight[<a class="el" href="#a4e34aefb3cc5403a07c020131077100a">n</a> *<a class="el" href="#aba761028ac72c20c7defaef09de61d95">sum_E</a>+<a class="el" href="#a242d5a911279d9ad2128346af039383f">table_offset</a>+<a class="el" href="#a9d7e9481c420588a334b2aedac0f5af4">idx</a>] = <a class="el" href="#ae1519b6699f9dca1080e9230f3d95245">grad_sum</a></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0d76fd54f347327376ed8ba28ff66bfc" name="a0d76fd54f347327376ed8ba28ff66bfc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0d76fd54f347327376ed8ba28ff66bfc">&#9670;&#160;</a></span>GROUP_INDEX_SELECT_COLS_PER_WARP</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">constexpr</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> GROUP_INDEX_SELECT_COLS_PER_WARP</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=</div>
<div class="line">    <a class="code hl_variable" href="#a693bb0de52991f987fe81dc61c750403">GROUP_INDEX_SELECT_UNROLL_FACTOR</a> * <a class="code hl_variable" href="gen__embedding__optimizer__rowwise__adagrad__split__kernel_8cu.html#a4a63994c436795f993c09c5626acfb05">kWarpSize</a></div>
<div class="ttc" id="agen__embedding__optimizer__rowwise__adagrad__split__kernel_8cu_html_a4a63994c436795f993c09c5626acfb05"><div class="ttname"><a href="gen__embedding__optimizer__rowwise__adagrad__split__kernel_8cu.html#a4a63994c436795f993c09c5626acfb05">kWarpSize</a></div><div class="ttdeci">template __global__ kWarpSize</div><div class="ttdef"><b>Definition</b> gen_embedding_optimizer_rowwise_adagrad_split_kernel.cu:1952</div></div>
<div class="ttc" id="anamespacefbgemm__gpu_html_a693bb0de52991f987fe81dc61c750403"><div class="ttname"><a href="#a693bb0de52991f987fe81dc61c750403">fbgemm_gpu::GROUP_INDEX_SELECT_UNROLL_FACTOR</a></div><div class="ttdeci">constexpr int GROUP_INDEX_SELECT_UNROLL_FACTOR</div><div class="ttdef"><b>Definition</b> sparse_group_index.cu:16</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a696ffb981f6c273f77aae0cf102b1f6b" name="a696ffb981f6c273f77aae0cf102b1f6b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a696ffb981f6c273f77aae0cf102b1f6b">&#9670;&#160;</a></span>GROUP_INDEX_SELECT_LOG_COLS_PER_WARP</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">constexpr</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> GROUP_INDEX_SELECT_LOG_COLS_PER_WARP</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=</div>
<div class="line">    <a class="code hl_struct" href="structlog2__calc.html">log2_calc&lt;GROUP_INDEX_SELECT_COLS_PER_WARP&gt;::value</a></div>
<div class="ttc" id="astructlog2__calc_html"><div class="ttname"><a href="structlog2__calc.html">log2_calc</a></div><div class="ttdef"><b>Definition</b> sparse_ops_utils.h:535</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a693bb0de52991f987fe81dc61c750403" name="a693bb0de52991f987fe81dc61c750403"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a693bb0de52991f987fe81dc61c750403">&#9670;&#160;</a></span>GROUP_INDEX_SELECT_UNROLL_FACTOR</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">constexpr</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> GROUP_INDEX_SELECT_UNROLL_FACTOR = 1</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="af0a2fbea18e37c564b3cada4172d96ff" name="af0a2fbea18e37c564b3cada4172d96ff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af0a2fbea18e37c564b3cada4172d96ff">&#9670;&#160;</a></span>group_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> group_size</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div>
<div class="line">  <span class="keyword">const</span> <span class="keyword">auto</span> total_num_warps = <a class="code hl_variable" href="#aecfb31f7c9583dd16ed7463ad8328db4">warp_offsets_group</a>[<a class="code hl_variable" href="#af0a2fbea18e37c564b3cada4172d96ff">group_size</a>]</div>
<div class="ttc" id="anamespacefbgemm__gpu_html_aecfb31f7c9583dd16ed7463ad8328db4"><div class="ttname"><a href="#aecfb31f7c9583dd16ed7463ad8328db4">fbgemm_gpu::warp_offsets_group</a></div><div class="ttdeci">__global__ const int64_t const int64_t const int64_t * warp_offsets_group</div><div class="ttdef"><b>Definition</b> sparse_group_index.cu:41</div></div>
<div class="ttc" id="anamespacefbgemm__gpu_html_af0a2fbea18e37c564b3cada4172d96ff"><div class="ttname"><a href="#af0a2fbea18e37c564b3cada4172d96ff">fbgemm_gpu::group_size</a></div><div class="ttdeci">__global__ const int64_t const int64_t const int64_t const int32_t const int64_t const int64_t group_size</div><div class="ttdef"><b>Definition</b> sparse_group_index.cu:44</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a9d7e9481c420588a334b2aedac0f5af4" name="a9d7e9481c420588a334b2aedac0f5af4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9d7e9481c420588a334b2aedac0f5af4">&#9670;&#160;</a></span>idx</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> idx = <a class="el" href="#a177d197b75db75ee70711f48a28e1524">linear_index</a> - <a class="el" href="#a242d5a911279d9ad2128346af039383f">table_offset</a></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aabefe307b5a16f2e2d2c5cc6c74719b6" name="aabefe307b5a16f2e2d2c5cc6c74719b6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aabefe307b5a16f2e2d2c5cc6c74719b6">&#9670;&#160;</a></span>indices</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">indices_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> indices</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a192b4d5303123cf4b57b1491cd42e36e" name="a192b4d5303123cf4b57b1491cd42e36e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a192b4d5303123cf4b57b1491cd42e36e">&#9670;&#160;</a></span>indices_addrs</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> indices_addrs</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="acb7eb1c50758e407a638a81723961f56" name="acb7eb1c50758e407a638a81723961f56"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acb7eb1c50758e407a638a81723961f56">&#9670;&#160;</a></span>indices_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> indices_data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac7c7ecdd5162f325b65a6b5c5c6c40ca" name="ac7c7ecdd5162f325b65a6b5c5c6c40ca"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac7c7ecdd5162f325b65a6b5c5c6c40ca">&#9670;&#160;</a></span>indices_end</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> indices_end = <a class="el" href="#af03fdab0a39bf13b8ec4de336253b8aa">indices_offsets</a>[<a class="el" href="#a07403af74afe12cdace7e1ec4ff38e72">list_id</a> + 1]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3d08a36103c24a910afe1dbfa89e3060" name="a3d08a36103c24a910afe1dbfa89e3060"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3d08a36103c24a910afe1dbfa89e3060">&#9670;&#160;</a></span>indices_is_long</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> indices_is_long</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af03fdab0a39bf13b8ec4de336253b8aa" name="af03fdab0a39bf13b8ec4de336253b8aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af03fdab0a39bf13b8ec4de336253b8aa">&#9670;&#160;</a></span>indices_offsets</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> indices_offsets</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7e26138f974174b1cd94f35321fef17d" name="a7e26138f974174b1cd94f35321fef17d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7e26138f974174b1cd94f35321fef17d">&#9670;&#160;</a></span>indices_ptrs</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a>* indices_ptrs</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a43255cb54bbd791afb26a23af02acfec" name="a43255cb54bbd791afb26a23af02acfec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a43255cb54bbd791afb26a23af02acfec">&#9670;&#160;</a></span>indices_start</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> indices_start = <a class="el" href="#af03fdab0a39bf13b8ec4de336253b8aa">indices_offsets</a>[<a class="el" href="#a07403af74afe12cdace7e1ec4ff38e72">list_id</a>]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af069d2baffbfbe0b8aae6aea56d31e86" name="af069d2baffbfbe0b8aae6aea56d31e86"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af069d2baffbfbe0b8aae6aea56d31e86">&#9670;&#160;</a></span>indices_to_lb</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> indices_to_lb</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div>
<div class="line">  <span class="keyword">using </span>uindex_t = std::make_unsigned_t&lt;index_t&gt;</div>
</div><!-- fragment -->
</div>
</div>
<a id="aa494944475a226c613cdd03931ba061d" name="aa494944475a226c613cdd03931ba061d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa494944475a226c613cdd03931ba061d">&#9670;&#160;</a></span>info</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">auto</a> info</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=</div>
<div class="line">      <span class="keyword">reinterpret_cast&lt;</span><span class="keyword">const </span><a class="code hl_variable" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a>*<span class="keyword">&gt;</span>(<a class="code hl_variable" href="#a89d9dff100cfa1f022fcfbf61e2500cc">sorted_infos</a>)[segment_start]</div>
<div class="ttc" id="anamespacefbgemm__gpu_html_a89d9dff100cfa1f022fcfbf61e2500cc"><div class="ttname"><a href="#a89d9dff100cfa1f022fcfbf61e2500cc">fbgemm_gpu::sorted_infos</a></div><div class="ttdeci">__global__ const int32_t const int32_t const scalar_t *__restrict__ const index_t *__restrict__ scalar_t *__restrict__ const at::PackedTensorAccessor32&lt; index_t, 1, at::RestrictPtrTraits &gt; const int32_t *__restrict__ const int32_t *__restrict__ sorted_infos</div><div class="ttdef"><b>Definition</b> sparse_batched_unary_embeddings.cu:126</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="acdf5304fcbfbc6f85054b8c45407691f" name="acdf5304fcbfbc6f85054b8c45407691f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acdf5304fcbfbc6f85054b8c45407691f">&#9670;&#160;</a></span>info_B_mask</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::PackedTensorAccessor32&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>, 1, at::RestrictPtrTraits&gt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> info_B_mask</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div>
<div class="line">  <a class="code hl_variable" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> run_id = blockIdx.x * blockDim.x + threadIdx.x</div>
</div><!-- fragment -->
</div>
</div>
<a id="a4558e86e39e5639ec4665246b76df453" name="a4558e86e39e5639ec4665246b76df453"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4558e86e39e5639ec4665246b76df453">&#9670;&#160;</a></span>info_B_num_bits</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::PackedTensorAccessor32&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>, 1, at::RestrictPtrTraits&gt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> info_B_num_bits</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a88aea1b3f2194509bb8bb7105e0d6553" name="a88aea1b3f2194509bb8bb7105e0d6553"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a88aea1b3f2194509bb8bb7105e0d6553">&#9670;&#160;</a></span>input_offsets</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">indices_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">weights_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> input_offsets</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5549affa3c112bf0c71b0e2323eb0c14" name="a5549affa3c112bf0c71b0e2323eb0c14"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5549affa3c112bf0c71b0e2323eb0c14">&#9670;&#160;</a></span>input_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> input_size</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div>
<div class="line">  <span class="keyword">const</span> <span class="keywordtype">int</span> i = blockDim.x * blockIdx.x + threadIdx.x</div>
</div><!-- fragment -->
</div>
</div>
<a id="a112ef14feafbe22a3b70fd5ddcefcf99" name="a112ef14feafbe22a3b70fd5ddcefcf99"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a112ef14feafbe22a3b70fd5ddcefcf99">&#9670;&#160;</a></span>int32_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ad8b8d41e5b0a7f0f67d18d46f561eef8">lengths_is_long</a>&amp; [<a class="el" href="#a96187c00fa81aaf4d6404cc915a5d7b7">is_long_idx</a>] <a class="el" href="#ace5ac8a87afdca35747d5c9bd8e33e73">is_long_mask</a> int32_t</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a96187c00fa81aaf4d6404cc915a5d7b7" name="a96187c00fa81aaf4d6404cc915a5d7b7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a96187c00fa81aaf4d6404cc915a5d7b7">&#9670;&#160;</a></span>is_long_idx</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> is_long_idx = <a class="el" href="#a07403af74afe12cdace7e1ec4ff38e72">list_id</a> / <a class="el" href="#ab9c0e24618d9ec723a7fcc8653c0dd59">IS_LONG_NUM_BITS</a></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ace5ac8a87afdca35747d5c9bd8e33e73" name="ace5ac8a87afdca35747d5c9bd8e33e73"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ace5ac8a87afdca35747d5c9bd8e33e73">&#9670;&#160;</a></span>is_long_mask</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> is_long_mask = 1<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">u</a> &lt;&lt; (<a class="el" href="#a07403af74afe12cdace7e1ec4ff38e72">list_id</a> % <a class="el" href="#ab9c0e24618d9ec723a7fcc8653c0dd59">IS_LONG_NUM_BITS</a>)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab9c0e24618d9ec723a7fcc8653c0dd59" name="ab9c0e24618d9ec723a7fcc8653c0dd59"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab9c0e24618d9ec723a7fcc8653c0dd59">&#9670;&#160;</a></span>IS_LONG_NUM_BITS</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">constexpr</a> <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> IS_LONG_NUM_BITS = 32</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a377d2c34d1f3becb19a91ea600e05321" name="a377d2c34d1f3becb19a91ea600e05321"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a377d2c34d1f3becb19a91ea600e05321">&#9670;&#160;</a></span>kCacheLocationMissing</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">constexpr</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> kCacheLocationMissing = -1</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a71a77dfc9561ca59031082dfd57dd5ca" name="a71a77dfc9561ca59031082dfd57dd5ca"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a71a77dfc9561ca59031082dfd57dd5ca">&#9670;&#160;</a></span>L</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> L = <a class="el" href="#ac7c7ecdd5162f325b65a6b5c5c6c40ca">indices_end</a> - <a class="el" href="#a43255cb54bbd791afb26a23af02acfec">indices_start</a></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad8f5e19e19f12974c9713e920ec54331" name="ad8f5e19e19f12974c9713e920ec54331"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad8f5e19e19f12974c9713e920ec54331">&#9670;&#160;</a></span>left</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> left = 0</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a10c64e822d3634da34b9bf1f0c38d757" name="a10c64e822d3634da34b9bf1f0c38d757"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a10c64e822d3634da34b9bf1f0c38d757">&#9670;&#160;</a></span>length_to_feature_idx</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> length_to_feature_idx</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div>
<div class="line">  <span class="keyword">const</span> <span class="keyword">auto</span> <a class="code hl_variable" href="embedding__forward__split__kernel__template_8cu.html#a1a5ea7b1f265584db8df7ef65698c2dd">b_t</a> = blockIdx.x * blockDim.x + threadIdx.x</div>
<div class="ttc" id="aembedding__forward__split__kernel__template_8cu_html_a1a5ea7b1f265584db8df7ef65698c2dd"><div class="ttname"><a href="embedding__forward__split__kernel__template_8cu.html#a1a5ea7b1f265584db8df7ef65698c2dd">b_t</a></div><div class="ttdeci">int32_t b_t</div><div class="ttdef"><b>Definition</b> embedding_forward_split_kernel_template.cu:153</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="acbebb5d71fe9389f7b919325112c1548" name="acbebb5d71fe9389f7b919325112c1548"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acbebb5d71fe9389f7b919325112c1548">&#9670;&#160;</a></span>lengths</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> lengths</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2b15eac55dd0239102e264b41febb49f" name="a2b15eac55dd0239102e264b41febb49f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2b15eac55dd0239102e264b41febb49f">&#9670;&#160;</a></span>lengths_addrs</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> lengths_addrs</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a80de4cfcf0b435f1edbf9ba9cb999695" name="a80de4cfcf0b435f1edbf9ba9cb999695"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a80de4cfcf0b435f1edbf9ba9cb999695">&#9670;&#160;</a></span>lengths_end</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">auto</a> lengths_end = <a class="el" href="#ab245b3e7b831d8e003a353250359843d">lengths_offsets</a>[<a class="el" href="#a07403af74afe12cdace7e1ec4ff38e72">list_id</a> + 1]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad8b8d41e5b0a7f0f67d18d46f561eef8" name="ad8b8d41e5b0a7f0f67d18d46f561eef8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad8b8d41e5b0a7f0f67d18d46f561eef8">&#9670;&#160;</a></span>lengths_is_long</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> lengths_is_long</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab245b3e7b831d8e003a353250359843d" name="ab245b3e7b831d8e003a353250359843d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab245b3e7b831d8e003a353250359843d">&#9670;&#160;</a></span>lengths_offsets</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> lengths_offsets</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a332f5a97c570870675755b52b91919d6" name="a332f5a97c570870675755b52b91919d6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a332f5a97c570870675755b52b91919d6">&#9670;&#160;</a></span>lengths_start</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">auto</a> lengths_start = <a class="el" href="#ab245b3e7b831d8e003a353250359843d">lengths_offsets</a>[<a class="el" href="#a07403af74afe12cdace7e1ec4ff38e72">list_id</a>]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a177d197b75db75ee70711f48a28e1524" name="a177d197b75db75ee70711f48a28e1524"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a177d197b75db75ee70711f48a28e1524">&#9670;&#160;</a></span>linear_index</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> linear_index = <a class="el" href="#a30d761b81b0e05f95a7a118a17d6c4a2">sorted_linear_indices_run</a>[<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">run_id</a>]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a07403af74afe12cdace7e1ec4ff38e72" name="a07403af74afe12cdace7e1ec4ff38e72"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a07403af74afe12cdace7e1ec4ff38e72">&#9670;&#160;</a></span>list_id</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> list_id</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a666f6d4fb27d254047edf38944a98e81" name="a666f6d4fb27d254047edf38944a98e81"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a666f6d4fb27d254047edf38944a98e81">&#9670;&#160;</a></span>logit_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">LogitType</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> logit_data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af75fe947c4a976895a9fb2c7501439b1" name="af75fe947c4a976895a9fb2c7501439b1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af75fe947c4a976895a9fb2c7501439b1">&#9670;&#160;</a></span>MAX_ELEMENTS_PER_THREAD</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">constexpr</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> MAX_ELEMENTS_PER_THREAD = 4</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a726d1405842124631d2e9543e6abfd70" name="a726d1405842124631d2e9543e6abfd70"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a726d1405842124631d2e9543e6abfd70">&#9670;&#160;</a></span>my_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> my_size</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4e34aefb3cc5403a07c020131077100a" name="a4e34aefb3cc5403a07c020131077100a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4e34aefb3cc5403a07c020131077100a">&#9670;&#160;</a></span>n</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> n = blockIdx.z</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a12ee89697c142bf6626fc9773b3784ce" name="a12ee89697c142bf6626fc9773b3784ce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a12ee89697c142bf6626fc9773b3784ce">&#9670;&#160;</a></span>new_indices_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> new_indices_data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2590465d158f637aa65cb705ceff155d" name="a2590465d158f637aa65cb705ceff155d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2590465d158f637aa65cb705ceff155d">&#9670;&#160;</a></span>new_lengths_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> new_lengths_data</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div>
<div class="line">  <span class="keyword">using </span>uscalar_t = std::make_unsigned_t&lt;scalar_t&gt;</div>
</div><!-- fragment -->
</div>
</div>
<a id="ab36576a24b49bfce1e9b6ff66a37ebe1" name="ab36576a24b49bfce1e9b6ff66a37ebe1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab36576a24b49bfce1e9b6ff66a37ebe1">&#9670;&#160;</a></span>new_offsets_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> new_offsets_data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1543754093f5b3f003f28b6120d4508f" name="a1543754093f5b3f003f28b6120d4508f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1543754093f5b3f003f28b6120d4508f">&#9670;&#160;</a></span>new_pos_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> new_pos_data</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div>
<div class="line">  <span class="keyword">using </span>uindex_t = std::make_unsigned_t&lt;index_t&gt;</div>
</div><!-- fragment -->
</div>
</div>
<a id="a2aaf9a58df0549a13d01ab53cd60ddff" name="a2aaf9a58df0549a13d01ab53cd60ddff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2aaf9a58df0549a13d01ab53cd60ddff">&#9670;&#160;</a></span>new_weights_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> new_weights_data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac588c52c993fa6f169cb54d418ea584c" name="ac588c52c993fa6f169cb54d418ea584c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac588c52c993fa6f169cb54d418ea584c">&#9670;&#160;</a></span>next_offset</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">auto</a> next_offset = <a class="el" href="#a091bd2259a1e959d0052ad2fa399065f">segment_offsets_data</a>[<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index</a> + 1]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a711d3a0cadc94f73da860c1ffd01e1b2" name="a711d3a0cadc94f73da860c1ffd01e1b2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a711d3a0cadc94f73da860c1ffd01e1b2">&#9670;&#160;</a></span>NUM_ARGS</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">constexpr</a> <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> NUM_ARGS = 7</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="aff8ee4d321b4a815868fe53b25b8fe6b" name="aff8ee4d321b4a815868fe53b25b8fe6b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aff8ee4d321b4a815868fe53b25b8fe6b">&#9670;&#160;</a></span>num_bins</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> num_bins</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2f734f38c3537666ae53e906e65c1a6e" name="a2f734f38c3537666ae53e906e65c1a6e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2f734f38c3537666ae53e906e65c1a6e">&#9670;&#160;</a></span>num_cols_group</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* num_cols_group</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a447e5ea8dc79992a05131d8803d2bf7e" name="a447e5ea8dc79992a05131d8803d2bf7e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a447e5ea8dc79992a05131d8803d2bf7e">&#9670;&#160;</a></span>num_lists</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a> num_lists</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a13adcdfa105d3fe5d68bfeae4df5f017" name="a13adcdfa105d3fe5d68bfeae4df5f017"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a13adcdfa105d3fe5d68bfeae4df5f017">&#9670;&#160;</a></span>num_segments</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> num_segments</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aeb2ce03cab381b1393d4c7c355ef2286" name="aeb2ce03cab381b1393d4c7c355ef2286"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeb2ce03cab381b1393d4c7c355ef2286">&#9670;&#160;</a></span>num_work_rows</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> num_work_rows</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aad33dfd216d9ea27b505a304ca3e32da" name="aad33dfd216d9ea27b505a304ca3e32da"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aad33dfd216d9ea27b505a304ca3e32da">&#9670;&#160;</a></span>offsets</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> offsets</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a66f41f5ea495c26af7e2007fe0a28edc" name="a66f41f5ea495c26af7e2007fe0a28edc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a66f41f5ea495c26af7e2007fe0a28edc">&#9670;&#160;</a></span>offsets_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> offsets_data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae662e9187ce6364e1668803dfbf7e7d0" name="ae662e9187ce6364e1668803dfbf7e7d0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae662e9187ce6364e1668803dfbf7e7d0">&#9670;&#160;</a></span>output</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> * output</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div>
<div class="line">  index_t <a class="code hl_variable" href="#aba761028ac72c20c7defaef09de61d95">sum_E</a> = <a class="code hl_variable" href="#a114a2ddecfbdbb209bc791977fcb1c0e">table_offsets</a>[<a class="code hl_variable" href="gen__embedding__forward__split__unweighted__codegen__cuda_8cu.html#a2ee4b3e799d56c4d34c87190c37a7a64">T</a>]</div>
<div class="ttc" id="agen__embedding__forward__split__unweighted__codegen__cuda_8cu_html_a2ee4b3e799d56c4d34c87190c37a7a64"><div class="ttname"><a href="gen__embedding__forward__split__unweighted__codegen__cuda_8cu.html#a2ee4b3e799d56c4d34c87190c37a7a64">T</a></div><div class="ttdeci">__launch_bounds__(kForwardMaxThreads) __global__ void split_embedding_nobag_codegen_forward_unweighted_small_kernel(const pta const emb_t *__restrict__ const const cache_t *__restrict__ const const int32_t *__restrict__ const const uint32_t const uint32_t T</div><div class="ttdef"><b>Definition</b> gen_embedding_forward_split_unweighted_codegen_cuda.cu:62</div></div>
<div class="ttc" id="anamespacefbgemm__gpu_html_a114a2ddecfbdbb209bc791977fcb1c0e"><div class="ttname"><a href="#a114a2ddecfbdbb209bc791977fcb1c0e">fbgemm_gpu::table_offsets</a></div><div class="ttdeci">__global__ const int32_t const int32_t const scalar_t *__restrict__ const index_t *__restrict__ table_offsets</div><div class="ttdef"><b>Definition</b> sparse_batched_unary_embeddings.cu:24</div></div>
<div class="ttc" id="anamespacefbgemm__gpu_html_aba761028ac72c20c7defaef09de61d95"><div class="ttname"><a href="#aba761028ac72c20c7defaef09de61d95">fbgemm_gpu::sum_E</a></div><div class="ttdeci">index_t sum_E</div><div class="ttdef"><b>Definition</b> sparse_batched_unary_embeddings.cu:166</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a783fcd132908afcc711d1a7fb2cb51a7" name="a783fcd132908afcc711d1a7fb2cb51a7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a783fcd132908afcc711d1a7fb2cb51a7">&#9670;&#160;</a></span>output_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* output_data</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div>
<div class="line">  <span class="keyword">typedef</span> <a class="code hl_define" href="cub__namespace__postfix_8cuh.html#a12567f2486c4686871a5330dbd8e9bb4">FBGEMM_GPU_CUB_NS_PREFIX</a> cub::BlockReduce&lt;scalar_t, 256&gt; BlockReduce</div>
<div class="ttc" id="acub__namespace__postfix_8cuh_html_a12567f2486c4686871a5330dbd8e9bb4"><div class="ttname"><a href="cub__namespace__postfix_8cuh.html#a12567f2486c4686871a5330dbd8e9bb4">FBGEMM_GPU_CUB_NS_PREFIX</a></div><div class="ttdeci">#define FBGEMM_GPU_CUB_NS_PREFIX</div><div class="ttdef"><b>Definition</b> cub_namespace_postfix.cuh:34</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a72822c0cc98165904fdc0110344ecdd5" name="a72822c0cc98165904fdc0110344ecdd5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a72822c0cc98165904fdc0110344ecdd5">&#9670;&#160;</a></span>output_offsets</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">indices_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">weights_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> output_offsets</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa80e8b11fe8b3b1a619f329aeb089f54" name="aa80e8b11fe8b3b1a619f329aeb089f54"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa80e8b11fe8b3b1a619f329aeb089f54">&#9670;&#160;</a></span>output_permute</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> output_permute</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div>
<div class="line">  <span class="keyword">const</span> <a class="code hl_variable" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> t_start = blockIdx.x * blockDim.y + threadIdx.y</div>
</div><!-- fragment -->
</div>
</div>
<a id="a038ee34932113e6d3d38345920211f4c" name="a038ee34932113e6d3d38345920211f4c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a038ee34932113e6d3d38345920211f4c">&#9670;&#160;</a></span>output_ptrs</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a>* output_ptrs</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a34e6956031d1fc5c0f8df5fb432bcfbd" name="a34e6956031d1fc5c0f8df5fb432bcfbd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a34e6956031d1fc5c0f8df5fb432bcfbd">&#9670;&#160;</a></span>per_sample_weights_addrs</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> per_sample_weights_addrs</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a313d400789ec7e8bf0702c1d06339394" name="a313d400789ec7e8bf0702c1d06339394"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a313d400789ec7e8bf0702c1d06339394">&#9670;&#160;</a></span>permute</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> permute</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab448dead4746a419f7d4a69a32c788ea" name="ab448dead4746a419f7d4a69a32c788ea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab448dead4746a419f7d4a69a32c788ea">&#9670;&#160;</a></span>permuted_indices</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">indices_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">weights_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">indices_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> permuted_indices</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a77fcd99017c7bb6155d154951f8f45bc" name="a77fcd99017c7bb6155d154951f8f45bc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a77fcd99017c7bb6155d154951f8f45bc">&#9670;&#160;</a></span>permuted_lengths_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> permuted_lengths_size</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3035a61c641ca380da28b01558f5fdaa" name="a3035a61c641ca380da28b01558f5fdaa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3035a61c641ca380da28b01558f5fdaa">&#9670;&#160;</a></span>permuted_weights</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">indices_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">weights_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offsets_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">indices_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">weights_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> permuted_weights</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div>
<div class="line">  <a class="code hl_variable" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> b_t_start = blockIdx.x * blockDim.y + threadIdx.y</div>
</div><!-- fragment -->
</div>
</div>
<a id="a63c15a2ca68e0a1638710ac9d5335e6a" name="a63c15a2ca68e0a1638710ac9d5335e6a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a63c15a2ca68e0a1638710ac9d5335e6a">&#9670;&#160;</a></span>pre_sigmoid</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">LogitType</a> pre_sigmoid = <a class="el" href="#a666f6d4fb27d254047edf38944a98e81">logit_data</a>[<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index</a>] + <a class="el" href="#a6b36a55458d7d4b9024fd515605c29ee">recalibrate_value</a></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aef9d86cd563a5416a6c556a5902c966d" name="aef9d86cd563a5416a6c556a5902c966d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aef9d86cd563a5416a6c556a5902c966d">&#9670;&#160;</a></span>range_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> range_data</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div>
<div class="line">  <span class="keywordtype">int</span> start_row_idx = blockIdx.x * blockDim.y + threadIdx.y</div>
</div><!-- fragment -->
</div>
</div>
<a id="ad7972a8cfd2b4fbe5e0b5b29f12beaa7" name="ad7972a8cfd2b4fbe5e0b5b29f12beaa7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad7972a8cfd2b4fbe5e0b5b29f12beaa7">&#9670;&#160;</a></span>range_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> range_size</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6b36a55458d7d4b9024fd515605c29ee" name="a6b36a55458d7d4b9024fd515605c29ee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6b36a55458d7d4b9024fd515605c29ee">&#9670;&#160;</a></span>recalibrate_value</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> recalibrate_value</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2f54f8b71f0d765e2b7dbd9a8b9774ff" name="a2f54f8b71f0d765e2b7dbd9a8b9774ff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2f54f8b71f0d765e2b7dbd9a8b9774ff">&#9670;&#160;</a></span>right</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> right = <a class="el" href="#aff8ee4d321b4a815868fe53b25b8fe6b">num_bins</a> - 1</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4311f4976e51399caed297d2cad3bfd3" name="a4311f4976e51399caed297d2cad3bfd3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4311f4976e51399caed297d2cad3bfd3">&#9670;&#160;</a></span>seg_end</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> seg_end = <a class="el" href="#a0523b0079ced4e8a092ec1f3e5b5a193">csr_seg_data</a>[blockIdx.x + 1] * <a class="el" href="#add6df347839b36aa580f997fddaebf86">batch_size</a></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="adc735e446799084e3d27da58cf5807c3" name="adc735e446799084e3d27da58cf5807c3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adc735e446799084e3d27da58cf5807c3">&#9670;&#160;</a></span>seg_start</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> seg_start = <a class="el" href="#a0523b0079ced4e8a092ec1f3e5b5a193">csr_seg_data</a>[blockIdx.x] * <a class="el" href="#add6df347839b36aa580f997fddaebf86">batch_size</a></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a00965ae9e18f8292077b81d9040515c0" name="a00965ae9e18f8292077b81d9040515c0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a00965ae9e18f8292077b81d9040515c0">&#9670;&#160;</a></span>segment_end</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> segment_end</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=</div>
<div class="line">      <a class="code hl_variable" href="#ae6972dc3932ca715765452e39f97f21b">sorted_linear_indices_cumulative_run_lengths</a>[run_id + 1]</div>
<div class="ttc" id="anamespacefbgemm__gpu_html_ae6972dc3932ca715765452e39f97f21b"><div class="ttname"><a href="#ae6972dc3932ca715765452e39f97f21b">fbgemm_gpu::sorted_linear_indices_cumulative_run_lengths</a></div><div class="ttdeci">__global__ const int32_t const int32_t const scalar_t *__restrict__ const index_t *__restrict__ scalar_t *__restrict__ const at::PackedTensorAccessor32&lt; index_t, 1, at::RestrictPtrTraits &gt; const int32_t *__restrict__ sorted_linear_indices_cumulative_run_lengths</div><div class="ttdef"><b>Definition</b> sparse_batched_unary_embeddings.cu:125</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a091bd2259a1e959d0052ad2fa399065f" name="a091bd2259a1e959d0052ad2fa399065f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a091bd2259a1e959d0052ad2fa399065f">&#9670;&#160;</a></span>segment_offsets_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">ValueType</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">OffsetType</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> segment_offsets_data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa58de74ea57ed45322b04e829cb75d9b" name="aa58de74ea57ed45322b04e829cb75d9b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa58de74ea57ed45322b04e829cb75d9b">&#9670;&#160;</a></span>segment_start</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> segment_start = <a class="el" href="#ae6972dc3932ca715765452e39f97f21b">sorted_linear_indices_cumulative_run_lengths</a>[<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">run_id</a>]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac49066d09ce07fcb75c1f913da32b626" name="ac49066d09ce07fcb75c1f913da32b626"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac49066d09ce07fcb75c1f913da32b626">&#9670;&#160;</a></span>segment_value_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">ValueType</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> segment_value_data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4478543eef2b1a98a328e4c634b5f6ad" name="a4478543eef2b1a98a328e4c634b5f6ad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4478543eef2b1a98a328e4c634b5f6ad">&#9670;&#160;</a></span>SL</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> SL = <a class="el" href="#a00965ae9e18f8292077b81d9040515c0">segment_end</a> - <a class="el" href="#aa58de74ea57ed45322b04e829cb75d9b">segment_start</a></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a89d9dff100cfa1f022fcfbf61e2500cc" name="a89d9dff100cfa1f022fcfbf61e2500cc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a89d9dff100cfa1f022fcfbf61e2500cc">&#9670;&#160;</a></span>sorted_infos</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::PackedTensorAccessor32&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>, 1, at::RestrictPtrTraits&gt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> sorted_infos</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae6972dc3932ca715765452e39f97f21b" name="ae6972dc3932ca715765452e39f97f21b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae6972dc3932ca715765452e39f97f21b">&#9670;&#160;</a></span>sorted_linear_indices_cumulative_run_lengths</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::PackedTensorAccessor32&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>, 1, at::RestrictPtrTraits&gt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> sorted_linear_indices_cumulative_run_lengths</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9531de3506c1c1753051c949613ee1b5" name="a9531de3506c1c1753051c949613ee1b5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9531de3506c1c1753051c949613ee1b5">&#9670;&#160;</a></span>sorted_linear_indices_num_runs</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::PackedTensorAccessor32&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>, 1, at::RestrictPtrTraits&gt; <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> sorted_linear_indices_num_runs</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a30d761b81b0e05f95a7a118a17d6c4a2" name="a30d761b81b0e05f95a7a118a17d6c4a2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a30d761b81b0e05f95a7a118a17d6c4a2">&#9670;&#160;</a></span>sorted_linear_indices_run</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> at::PackedTensorAccessor32&lt;<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>, 1, at::RestrictPtrTraits&gt; sorted_linear_indices_run</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a119724f55ff744b85a20a870b5da4152" name="a119724f55ff744b85a20a870b5da4152"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a119724f55ff744b85a20a870b5da4152">&#9670;&#160;</a></span>src_idx</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">uint64_t</a> src_idx = (<a class="el" href="#a039dca4bc32e9ad20122b5855542e292">warp_id</a> * kWarpSize + threadIdx.x) * <a class="el" href="#a14fea42ceabd6ac042ad0d2fe5452762">VEC_WIDTH</a></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="abb9cbb13307ba09bfd2a13ca7abbb19b" name="abb9cbb13307ba09bfd2a13ca7abbb19b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abb9cbb13307ba09bfd2a13ca7abbb19b">&#9670;&#160;</a></span>start_input</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> start_input</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a17e8d602b1d99905e55e6b875dc306b5" name="a17e8d602b1d99905e55e6b875dc306b5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a17e8d602b1d99905e55e6b875dc306b5">&#9670;&#160;</a></span>step</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> step</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a85f38ec0d4f8474b6d4ccad168974cf9" name="a85f38ec0d4f8474b6d4ccad168974cf9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a85f38ec0d4f8474b6d4ccad168974cf9">&#9670;&#160;</a></span>stride</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> stride = gridDim.x * blockDim.y</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="adb83758639b252f212d790847ca2f6b6" name="adb83758639b252f212d790847ca2f6b6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adb83758639b252f212d790847ca2f6b6">&#9670;&#160;</a></span>sum</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> sum = 0.0</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aba761028ac72c20c7defaef09de61d95" name="aba761028ac72c20c7defaef09de61d95"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aba761028ac72c20c7defaef09de61d95">&#9670;&#160;</a></span>sum_E</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> sum_E = <a class="el" href="#a114a2ddecfbdbb209bc791977fcb1c0e">table_offsets</a>[<a class="el" href="#a2bef322c4183a01bc9d8e3c084ae1d15">T</a>]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2bef322c4183a01bc9d8e3c084ae1d15" name="a2bef322c4183a01bc9d8e3c084ae1d15"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2bef322c4183a01bc9d8e3c084ae1d15">&#9670;&#160;</a></span>T</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> T</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa80cbea4714c980d14626fd87c9287a4" name="aa80cbea4714c980d14626fd87c9287a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa80cbea4714c980d14626fd87c9287a4">&#9670;&#160;</a></span>t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">auto</a> t = blockIdx.y</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a242d5a911279d9ad2128346af039383f" name="a242d5a911279d9ad2128346af039383f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a242d5a911279d9ad2128346af039383f">&#9670;&#160;</a></span>table_offset</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> table_offset = <a class="el" href="#a114a2ddecfbdbb209bc791977fcb1c0e">table_offsets</a>[<a class="el" href="#aa80cbea4714c980d14626fd87c9287a4">t</a>]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a114a2ddecfbdbb209bc791977fcb1c0e" name="a114a2ddecfbdbb209bc791977fcb1c0e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a114a2ddecfbdbb209bc791977fcb1c0e">&#9670;&#160;</a></span>table_offsets</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> table_offsets</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad0fce99009259dbc5e5c0527eb5b3f64" name="ad0fce99009259dbc5e5c0527eb5b3f64"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad0fce99009259dbc5e5c0527eb5b3f64">&#9670;&#160;</a></span>temp_storage</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__shared__</a> BlockReduce::TempStorage temp_storage</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa403c596f919b42af361fc6554cce9e0" name="aa403c596f919b42af361fc6554cce9e0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa403c596f919b42af361fc6554cce9e0">&#9670;&#160;</a></span>unbucketize_permute_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">offset_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> unbucketize_permute_data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7b13aa0c4501d0593484a73afe8786c2" name="a7b13aa0c4501d0593484a73afe8786c2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7b13aa0c4501d0593484a73afe8786c2">&#9670;&#160;</a></span>uncalibrated</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">double</a> uncalibrated = 1.0 / (1.0 + <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">exp</a>(-<a class="el" href="#a63c15a2ca68e0a1638710ac9d5335e6a">pre_sigmoid</a>))</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af7acf47e01ed08917ef22330aaa8f95d" name="af7acf47e01ed08917ef22330aaa8f95d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af7acf47e01ed08917ef22330aaa8f95d">&#9670;&#160;</a></span>values_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* values_data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6b717a692f34f1bc7afb9eec6d5f9a2e" name="a6b717a692f34f1bc7afb9eec6d5f9a2e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6b717a692f34f1bc7afb9eec6d5f9a2e">&#9670;&#160;</a></span>vec_copy_with_implicit_type_cast&lt; int64_t, int32_t, VEC_WIDTH &gt;</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ad8b8d41e5b0a7f0f67d18d46f561eef8">lengths_is_long</a>&amp; [<a class="el" href="#a96187c00fa81aaf4d6404cc915a5d7b7">is_long_idx</a>] <a class="el" href="#ace5ac8a87afdca35747d5c9bd8e33e73">is_long_mask</a> <a class="el" href="#a8c639f9912105390e4083332e01ecc57">vec_copy_with_implicit_type_cast</a>&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a>, <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a>, <a class="el" href="#a14fea42ceabd6ac042ad0d2fe5452762">VEC_WIDTH</a> &gt;</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a039dca4bc32e9ad20122b5855542e292" name="a039dca4bc32e9ad20122b5855542e292"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a039dca4bc32e9ad20122b5855542e292">&#9670;&#160;</a></span>warp_id</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> warp_id</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aecfb31f7c9583dd16ed7463ad8328db4" name="aecfb31f7c9583dd16ed7463ad8328db4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aecfb31f7c9583dd16ed7463ad8328db4">&#9670;&#160;</a></span>warp_offsets_group</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a>* warp_offsets_group</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab1426ad1956909abff1b26d04575767a" name="ab1426ad1956909abff1b26d04575767a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab1426ad1956909abff1b26d04575767a">&#9670;&#160;</a></span>weight</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> weight</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="adc8829ea4c8f30f6aaef00680ba3754a" name="adc8829ea4c8f30f6aaef00680ba3754a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adc8829ea4c8f30f6aaef00680ba3754a">&#9670;&#160;</a></span>weights</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="#a112ef14feafbe22a3b70fd5ddcefcf99">int32_t</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">indices_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">weights_t</a>* <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> weights</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1148e12a9142c43e97064ffe24a0aa63" name="a1148e12a9142c43e97064ffe24a0aa63"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1148e12a9142c43e97064ffe24a0aa63">&#9670;&#160;</a></span>weights_data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__global__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">int</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">index_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">const</a> <a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">scalar_t</a> *<a class="el" href="classfbgemm__gpu_1_1_tensor_accessor.html">__restrict__</a> weights_data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.10.0
</small></address>
</body>
</html>
