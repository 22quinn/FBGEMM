<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.10.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>fbgemm_gpu: /__w/FBGEMM/FBGEMM/fbgemm_gpu/_skbuild/linux-x86_64-3.12/cmake-build/gen_embedding_forward_split_unweighted_codegen_cuda.cu File Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">fbgemm_gpu
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.10.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_b4b8bd075f03e0fff4167d5f80e92046.html">_skbuild</a></li><li class="navelem"><a class="el" href="dir_a27d41c4018669c20f452802c44efb2d.html">linux-x86_64-3.12</a></li><li class="navelem"><a class="el" href="dir_d42b091ea9351334e82212d21cbafb15.html">cmake-build</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle"><div class="title">gen_embedding_forward_split_unweighted_codegen_cuda.cu File Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><code>#include &quot;<a class="el" href="dispatch__macros_8h.html">fbgemm_gpu/dispatch_macros.h</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="embedding__op__registration_8h.html">codegen/embedding_op_registration.h</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="embedding__forward__template__helpers_8cuh.html">codegen/embedding_forward_template_helpers.cuh</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="split__embeddings__cache__cuda_8cuh.html">fbgemm_gpu/split_embeddings_cache_cuda.cuh</a>&quot;</code><br />
</div><h2 class="groupheader">Macro Definition Documentation</h2>
<a id="a285553bb10df1164c041a1cb931b44a8" name="a285553bb10df1164c041a1cb931b44a8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a285553bb10df1164c041a1cb931b44a8">&#9670;&#160;</a></span>DISPATCH_KERNEL_FOR_CACHE_CASE</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define DISPATCH_KERNEL_FOR_CACHE_CASE</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">CACHE_CASE_, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>...</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  [&amp;] {                                                                        \</div>
<div class="line">    if (CACHE_CASE_ == <span class="keyword">false</span>) {                                      \</div>
<div class="line">      <span class="keyword">constexpr</span> <span class="keyword">auto</span> use_cache_t = <span class="keyword">false</span>;                            \</div>
<div class="line">      <span class="keywordflow">return</span> __VA_ARGS__();                                                    \</div>
<div class="line">    }                                                                          \</div>
<div class="line">    if (CACHE_CASE_ == <span class="keyword">true</span>) {                                      \</div>
<div class="line">      <span class="keyword">constexpr</span> <span class="keyword">auto</span> use_cache_t = <span class="keyword">true</span>;                            \</div>
<div class="line">      <span class="keywordflow">return</span> __VA_ARGS__();                                                    \</div>
<div class="line">    }                                                                          \</div>
<div class="line">    <span class="keywordflow">return</span>;                                                                    \</div>
<div class="line">  }()</div>
</div><!-- fragment -->
</div>
</div>
<a id="abe51720e514c6a9d39c95bc2c72e1cd6" name="abe51720e514c6a9d39c95bc2c72e1cd6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abe51720e514c6a9d39c95bc2c72e1cd6">&#9670;&#160;</a></span>DISPATCH_OPTIMAL_FORWARD_KERNEL</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define DISPATCH_OPTIMAL_FORWARD_KERNEL</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">MAX_D_, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>...</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a805da9b1e5a1c6e28a4d4c99501d1b1a" name="a805da9b1e5a1c6e28a4d4c99501d1b1a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a805da9b1e5a1c6e28a4d4c99501d1b1a">&#9670;&#160;</a></span>DISPATCH_OPTIMAL_NOBAG_FORWARD_KERNEL</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define DISPATCH_OPTIMAL_NOBAG_FORWARD_KERNEL</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">DD_, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>...</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  [&amp;] {                                                                        \</div>
<div class="line">    if (DD_ &lt;= 4) {                                         \</div>
<div class="line">      <span class="keyword">constexpr</span> <span class="keywordtype">int</span> kEmbeddingSize = 4;                     \</div>
<div class="line">      <span class="keywordflow">return</span> __VA_ARGS__();                                                    \</div>
<div class="line">    }                                                                          \</div>
<div class="line">    if (DD_ &lt;= 8) {                                         \</div>
<div class="line">      <span class="keyword">constexpr</span> <span class="keywordtype">int</span> kEmbeddingSize = 8;                     \</div>
<div class="line">      <span class="keywordflow">return</span> __VA_ARGS__();                                                    \</div>
<div class="line">    }                                                                          \</div>
<div class="line">    if (DD_ &lt;= 16) {                                         \</div>
<div class="line">      <span class="keyword">constexpr</span> <span class="keywordtype">int</span> kEmbeddingSize = 16;                     \</div>
<div class="line">      <span class="keywordflow">return</span> __VA_ARGS__();                                                    \</div>
<div class="line">    }                                                                          \</div>
<div class="line">    if (DD_ &lt;= 32) {                                         \</div>
<div class="line">      <span class="keyword">constexpr</span> <span class="keywordtype">int</span> kEmbeddingSize = 32;                     \</div>
<div class="line">      <span class="keywordflow">return</span> __VA_ARGS__();                                                    \</div>
<div class="line">    }                                                                          \</div>
<div class="line">    <span class="keywordflow">return</span>;                                                                    \</div>
<div class="line">  }()</div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Typedef Documentation</h2>
<a id="abc1167888f441327c12e300780ee568a" name="abc1167888f441327c12e300780ee568a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abc1167888f441327c12e300780ee568a">&#9670;&#160;</a></span>Tensor</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> = at::Tensor</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Function Documentation</h2>
<a id="ab08dd38a042ee1b012a6db152e28df6d" name="ab08dd38a042ee1b012a6db152e28df6d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab08dd38a042ee1b012a6db152e28df6d">&#9670;&#160;</a></span>__launch_bounds__()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename emb_t , typename cache_t , typename output_t , typename index_t , bool use_lxu_cache&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">template __launch_bounds__ </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="embedding__forward__template__helpers_8cuh.html#ac9909b6865afc4a3e07fabe1ed204459">kForwardMaxThreads</a></td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">2048/</td>          <td class="paramname"><span class="paramname"><em>kForwardMaxThreads</em></span>&#160;) const</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9a6feca380488898b3f01a95a5dd69e2" name="a9a6feca380488898b3f01a95a5dd69e2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9a6feca380488898b3f01a95a5dd69e2">&#9670;&#160;</a></span>split_embedding_codegen_forward_unweighted_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> split_embedding_codegen_forward_unweighted_cuda </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>dev_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>uvm_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lxu_cache_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>weights_placements</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>weights_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>D_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>total_D</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>max_D</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>pooling_mode</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lxu_cache_locations</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>uvm_cache_stats</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>output_dtype</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const bool</td>          <td class="paramname"><span class="paramname"><em>is_experimental</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3047d316049ed936c49aa57980aad20b" name="a3047d316049ed936c49aa57980aad20b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3047d316049ed936c49aa57980aad20b">&#9670;&#160;</a></span>split_embedding_nobag_codegen_forward_unweighted_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> split_embedding_nobag_codegen_forward_unweighted_cuda </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>dev_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>uvm_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lxu_cache_weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>weights_placements</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>weights_offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>D</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>offsets</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>lxu_cache_locations</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__backward__codegen__cuda_8cu.html#abc1167888f441327c12e300780ee568a">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>uvm_cache_stats</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a></td>          <td class="paramname"><span class="paramname"><em>output_dtype</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const bool</td>          <td class="paramname"><span class="paramname"><em>is_experimental</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af53d2b0e9d8aeadd7d5094bd03ea25cc" name="af53d2b0e9d8aeadd7d5094bd03ea25cc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af53d2b0e9d8aeadd7d5094bd03ea25cc">&#9670;&#160;</a></span>TORCH_LIBRARY_FRAGMENT()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">TORCH_LIBRARY_FRAGMENT </td>
          <td>(</td>
          <td class="paramtype">fbgemm</td>          <td class="paramname"><span class="paramname">, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">m</td>          <td class="paramname"><span class="paramname"></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a240b4e029c521f922d447346c8b757b8" name="a240b4e029c521f922d447346c8b757b8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a240b4e029c521f922d447346c8b757b8">&#9670;&#160;</a></span>B</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6e4504b4f1023565bf18ac29f304f165">__launch_bounds__</a>(<a class="el" href="embedding__forward__template__helpers_8cuh.html#ac9909b6865afc4a3e07fabe1ed204459">kForwardMaxThreads</a>) __global__ void split_embedding_nobag_codegen_forward_unweighted_small_kernel(const pta const emb_t* __restrict__ const const cache_t* __restrict__ const const int32_t* __restrict__ const const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> B</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a723eb6856253bb4551265a356dd5f35d" name="a723eb6856253bb4551265a356dd5f35d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a723eb6856253bb4551265a356dd5f35d">&#9670;&#160;</a></span>D_offsets</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6e4504b4f1023565bf18ac29f304f165">__launch_bounds__</a>(<a class="el" href="embedding__forward__template__helpers_8cuh.html#ac9909b6865afc4a3e07fabe1ed204459">kForwardMaxThreads</a>) __global__ void split_embedding_nobag_codegen_forward_unweighted_small_kernel(const pta const emb_t* __restrict__ const const cache_t* __restrict__ const const int32_t* __restrict__ const const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const bool const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const <a class="el" href="classfbgemm__gpu_1_1_fixed_divisor.html">FixedDivisor</a> const index_t* __restrict__ const const index_t* __restrict__ const const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a>* __restrict__ const D_offsets</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4a300401a48c1b4c0d98e372a4293da2" name="a4a300401a48c1b4c0d98e372a4293da2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4a300401a48c1b4c0d98e372a4293da2">&#9670;&#160;</a></span>fd_num_warps_per_table</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6e4504b4f1023565bf18ac29f304f165">__launch_bounds__</a>(<a class="el" href="embedding__forward__template__helpers_8cuh.html#ac9909b6865afc4a3e07fabe1ed204459">kForwardMaxThreads</a>) __global__ void split_embedding_nobag_codegen_forward_unweighted_small_kernel(const pta const emb_t* __restrict__ const const cache_t* __restrict__ const const int32_t* __restrict__ const const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const bool const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const <a class="el" href="classfbgemm__gpu_1_1_fixed_divisor.html">FixedDivisor</a> fd_num_warps_per_table</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2d7f9971f231260d0da708ce6bf6c179" name="a2d7f9971f231260d0da708ce6bf6c179"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2d7f9971f231260d0da708ce6bf6c179">&#9670;&#160;</a></span>indices</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6e4504b4f1023565bf18ac29f304f165">__launch_bounds__</a>(<a class="el" href="embedding__forward__template__helpers_8cuh.html#ac9909b6865afc4a3e07fabe1ed204459">kForwardMaxThreads</a>) __global__ void split_embedding_nobag_codegen_forward_unweighted_small_kernel(const pta const emb_t* __restrict__ const const cache_t* __restrict__ const const int32_t* __restrict__ const const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const bool const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const <a class="el" href="classfbgemm__gpu_1_1_fixed_divisor.html">FixedDivisor</a> const index_t* __restrict__ const indices</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a60a1ec59d36df78e844d5cd7a0d34f03" name="a60a1ec59d36df78e844d5cd7a0d34f03"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a60a1ec59d36df78e844d5cd7a0d34f03">&#9670;&#160;</a></span>lxu_cache_locations</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">template const pta::PackedTensorAccessor64&lt; <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>, 1, at::RestrictPtrTraits &gt; const pta::PackedTensorAccessor64&lt; <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>, 1, at::RestrictPtrTraits &gt; const pta::PackedTensorAccessor64&lt; at::Half, 2, at::RestrictPtrTraits &gt; const pta::PackedTensorAccessor32&lt; int32_t, 1, at::RestrictPtrTraits &gt; const pta::PackedTensorAccessor32&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a>, 1, at::RestrictPtrTraits &gt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a> <a class="el" href="classfbgemm__gpu_1_1_fixed_divisor.html">FixedDivisor</a> const pta::PackedTensorAccessor32&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a>, 1, at::RestrictPtrTraits &gt; const pta::PackedTensorAccessor32&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a>, 1, at::RestrictPtrTraits &gt; const pta::PackedTensorAccessor32&lt; int32_t, 1, at::RestrictPtrTraits &gt; lxu_cache_locations</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0c2527424502280dfcf6276b49b41cdc" name="a0c2527424502280dfcf6276b49b41cdc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0c2527424502280dfcf6276b49b41cdc">&#9670;&#160;</a></span>lxu_cache_weights</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">template __global__ at::PackedTensorAccessor64&lt; <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>, 1, at::RestrictPtrTraits &gt; at::PackedTensorAccessor64&lt; <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>, 1, at::RestrictPtrTraits &gt; at::PackedTensorAccessor64&lt; at::Half, 2, at::RestrictPtrTraits &gt; lxu_cache_weights</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a179f256aa33ee3f02b437129f3186a4c" name="a179f256aa33ee3f02b437129f3186a4c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a179f256aa33ee3f02b437129f3186a4c">&#9670;&#160;</a></span>max_D_cache</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6e4504b4f1023565bf18ac29f304f165">__launch_bounds__</a>(<a class="el" href="embedding__forward__template__helpers_8cuh.html#ac9909b6865afc4a3e07fabe1ed204459">kForwardMaxThreads</a>) __global__ void split_embedding_nobag_codegen_forward_unweighted_small_kernel(const pta const emb_t* __restrict__ const const cache_t* __restrict__ const const int32_t* __restrict__ const const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const bool const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> max_D_cache</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa7749446d7c1da86adc5b7c06dcc7817" name="aa7749446d7c1da86adc5b7c06dcc7817"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa7749446d7c1da86adc5b7c06dcc7817">&#9670;&#160;</a></span>mean_pooling</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6e4504b4f1023565bf18ac29f304f165">__launch_bounds__</a>(<a class="el" href="embedding__forward__template__helpers_8cuh.html#ac9909b6865afc4a3e07fabe1ed204459">kForwardMaxThreads</a>) __global__ void split_embedding_nobag_codegen_forward_unweighted_small_kernel(const pta const emb_t* __restrict__ const const cache_t* __restrict__ const const int32_t* __restrict__ const const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const bool mean_pooling</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="afc0762ff936d64a73eef3c78b9585024" name="afc0762ff936d64a73eef3c78b9585024"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afc0762ff936d64a73eef3c78b9585024">&#9670;&#160;</a></span>offsets</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6e4504b4f1023565bf18ac29f304f165">__launch_bounds__</a>(<a class="el" href="embedding__forward__template__helpers_8cuh.html#ac9909b6865afc4a3e07fabe1ed204459">kForwardMaxThreads</a>) __global__ void split_embedding_nobag_codegen_forward_unweighted_small_kernel(const pta const emb_t* __restrict__ const const cache_t* __restrict__ const const int32_t* __restrict__ const const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const bool const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const <a class="el" href="classfbgemm__gpu_1_1_fixed_divisor.html">FixedDivisor</a> const index_t* __restrict__ const const index_t* __restrict__ const offsets</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8cb737489e5e5b8dc4db6de0b9c96a6f" name="a8cb737489e5e5b8dc4db6de0b9c96a6f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8cb737489e5e5b8dc4db6de0b9c96a6f">&#9670;&#160;</a></span>output</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6e4504b4f1023565bf18ac29f304f165">__launch_bounds__</a>(<a class="el" href="embedding__forward__template__helpers_8cuh.html#ac9909b6865afc4a3e07fabe1ed204459">kForwardMaxThreads</a>) __global__ void split_embedding_nobag_codegen_forward_unweighted_small_kernel(const pta const emb_t* __restrict__ const const cache_t* __restrict__ const const int32_t* __restrict__ const const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const bool const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const <a class="el" href="classfbgemm__gpu_1_1_fixed_divisor.html">FixedDivisor</a> const index_t* __restrict__ const const index_t* __restrict__ const const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a>* __restrict__ const const <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a>* __restrict__ const const int32_t* __restrict__ const output_t* __restrict__ const output</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2ee4b3e799d56c4d34c87190c37a7a64" name="a2ee4b3e799d56c4d34c87190c37a7a64"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2ee4b3e799d56c4d34c87190c37a7a64">&#9670;&#160;</a></span>T</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6e4504b4f1023565bf18ac29f304f165">__launch_bounds__</a>(<a class="el" href="embedding__forward__template__helpers_8cuh.html#ac9909b6865afc4a3e07fabe1ed204459">kForwardMaxThreads</a>) __global__ void split_embedding_nobag_codegen_forward_unweighted_small_kernel(const pta const emb_t* __restrict__ const const cache_t* __restrict__ const const int32_t* __restrict__ const const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> T</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a17f61eb7bf7a7e4089982fbf69116da5" name="a17f61eb7bf7a7e4089982fbf69116da5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a17f61eb7bf7a7e4089982fbf69116da5">&#9670;&#160;</a></span>uvm_weights</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">template __global__ at::PackedTensorAccessor64&lt; <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>, 1, at::RestrictPtrTraits &gt; at::PackedTensorAccessor64&lt; <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>, 1, at::RestrictPtrTraits &gt; uvm_weights</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9f15527d585dd62a23511c2f0bad4ca7" name="a9f15527d585dd62a23511c2f0bad4ca7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9f15527d585dd62a23511c2f0bad4ca7">&#9670;&#160;</a></span>weights_offsets</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6e4504b4f1023565bf18ac29f304f165">__launch_bounds__</a>(<a class="el" href="embedding__forward__template__helpers_8cuh.html#ac9909b6865afc4a3e07fabe1ed204459">kForwardMaxThreads</a>) __global__ void split_embedding_nobag_codegen_forward_unweighted_small_kernel(const pta const emb_t* __restrict__ const const cache_t* __restrict__ const const int32_t* __restrict__ const const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const bool const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a> const <a class="el" href="classfbgemm__gpu_1_1_fixed_divisor.html">FixedDivisor</a> const index_t* __restrict__ const const index_t* __restrict__ const const <a class="el" href="gen__embedding__backward__split__grad_8cu.html#abe53421bcec0b67763c3ed41e3a2a2ad">uint32_t</a>* __restrict__ const const <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a>* __restrict__ const weights_offsets</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad4dd9cc51f1eccdf4626318632701868" name="ad4dd9cc51f1eccdf4626318632701868"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad4dd9cc51f1eccdf4626318632701868">&#9670;&#160;</a></span>weights_placements</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">template __global__ at::PackedTensorAccessor64&lt; <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>, 1, at::RestrictPtrTraits &gt; at::PackedTensorAccessor64&lt; <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>, 1, at::RestrictPtrTraits &gt; at::PackedTensorAccessor64&lt; at::Half, 2, at::RestrictPtrTraits &gt; const at::PackedTensorAccessor32&lt; <a class="el" href="gen__batch__index__select__dim0__backward__kernel__cta_8cu.html#a6df94b891e47f19e9fa76b529e49cdda">float</a>, 1, at::RestrictPtrTraits &gt; const at::PackedTensorAccessor32&lt; <a class="el" href="gen__batch__index__select__dim0__forward__kernel_8cu.html#ac4ebc0de2e60165af8333b6f4eab3e70">int64_t</a>, 1, at::RestrictPtrTraits &gt; const at::PackedTensorAccessor32&lt; int32_t, 1, at::RestrictPtrTraits &gt; weights_placements</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.10.0
</small></address>
</body>
</html>
