<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.10.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>fbgemm_gpu: /__w/FBGEMM/FBGEMM/fbgemm_gpu/include/fbgemm_gpu/sparse_ops_utils.h File Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">fbgemm_gpu
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.10.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_9bbc85fb6cfbce51ed674bab6205f8cb.html">include</a></li><li class="navelem"><a class="el" href="dir_a13c1b53005a8c279eb71f07c614d23a.html">fbgemm_gpu</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">sparse_ops_utils.h File Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><code>#include &lt;ATen/ATen.h&gt;</code><br />
<code>#include &lt;cstdint&gt;</code><br />
<code>#include &lt;optional&gt;</code><br />
<code>#include &lt;string&gt;</code><br />
</div><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="struct_stack_array.html">StackArray&lt; T &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structlog2__calc__.html">log2_calc_&lt; x &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structlog2__calc___3_010_01_4.html">log2_calc_&lt; 0 &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structlog2__calc.html">log2_calc&lt; x &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a885f787cafec301665604303ae43a2e3" id="r_a885f787cafec301665604303ae43a2e3"><td class="memTemplParams" colspan="2">template&lt;typename Integer1 , typename Integer2 , std::enable_if_t&lt; std::is_integral&lt; Integer1 &gt;::value, bool &gt;  = true, std::enable_if_t&lt; std::is_integral&lt; Integer2 &gt;::value, bool &gt;  = true&gt; </td></tr>
<tr class="memitem:a885f787cafec301665604303ae43a2e3"><td class="memTemplItemLeft" align="right" valign="top">constexpr uint32_t&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="#a885f787cafec301665604303ae43a2e3">cuda_calc_xblock_count_base</a> (Integer1 num_items, Integer2 threads_per_block)</td></tr>
<tr class="separator:a885f787cafec301665604303ae43a2e3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab702f2479ba0bedf91c18e0b644b210a" id="r_ab702f2479ba0bedf91c18e0b644b210a"><td class="memTemplParams" colspan="2">template&lt;typename Integer1 , typename Integer2 , std::enable_if_t&lt; std::is_integral&lt; Integer1 &gt;::value, bool &gt;  = true, std::enable_if_t&lt; std::is_integral&lt; Integer2 &gt;::value, bool &gt;  = true&gt; </td></tr>
<tr class="memitem:ab702f2479ba0bedf91c18e0b644b210a"><td class="memTemplItemLeft" align="right" valign="top">constexpr uint32_t&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="#ab702f2479ba0bedf91c18e0b644b210a">cuda_calc_block_count</a> (Integer1 num_items, Integer2 threads_per_block)</td></tr>
<tr class="separator:ab702f2479ba0bedf91c18e0b644b210a"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Macro Definition Documentation</h2>
<a id="ae80e8b33bdef7d2849eb3d516ff67d1b" name="ae80e8b33bdef7d2849eb3d516ff67d1b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae80e8b33bdef7d2849eb3d516ff67d1b">&#9670;&#160;</a></span>DISPATCH_TO_ALL</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define DISPATCH_TO_ALL</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">name, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">function</span>&#160;)&#160;&#160;&#160;  m.impl(name, torch::dispatch(c10::DispatchKey::CatchAll, TORCH_FN(function)))</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aab6390a9590ead03a896aae2b93a96ed" name="aab6390a9590ead03a896aae2b93a96ed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aab6390a9590ead03a896aae2b93a96ed">&#9670;&#160;</a></span>DISPATCH_TO_AUTOGRAD</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define DISPATCH_TO_AUTOGRAD</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">name, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">function</span>&#160;)&#160;&#160;&#160;  m.impl(name, torch::dispatch(c10::DispatchKey::Autograd, TORCH_FN(function)))</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="adb242971e11b66b1f8f58c361e44b8e7" name="adb242971e11b66b1f8f58c361e44b8e7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adb242971e11b66b1f8f58c361e44b8e7">&#9670;&#160;</a></span>DISPATCH_TO_AUTOGRAD_CUDA</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define DISPATCH_TO_AUTOGRAD_CUDA</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">name, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">function</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  m.impl(                                         \</div>
<div class="line">      name,                                       \</div>
<div class="line">      torch::dispatch(c10::DispatchKey::AutogradCUDA, TORCH_FN(function)))</div>
</div><!-- fragment -->
</div>
</div>
<a id="a8ed65710de63bd56275d2ceded5d59b4" name="a8ed65710de63bd56275d2ceded5d59b4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8ed65710de63bd56275d2ceded5d59b4">&#9670;&#160;</a></span>DISPATCH_TO_AUTOGRAD_META</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define DISPATCH_TO_AUTOGRAD_META</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">name, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">function</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  m.impl(                                         \</div>
<div class="line">      name,                                       \</div>
<div class="line">      torch::dispatch(c10::DispatchKey::AutogradMETA, TORCH_FN(function)))</div>
</div><!-- fragment -->
</div>
</div>
<a id="af5cf39897136f04c6f2ac5f3544c49c3" name="af5cf39897136f04c6f2ac5f3544c49c3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af5cf39897136f04c6f2ac5f3544c49c3">&#9670;&#160;</a></span>DISPATCH_TO_CPU</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define DISPATCH_TO_CPU</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">name, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">function</span>&#160;)&#160;&#160;&#160;  m.impl(name, torch::dispatch(c10::DispatchKey::CPU, TORCH_FN(function)))</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a06de50f3ede518ff59612c9ada5a85c8" name="a06de50f3ede518ff59612c9ada5a85c8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a06de50f3ede518ff59612c9ada5a85c8">&#9670;&#160;</a></span>DISPATCH_TO_CUDA</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define DISPATCH_TO_CUDA</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">name, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">function</span>&#160;)&#160;&#160;&#160;  m.impl(name, torch::dispatch(c10::DispatchKey::CUDA, TORCH_FN(function)))</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa751218a0e9119ad6fa4d6d4df63fda5" name="aa751218a0e9119ad6fa4d6d4df63fda5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa751218a0e9119ad6fa4d6d4df63fda5">&#9670;&#160;</a></span>DISPATCH_TO_META</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define DISPATCH_TO_META</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">name, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">function</span>&#160;)&#160;&#160;&#160;  m.impl(name, torch::dispatch(c10::DispatchKey::Meta, TORCH_FN(function)))</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8f3cc6f3a1a83750715b4ddcb228ca8b" name="a8f3cc6f3a1a83750715b4ddcb228ca8b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8f3cc6f3a1a83750715b4ddcb228ca8b">&#9670;&#160;</a></span>JAGGED_TENSOR_DISPATCH_DIMS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define JAGGED_TENSOR_DISPATCH_DIMS</td>
          <td>(</td>
          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  AT_DISPATCH_INDEX_TYPES(x_offsets[0].scalar_type(), <span class="stringliteral">&quot;jagged_indices&quot;</span>, [=] { \</div>
<div class="line">    switch (num_jagged_dim) {                                                 \</div>
<div class="line">      <span class="keywordflow">case</span> 1:                                                                 \</div>
<div class="line">        INVOKE_KERNEL_WITH_DIM(1);                                            \</div>
<div class="line">        <span class="keywordflow">break</span>;                                                                \</div>
<div class="line">      <span class="keywordflow">case</span> 2:                                                                 \</div>
<div class="line">        INVOKE_KERNEL_WITH_DIM(2);                                            \</div>
<div class="line">        <span class="keywordflow">break</span>;                                                                \</div>
<div class="line">      <span class="keywordflow">case</span> 3:                                                                 \</div>
<div class="line">        INVOKE_KERNEL_WITH_DIM(3);                                            \</div>
<div class="line">        <span class="keywordflow">break</span>;                                                                \</div>
<div class="line">      <span class="keywordflow">case</span> 4:                                                                 \</div>
<div class="line">        INVOKE_KERNEL_WITH_DIM(4);                                            \</div>
<div class="line">        <span class="keywordflow">break</span>;                                                                \</div>
<div class="line">      <span class="keywordflow">case</span> 5:                                                                 \</div>
<div class="line">        INVOKE_KERNEL_WITH_DIM(5);                                            \</div>
<div class="line">        <span class="keywordflow">break</span>;                                                                \</div>
<div class="line">      <span class="keywordflow">default</span>:                                                                \</div>
<div class="line">        TORCH_CHECK(                                                          \</div>
<div class="line">            <span class="keyword">false</span>, <span class="stringliteral">&quot;unsupported number of jagged dim &quot;</span>, num_jagged_dim);      \</div>
<div class="line">    }                                                                         \</div>
<div class="line">  });</div>
</div><!-- fragment -->
</div>
</div>
<a id="a333341c9590667c47753510e0da7b6e3" name="a333341c9590667c47753510e0da7b6e3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a333341c9590667c47753510e0da7b6e3">&#9670;&#160;</a></span>TENSOR_CONTIGUOUS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define TENSOR_CONTIGUOUS</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">x</span></td><td>)</td>
          <td>&#160;&#160;&#160;  TORCH_CHECK((x).is_contiguous(), #x &quot; must be contiguous&quot;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0378cd5f9e716f13079b83a9b9805691" name="a0378cd5f9e716f13079b83a9b9805691"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0378cd5f9e716f13079b83a9b9805691">&#9670;&#160;</a></span>TENSOR_CONTIGUOUS_AND_ON_CPU</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define TENSOR_CONTIGUOUS_AND_ON_CPU</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">x</span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  <a class="code hl_define" href="#a5d19d4051835acd2c6d83eb637341010">TENSOR_ON_CPU</a>(x);                     \</div>
<div class="line">  TENSOR_CONTIGUOUS(x)</div>
<div class="ttc" id="asparse__ops__utils_8h_html_a5d19d4051835acd2c6d83eb637341010"><div class="ttname"><a href="#a5d19d4051835acd2c6d83eb637341010">TENSOR_ON_CPU</a></div><div class="ttdeci">#define TENSOR_ON_CPU(x)</div><div class="ttdef"><b>Definition</b> sparse_ops_utils.h:124</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a350ade6aa989687c2ca8ced000e200ff" name="a350ade6aa989687c2ca8ced000e200ff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a350ade6aa989687c2ca8ced000e200ff">&#9670;&#160;</a></span>TENSOR_CONTIGUOUS_AND_ON_CUDA_GPU</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define TENSOR_CONTIGUOUS_AND_ON_CUDA_GPU</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">x</span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  <a class="code hl_define" href="#ac6089c2908cb1ae6367af5cf7bbea30d">TENSOR_ON_CUDA_GPU</a>(x);                     \</div>
<div class="line">  TENSOR_CONTIGUOUS(x)</div>
<div class="ttc" id="asparse__ops__utils_8h_html_ac6089c2908cb1ae6367af5cf7bbea30d"><div class="ttname"><a href="#ac6089c2908cb1ae6367af5cf7bbea30d">TENSOR_ON_CUDA_GPU</a></div><div class="ttdeci">#define TENSOR_ON_CUDA_GPU(x)</div><div class="ttdef"><b>Definition</b> sparse_ops_utils.h:136</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a73ab1987fec37ac982ae1ed77be0e3ea" name="a73ab1987fec37ac982ae1ed77be0e3ea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a73ab1987fec37ac982ae1ed77be0e3ea">&#9670;&#160;</a></span>TENSOR_EMPTY_OR_ON_CPU</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define TENSOR_EMPTY_OR_ON_CPU</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">x</span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  TORCH_CHECK(                                                         \</div>
<div class="line">      <a class="code hl_function" href="#a6328f240dd58293d0349471dca28797e">torch_tensor_empty_or_on_cpu_check</a>(x),                           \</div>
<div class="line">      #x <span class="stringliteral">&quot; must be empty or a CPU tensor; it is currently on device &quot;</span>, \</div>
<div class="line">      <a class="code hl_function" href="#a535403fdc5c523b45f0d56d657e17f7b">torch_tensor_device_name</a>(x))</div>
<div class="ttc" id="asparse__ops__utils_8h_html_a535403fdc5c523b45f0d56d657e17f7b"><div class="ttname"><a href="#a535403fdc5c523b45f0d56d657e17f7b">torch_tensor_device_name</a></div><div class="ttdeci">std::string torch_tensor_device_name(const at::Tensor &amp;ten)</div><div class="ttdef"><b>Definition</b> sparse_ops_utils.h:38</div></div>
<div class="ttc" id="asparse__ops__utils_8h_html_a6328f240dd58293d0349471dca28797e"><div class="ttname"><a href="#a6328f240dd58293d0349471dca28797e">torch_tensor_empty_or_on_cpu_check</a></div><div class="ttdeci">bool torch_tensor_empty_or_on_cpu_check(const at::Tensor &amp;ten)</div><div class="ttdef"><b>Definition</b> sparse_ops_utils.h:90</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="aff83e4ada08cf70146ffc4ac2009aa9a" name="aff83e4ada08cf70146ffc4ac2009aa9a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aff83e4ada08cf70146ffc4ac2009aa9a">&#9670;&#160;</a></span>TENSOR_EMPTY_OR_ON_CUDA_GPU</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define TENSOR_EMPTY_OR_ON_CUDA_GPU</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">x</span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  TORCH_CHECK(                                                          \</div>
<div class="line">      <a class="code hl_function" href="#abb9778e9fb75a70593c27e53dca268cd">torch_tensor_empty_or_on_cuda_gpu_check</a>(x),                       \</div>
<div class="line">      #x <span class="stringliteral">&quot; must be empty or a CUDA tensor; it is currently on device &quot;</span>, \</div>
<div class="line">      <a class="code hl_function" href="#a535403fdc5c523b45f0d56d657e17f7b">torch_tensor_device_name</a>(x))</div>
<div class="ttc" id="asparse__ops__utils_8h_html_abb9778e9fb75a70593c27e53dca268cd"><div class="ttname"><a href="#abb9778e9fb75a70593c27e53dca268cd">torch_tensor_empty_or_on_cuda_gpu_check</a></div><div class="ttdeci">bool torch_tensor_empty_or_on_cuda_gpu_check(const at::Tensor &amp;ten)</div><div class="ttdef"><b>Definition</b> sparse_ops_utils.h:80</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a485f848acf189619cb61a0ae7534eaa1" name="a485f848acf189619cb61a0ae7534eaa1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a485f848acf189619cb61a0ae7534eaa1">&#9670;&#160;</a></span>TENSOR_NDIM_EQUALS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define TENSOR_NDIM_EQUALS</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">ten, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">dims</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  TORCH_CHECK(                             \</div>
<div class="line">      (ten).ndimension() == (dims),        \</div>
<div class="line">      <span class="stringliteral">&quot;Tensor &#39;&quot;</span> #ten <span class="stringliteral">&quot;&#39; must have &quot;</span> #dims \</div>
<div class="line">      <span class="stringliteral">&quot; dimension(s). &quot;</span>                    \</div>
<div class="line">      <span class="stringliteral">&quot;Found &quot;</span>,                            \</div>
<div class="line">      (ten).ndimension())</div>
</div><!-- fragment -->
</div>
</div>
<a id="acfab048550cb0518bdb1ac267ef1e7ba" name="acfab048550cb0518bdb1ac267ef1e7ba"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acfab048550cb0518bdb1ac267ef1e7ba">&#9670;&#160;</a></span>TENSOR_NDIM_EXCEEDS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define TENSOR_NDIM_EXCEEDS</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">ten, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">dims</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  TORCH_CHECK(                                       \</div>
<div class="line">      (ten).dim() &gt; (dims),                          \</div>
<div class="line">      <span class="stringliteral">&quot;Tensor &#39;&quot;</span> #ten <span class="stringliteral">&quot;&#39; must have more than &quot;</span> #dims \</div>
<div class="line">      <span class="stringliteral">&quot; dimension(s). &quot;</span>                              \</div>
<div class="line">      <span class="stringliteral">&quot;Found &quot;</span>,                                      \</div>
<div class="line">      (ten).ndimension())</div>
</div><!-- fragment -->
</div>
</div>
<a id="abd9e69a82885e6e361275a0b08ebe565" name="abd9e69a82885e6e361275a0b08ebe565"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abd9e69a82885e6e361275a0b08ebe565">&#9670;&#160;</a></span>TENSOR_NDIM_IS_GE</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define TENSOR_NDIM_IS_GE</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">ten, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">dims</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  TORCH_CHECK(                               \</div>
<div class="line">      (ten).dim() &gt;= (dims),                 \</div>
<div class="line">      <span class="stringliteral">&quot;Tensor &#39;&quot;</span> #ten <span class="stringliteral">&quot;&#39; must have &gt;=&quot;</span> #dims \</div>
<div class="line">      <span class="stringliteral">&quot; dimension(s). &quot;</span>                      \</div>
<div class="line">      <span class="stringliteral">&quot;Found &quot;</span>,                              \</div>
<div class="line">      (ten).ndimension())</div>
</div><!-- fragment -->
</div>
</div>
<a id="a5d19d4051835acd2c6d83eb637341010" name="a5d19d4051835acd2c6d83eb637341010"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5d19d4051835acd2c6d83eb637341010">&#9670;&#160;</a></span>TENSOR_ON_CPU</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define TENSOR_ON_CPU</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">x</span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  TORCH_CHECK(                                                \</div>
<div class="line">      <a class="code hl_function" href="#ad971d56f6b82b6c62a2d6fed276b0463">torch_tensor_on_cpu_check</a>(x),                           \</div>
<div class="line">      #x <span class="stringliteral">&quot; must be a CPU tensor; it is currently on device &quot;</span>, \</div>
<div class="line">      <a class="code hl_function" href="#a535403fdc5c523b45f0d56d657e17f7b">torch_tensor_device_name</a>(x))</div>
<div class="ttc" id="asparse__ops__utils_8h_html_ad971d56f6b82b6c62a2d6fed276b0463"><div class="ttname"><a href="#ad971d56f6b82b6c62a2d6fed276b0463">torch_tensor_on_cpu_check</a></div><div class="ttdeci">bool torch_tensor_on_cpu_check(const at::Tensor &amp;ten)</div><div class="ttdef"><b>Definition</b> sparse_ops_utils.h:16</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="ac6089c2908cb1ae6367af5cf7bbea30d" name="ac6089c2908cb1ae6367af5cf7bbea30d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac6089c2908cb1ae6367af5cf7bbea30d">&#9670;&#160;</a></span>TENSOR_ON_CUDA_GPU</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define TENSOR_ON_CUDA_GPU</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">x</span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  TORCH_CHECK(                                                 \</div>
<div class="line">      <a class="code hl_function" href="#a5568d44e6066339da1326798f9637b16">torch_tensor_on_cuda_gpu_check</a>(x),                       \</div>
<div class="line">      #x <span class="stringliteral">&quot; must be a CUDA tensor; it is currently on device &quot;</span>, \</div>
<div class="line">      <a class="code hl_function" href="#a535403fdc5c523b45f0d56d657e17f7b">torch_tensor_device_name</a>(x))</div>
<div class="ttc" id="asparse__ops__utils_8h_html_a5568d44e6066339da1326798f9637b16"><div class="ttname"><a href="#a5568d44e6066339da1326798f9637b16">torch_tensor_on_cuda_gpu_check</a></div><div class="ttdeci">bool torch_tensor_on_cuda_gpu_check(const at::Tensor &amp;ten)</div><div class="ttdef"><b>Definition</b> sparse_ops_utils.h:71</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a003b5640cfa59fe8f5da9b1c9fcb8f26" name="a003b5640cfa59fe8f5da9b1c9fcb8f26"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a003b5640cfa59fe8f5da9b1c9fcb8f26">&#9670;&#160;</a></span>TENSOR_TYPE_MUST_BE</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define TENSOR_TYPE_MUST_BE</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">ten, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">typ</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  TORCH_CHECK(                                                             \</div>
<div class="line">      (ten).scalar_type() == typ,                                          \</div>
<div class="line">      <span class="stringliteral">&quot;Tensor &#39;&quot;</span> #ten <span class="stringliteral">&quot;&#39; must have scalar type &quot;</span> #typ <span class="stringliteral">&quot; but it had type &quot;</span>, \</div>
<div class="line">      (ten).dtype().name())</div>
</div><!-- fragment -->
</div>
</div>
<a id="a3df91ae56fe10d1c002bed63e5b78d1b" name="a3df91ae56fe10d1c002bed63e5b78d1b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3df91ae56fe10d1c002bed63e5b78d1b">&#9670;&#160;</a></span>TENSORS_EMPTY_OR_ON_SAME_DEVICE</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define TENSORS_EMPTY_OR_ON_SAME_DEVICE</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">x, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">y</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  TORCH_CHECK(                                                          \</div>
<div class="line">      <a class="code hl_function" href="#a5683dd4c2143c3c0ba0eeb80fd5223f0">torch_tensor_on_same_device_check</a>(x, y) || (x.numel() == 0),      \</div>
<div class="line">      #x <span class="stringliteral">&quot; must be empty or a CUDA tensor; it is currently on device &quot;</span>, \</div>
<div class="line">      <a class="code hl_function" href="#a535403fdc5c523b45f0d56d657e17f7b">torch_tensor_device_name</a>(x))</div>
<div class="ttc" id="asparse__ops__utils_8h_html_a5683dd4c2143c3c0ba0eeb80fd5223f0"><div class="ttname"><a href="#a5683dd4c2143c3c0ba0eeb80fd5223f0">torch_tensor_on_same_device_check</a></div><div class="ttdeci">bool torch_tensor_on_same_device_check(const at::Tensor &amp;ten1, const at::Tensor &amp;ten2)</div><div class="ttdef"><b>Definition</b> sparse_ops_utils.h:51</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a9be1e573e7d3e35f3db03210e2624e61" name="a9be1e573e7d3e35f3db03210e2624e61"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9be1e573e7d3e35f3db03210e2624e61">&#9670;&#160;</a></span>TENSORS_HAVE_SAME_NUMEL</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define TENSORS_HAVE_SAME_NUMEL</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">x, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">y</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  TORCH_CHECK(                                                         \</div>
<div class="line">      (x).numel() == (y).numel(),                                      \</div>
<div class="line">      #x <span class="stringliteral">&quot; must have the same number of elements as &quot;</span> #y <span class="stringliteral">&quot; They had &quot;</span>, \</div>
<div class="line">      (x).numel(),                                                     \</div>
<div class="line">      <span class="stringliteral">&quot; and &quot;</span>,                                                         \</div>
<div class="line">      (y).numel())</div>
</div><!-- fragment -->
</div>
</div>
<a id="a97687675a3398d3168fe8f07a1b4db87" name="a97687675a3398d3168fe8f07a1b4db87"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a97687675a3398d3168fe8f07a1b4db87">&#9670;&#160;</a></span>TENSORS_HAVE_SAME_TYPE</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define TENSORS_HAVE_SAME_TYPE</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">x, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">y</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  TORCH_CHECK(                                             \</div>
<div class="line">      (x).dtype() == (y).dtype(),                          \</div>
<div class="line">      #x <span class="stringliteral">&quot; must have the same type as &quot;</span> #y <span class="stringliteral">&quot; types were &quot;</span>, \</div>
<div class="line">      (x).dtype().name(),                                  \</div>
<div class="line">      <span class="stringliteral">&quot; and &quot;</span>,                                             \</div>
<div class="line">      (y).dtype().name())</div>
</div><!-- fragment -->
</div>
</div>
<a id="a4724e1d67266b6998b8fe4ef1ec743d9" name="a4724e1d67266b6998b8fe4ef1ec743d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4724e1d67266b6998b8fe4ef1ec743d9">&#9670;&#160;</a></span>TENSORS_ON_SAME_CUDA_GPU_IF_NOT_OPTIONAL</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define TENSORS_ON_SAME_CUDA_GPU_IF_NOT_OPTIONAL</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>...</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  <span class="keywordflow">do</span> {                                                                       \</div>
<div class="line">    <span class="keyword">const</span> <span class="keyword">auto</span> tensors_on_same_gpu =                                         \</div>
<div class="line">        tensor_on_same_gpu_if_not_optional_check(#__VA_ARGS__, __VA_ARGS__); \</div>
<div class="line">    TORCH_CHECK(tensors_on_same_gpu.empty(), tensors_on_same_gpu);           \</div>
<div class="line">  } <span class="keywordflow">while</span> (<span class="keyword">false</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="aa6ef8e13e3280066cc5f4f0970d3e7a6" name="aa6ef8e13e3280066cc5f4f0970d3e7a6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa6ef8e13e3280066cc5f4f0970d3e7a6">&#9670;&#160;</a></span>TENSORS_ON_SAME_DEVICE</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define TENSORS_ON_SAME_DEVICE</td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">x, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname">y</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Value:</b><div class="fragment"><div class="line">  TORCH_CHECK(                                                             \</div>
<div class="line">      <a class="code hl_function" href="#a5683dd4c2143c3c0ba0eeb80fd5223f0">torch_tensor_on_same_device_check</a>(x, y),                             \</div>
<div class="line">      #x <span class="stringliteral">&quot; must be on the same device as &quot;</span> #y <span class="stringliteral">&quot;! &quot;</span> #x <span class="stringliteral">&quot; is currently on &quot;</span>, \</div>
<div class="line">      <a class="code hl_function" href="#a535403fdc5c523b45f0d56d657e17f7b">torch_tensor_device_name</a>(x),                                         \</div>
<div class="line">      #y <span class="stringliteral">&quot; is currently on &quot;</span>,                                              \</div>
<div class="line">      <a class="code hl_function" href="#a535403fdc5c523b45f0d56d657e17f7b">torch_tensor_device_name</a>(y))</div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Function Documentation</h2>
<a id="a519154f3b89148b1b70e45d8c340ff81" name="a519154f3b89148b1b70e45d8c340ff81"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a519154f3b89148b1b70e45d8c340ff81">&#9670;&#160;</a></span>binary_search_range_cpu()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename scalar_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void binary_search_range_cpu </td>
          <td>(</td>
          <td class="paramtype">int *</td>          <td class="paramname"><span class="paramname"><em>found</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const scalar_t *</td>          <td class="paramname"><span class="paramname"><em>arr</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const scalar_t</td>          <td class="paramname"><span class="paramname"><em>target</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int</td>          <td class="paramname"><span class="paramname"><em>num_entries</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab702f2479ba0bedf91c18e0b644b210a" name="ab702f2479ba0bedf91c18e0b644b210a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab702f2479ba0bedf91c18e0b644b210a">&#9670;&#160;</a></span>cuda_calc_block_count()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Integer1 , typename Integer2 , std::enable_if_t&lt; std::is_integral&lt; Integer1 &gt;::value, bool &gt;  = true, std::enable_if_t&lt; std::is_integral&lt; Integer2 &gt;::value, bool &gt;  = true&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">constexpr uint32_t cuda_calc_block_count </td>
          <td>(</td>
          <td class="paramtype">Integer1</td>          <td class="paramname"><span class="paramname"><em>num_items</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Integer2</td>          <td class="paramname"><span class="paramname"><em>threads_per_block</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Determine an appropriate CUDA block count.</p>
<p>See <a class="el" href="#a885f787cafec301665604303ae43a2e3">cuda_calc_xblock_count_base()</a> for details. </p>

</div>
</div>
<a id="a2eba06f69b5b34fe6ca0eafb0240d369" name="a2eba06f69b5b34fe6ca0eafb0240d369"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2eba06f69b5b34fe6ca0eafb0240d369">&#9670;&#160;</a></span>cuda_calc_xblock_count()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Integer1 , typename Integer2 , std::enable_if_t&lt; std::is_integral&lt; Integer1 &gt;::value &amp;&amp;std::is_signed&lt; Integer2 &gt;::value, bool &gt;  = true, std::enable_if_t&lt; std::is_integral&lt; Integer2 &gt;::value &amp;&amp;std::is_unsigned&lt; Integer2 &gt;::value, bool &gt;  = true&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">constexpr uint32_t cuda_calc_xblock_count </td>
          <td>(</td>
          <td class="paramtype">Integer1</td>          <td class="paramname"><span class="paramname"><em>num_items</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Integer2</td>          <td class="paramname"><span class="paramname"><em>threads_per_block</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a885f787cafec301665604303ae43a2e3" name="a885f787cafec301665604303ae43a2e3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a885f787cafec301665604303ae43a2e3">&#9670;&#160;</a></span>cuda_calc_xblock_count_base()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Integer1 , typename Integer2 , std::enable_if_t&lt; std::is_integral&lt; Integer1 &gt;::value, bool &gt;  = true, std::enable_if_t&lt; std::is_integral&lt; Integer2 &gt;::value, bool &gt;  = true&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">constexpr uint32_t cuda_calc_xblock_count_base </td>
          <td>(</td>
          <td class="paramtype">Integer1</td>          <td class="paramname"><span class="paramname"><em>num_items</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Integer2</td>          <td class="paramname"><span class="paramname"><em>threads_per_block</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Determine an appropriate CUDA block count along the x axis</p>
<p>When launching CUDA kernels the number of blocks B is often calculated w.r.t. the number of threads T and items to be processed N as B=(N+T-1)/T - which is integer division rounding up. This function abstracts that calculation, performs it in an overflow-safe manner, and limits the return value appropriately.</p>
<p>This is a general function for all integral data types. The goal of this set of functions is to ensure correct calculations across a variety of data types without forcing the programmer to cast to an appropriate type (which is dangerous because we don't have conversion warnings enabled). The values of the variables can then be checked for correctness at run-time. Specialized functions below handle various combinations of signed and unsigned inputs. This system prevents "pointless comparison
against zero" warnings from the compiler for unsigned types (simpler ways of suppressing this warning didn't work) while maintaining the various warnings.</p>
<p>Function is designed to facilitate run-time value checking. </p>

</div>
</div>
<a id="a672c3da6666124b2950b2eef43587bc6" name="a672c3da6666124b2950b2eef43587bc6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a672c3da6666124b2950b2eef43587bc6">&#9670;&#160;</a></span>get_device_index_from_tensor() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::optional&lt; int64_t &gt; get_device_index_from_tensor </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="embedding__inplace__update_8h.html#abc1167888f441327c12e300780ee568a">at::Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>ten</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="af97638412af3aea185ac327ebe398542" name="af97638412af3aea185ac327ebe398542"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af97638412af3aea185ac327ebe398542">&#9670;&#160;</a></span>get_device_index_from_tensor() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::optional&lt; int64_t &gt; get_device_index_from_tensor </td>
          <td>(</td>
          <td class="paramtype">const c10::optional&lt; <a class="el" href="embedding__inplace__update_8h.html#abc1167888f441327c12e300780ee568a">at::Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>ten</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a5a8411338d3eef3620c7f5be3803c7cd" name="a5a8411338d3eef3620c7f5be3803c7cd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5a8411338d3eef3620c7f5be3803c7cd">&#9670;&#160;</a></span>tensor_on_same_gpu_if_not_optional_check()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename... Tensors&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">std::string tensor_on_same_gpu_if_not_optional_check </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;</td>          <td class="paramname"><span class="paramname"><em>var_names_str</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Tensors &amp;...</td>          <td class="paramname"><span class="paramname"><em>tensors</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a535403fdc5c523b45f0d56d657e17f7b" name="a535403fdc5c523b45f0d56d657e17f7b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a535403fdc5c523b45f0d56d657e17f7b">&#9670;&#160;</a></span>torch_tensor_device_name() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::string torch_tensor_device_name </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="embedding__inplace__update_8h.html#abc1167888f441327c12e300780ee568a">at::Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>ten</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a319c921d3abe8bdb14140b45afe9afdb" name="a319c921d3abe8bdb14140b45afe9afdb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a319c921d3abe8bdb14140b45afe9afdb">&#9670;&#160;</a></span>torch_tensor_device_name() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::string torch_tensor_device_name </td>
          <td>(</td>
          <td class="paramtype">const c10::optional&lt; <a class="el" href="embedding__inplace__update_8h.html#abc1167888f441327c12e300780ee568a">at::Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>ten</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a6328f240dd58293d0349471dca28797e" name="a6328f240dd58293d0349471dca28797e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6328f240dd58293d0349471dca28797e">&#9670;&#160;</a></span>torch_tensor_empty_or_on_cpu_check() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool torch_tensor_empty_or_on_cpu_check </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="embedding__inplace__update_8h.html#abc1167888f441327c12e300780ee568a">at::Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>ten</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="afc4520e447e8ad48a316af75860d84ae" name="afc4520e447e8ad48a316af75860d84ae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afc4520e447e8ad48a316af75860d84ae">&#9670;&#160;</a></span>torch_tensor_empty_or_on_cpu_check() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool torch_tensor_empty_or_on_cpu_check </td>
          <td>(</td>
          <td class="paramtype">const c10::optional&lt; <a class="el" href="embedding__inplace__update_8h.html#abc1167888f441327c12e300780ee568a">at::Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>ten</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="abb9778e9fb75a70593c27e53dca268cd" name="abb9778e9fb75a70593c27e53dca268cd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abb9778e9fb75a70593c27e53dca268cd">&#9670;&#160;</a></span>torch_tensor_empty_or_on_cuda_gpu_check() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool torch_tensor_empty_or_on_cuda_gpu_check </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="embedding__inplace__update_8h.html#abc1167888f441327c12e300780ee568a">at::Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>ten</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="aac863615b6eba91282fcf07b5e9a5460" name="aac863615b6eba91282fcf07b5e9a5460"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aac863615b6eba91282fcf07b5e9a5460">&#9670;&#160;</a></span>torch_tensor_empty_or_on_cuda_gpu_check() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool torch_tensor_empty_or_on_cuda_gpu_check </td>
          <td>(</td>
          <td class="paramtype">const c10::optional&lt; <a class="el" href="embedding__inplace__update_8h.html#abc1167888f441327c12e300780ee568a">at::Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>ten</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="ad971d56f6b82b6c62a2d6fed276b0463" name="ad971d56f6b82b6c62a2d6fed276b0463"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad971d56f6b82b6c62a2d6fed276b0463">&#9670;&#160;</a></span>torch_tensor_on_cpu_check() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool torch_tensor_on_cpu_check </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="embedding__inplace__update_8h.html#abc1167888f441327c12e300780ee568a">at::Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>ten</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="af4afd1e331412cf092a70d0fd816aed8" name="af4afd1e331412cf092a70d0fd816aed8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af4afd1e331412cf092a70d0fd816aed8">&#9670;&#160;</a></span>torch_tensor_on_cpu_check() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool torch_tensor_on_cpu_check </td>
          <td>(</td>
          <td class="paramtype">const c10::optional&lt; <a class="el" href="embedding__inplace__update_8h.html#abc1167888f441327c12e300780ee568a">at::Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>ten</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a5568d44e6066339da1326798f9637b16" name="a5568d44e6066339da1326798f9637b16"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5568d44e6066339da1326798f9637b16">&#9670;&#160;</a></span>torch_tensor_on_cuda_gpu_check() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool torch_tensor_on_cuda_gpu_check </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="embedding__inplace__update_8h.html#abc1167888f441327c12e300780ee568a">at::Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>ten</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a99211623695fce2a359b74a5823b58b8" name="a99211623695fce2a359b74a5823b58b8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a99211623695fce2a359b74a5823b58b8">&#9670;&#160;</a></span>torch_tensor_on_cuda_gpu_check() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool torch_tensor_on_cuda_gpu_check </td>
          <td>(</td>
          <td class="paramtype">const c10::optional&lt; <a class="el" href="embedding__inplace__update_8h.html#abc1167888f441327c12e300780ee568a">at::Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>ten</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a5683dd4c2143c3c0ba0eeb80fd5223f0" name="a5683dd4c2143c3c0ba0eeb80fd5223f0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5683dd4c2143c3c0ba0eeb80fd5223f0">&#9670;&#160;</a></span>torch_tensor_on_same_device_check() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool torch_tensor_on_same_device_check </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="embedding__inplace__update_8h.html#abc1167888f441327c12e300780ee568a">at::Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>ten1</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="embedding__inplace__update_8h.html#abc1167888f441327c12e300780ee568a">at::Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>ten2</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="ac60c66ce5a4058e4906907960f82f1be" name="ac60c66ce5a4058e4906907960f82f1be"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac60c66ce5a4058e4906907960f82f1be">&#9670;&#160;</a></span>torch_tensor_on_same_device_check() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool torch_tensor_on_same_device_check </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="embedding__inplace__update_8h.html#abc1167888f441327c12e300780ee568a">at::Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>ten1</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const c10::optional&lt; <a class="el" href="embedding__inplace__update_8h.html#abc1167888f441327c12e300780ee568a">at::Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>ten2</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="ab583553d9bf8ca92fadb8a81ffd40cd8" name="ab583553d9bf8ca92fadb8a81ffd40cd8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab583553d9bf8ca92fadb8a81ffd40cd8">&#9670;&#160;</a></span>torch_tensor_undefined() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool torch_tensor_undefined </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="embedding__inplace__update_8h.html#abc1167888f441327c12e300780ee568a">at::Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>ten</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a5e916ca6a05a17d36e5341d929cc18e0" name="a5e916ca6a05a17d36e5341d929cc18e0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5e916ca6a05a17d36e5341d929cc18e0">&#9670;&#160;</a></span>torch_tensor_undefined() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool torch_tensor_undefined </td>
          <td>(</td>
          <td class="paramtype">const c10::optional&lt; <a class="el" href="embedding__inplace__update_8h.html#abc1167888f441327c12e300780ee568a">at::Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>ten</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="ab6183b92f9eac6ca49e3055d79dfc83d" name="ab6183b92f9eac6ca49e3055d79dfc83d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab6183b92f9eac6ca49e3055d79dfc83d">&#9670;&#160;</a></span>kStackArrayMaxDims</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">constexpr size_t kStackArrayMaxDims = 5</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.10.0
</small></address>
</body>
</html>
