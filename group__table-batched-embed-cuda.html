<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.5"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>fbgemm_gpu: CUDA Operators</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">fbgemm_gpu
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.5 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">CUDA Operators</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ga50c08f9f30aa946d345e359347e77078"><td class="memItemLeft" align="right" valign="top">Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__table-batched-embed-cuda.html#ga50c08f9f30aa946d345e359347e77078">linearize_cache_indices_cuda</a> (Tensor cache_hash_size_cumsum, Tensor indices, Tensor offsets)</td></tr>
<tr class="separator:ga50c08f9f30aa946d345e359347e77078"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gac249ff0325c30030e2b02e89276e3c2a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__table-batched-embed-cuda.html#gac249ff0325c30030e2b02e89276e3c2a">lru_cache_populate_cuda</a> (Tensor weights, Tensor hash_size_cumsum, int64_t total_cache_hash_size, Tensor cache_index_table_map, Tensor weights_offsets, Tensor D_offsets, Tensor linear_cache_indices, Tensor lxu_cache_state, Tensor lxu_cache_weights, int64_t time_stamp, Tensor lru_state, bool stochastic_rounding)</td></tr>
<tr class="separator:gac249ff0325c30030e2b02e89276e3c2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga71a0615a0008433bfb961495fa613819"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__table-batched-embed-cuda.html#ga71a0615a0008433bfb961495fa613819">lru_cache_populate_byte_cuda</a> (Tensor weights, Tensor hash_size_cumsum, int64_t total_cache_hash_size, Tensor cache_index_table_map, Tensor weights_offsets, Tensor weights_tys, Tensor D_offsets, Tensor linear_cache_indices, Tensor lxu_cache_state, Tensor lxu_cache_weights, int64_t time_stamp, Tensor lru_state, int64_t row_alignment)</td></tr>
<tr class="separator:ga71a0615a0008433bfb961495fa613819"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga04f8e004bcd50f36d0a6f6ab00a8ec95"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__table-batched-embed-cuda.html#ga04f8e004bcd50f36d0a6f6ab00a8ec95">lfu_cache_populate_cuda</a> (Tensor weights, Tensor cache_hash_size_cumsum, int64_t total_cache_hash_size, Tensor cache_index_table_map, Tensor weights_offsets, Tensor D_offsets, Tensor linear_cache_indices, Tensor lxu_cache_state, Tensor lxu_cache_weights, Tensor lfu_state, bool stochastic_rounding)</td></tr>
<tr class="separator:ga04f8e004bcd50f36d0a6f6ab00a8ec95"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae4cc5aac62f83cf47ab49c96906f7b00"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__table-batched-embed-cuda.html#gae4cc5aac62f83cf47ab49c96906f7b00">lfu_cache_populate_byte_cuda</a> (Tensor weights, Tensor cache_hash_size_cumsum, int64_t total_cache_hash_size, Tensor cache_index_table_map, Tensor weights_offsets, Tensor weights_tys, Tensor D_offsets, Tensor linear_cache_indices, Tensor lxu_cache_state, Tensor lxu_cache_weights, Tensor lfu_state, int64_t row_alignment)</td></tr>
<tr class="separator:gae4cc5aac62f83cf47ab49c96906f7b00"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga52754295d9d8c8b7d73d54ab643456d0"><td class="memItemLeft" align="right" valign="top">Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__table-batched-embed-cuda.html#ga52754295d9d8c8b7d73d54ab643456d0">lxu_cache_lookup_cuda</a> (Tensor linear_cache_indices, Tensor lxu_cache_state, int64_t invalid_index)</td></tr>
<tr class="separator:ga52754295d9d8c8b7d73d54ab643456d0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2ced5bba3e0e02333122bcb1167485df"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__table-batched-embed-cuda.html#ga2ced5bba3e0e02333122bcb1167485df">lxu_cache_flush_cuda</a> (Tensor uvm_weights, Tensor cache_hash_size_cumsum, Tensor cache_index_table_map, Tensor weights_offsets, Tensor D_offsets, int64_t total_D, Tensor lxu_cache_state, Tensor lxu_cache_weights, bool stochastic_rounding)</td></tr>
<tr class="separator:ga2ced5bba3e0e02333122bcb1167485df"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<p >The following are CUDA Operators </p>
<h2 class="groupheader">Function Documentation</h2>
<a id="gae4cc5aac62f83cf47ab49c96906f7b00" name="gae4cc5aac62f83cf47ab49c96906f7b00"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae4cc5aac62f83cf47ab49c96906f7b00">&#9670;&#160;</a></span>lfu_cache_populate_byte_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void lfu_cache_populate_byte_cuda </td>
          <td>(</td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>cache_hash_size_cumsum</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int64_t&#160;</td>
          <td class="paramname"><em>total_cache_hash_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>cache_index_table_map</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>weights_offsets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>weights_tys</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>D_offsets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>linear_cache_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>lxu_cache_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>lxu_cache_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>lfu_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int64_t&#160;</td>
          <td class="paramname"><em>row_alignment</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >LFU cache: fetch the rows corresponding to <code>linear_cache_indices</code> from <code>weights</code>, and insert them into the cache. weights and lxu_cache_weights have "uint8_t" byte elements </p>

</div>
</div>
<a id="ga04f8e004bcd50f36d0a6f6ab00a8ec95" name="ga04f8e004bcd50f36d0a6f6ab00a8ec95"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga04f8e004bcd50f36d0a6f6ab00a8ec95">&#9670;&#160;</a></span>lfu_cache_populate_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void lfu_cache_populate_cuda </td>
          <td>(</td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>cache_hash_size_cumsum</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int64_t&#160;</td>
          <td class="paramname"><em>total_cache_hash_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>cache_index_table_map</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>weights_offsets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>D_offsets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>linear_cache_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>lxu_cache_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>lxu_cache_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>lfu_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>stochastic_rounding</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >LFU cache: fetch the rows corresponding to <code>linear_cache_indices</code> from <code>weights</code>, and insert them into the cache. </p>

</div>
</div>
<a id="ga50c08f9f30aa946d345e359347e77078" name="ga50c08f9f30aa946d345e359347e77078"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga50c08f9f30aa946d345e359347e77078">&#9670;&#160;</a></span>linearize_cache_indices_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Tensor linearize_cache_indices_cuda </td>
          <td>(</td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>cache_hash_size_cumsum</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>offsets</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Linearize the indices of all tables to make it be unique </p>

</div>
</div>
<a id="ga71a0615a0008433bfb961495fa613819" name="ga71a0615a0008433bfb961495fa613819"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga71a0615a0008433bfb961495fa613819">&#9670;&#160;</a></span>lru_cache_populate_byte_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void lru_cache_populate_byte_cuda </td>
          <td>(</td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>hash_size_cumsum</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int64_t&#160;</td>
          <td class="paramname"><em>total_cache_hash_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>cache_index_table_map</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>weights_offsets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>weights_tys</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>D_offsets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>linear_cache_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>lxu_cache_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>lxu_cache_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int64_t&#160;</td>
          <td class="paramname"><em>time_stamp</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>lru_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int64_t&#160;</td>
          <td class="paramname"><em>row_alignment</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >LRU cache: fetch the rows corresponding to <code>linear_cache_indices</code> from <code>weights</code>, and insert them into the cache at timestep <code>time_stamp</code>. weights and lxu_cache_weights have "uint8_t" byte elements </p>

</div>
</div>
<a id="gac249ff0325c30030e2b02e89276e3c2a" name="gac249ff0325c30030e2b02e89276e3c2a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gac249ff0325c30030e2b02e89276e3c2a">&#9670;&#160;</a></span>lru_cache_populate_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void lru_cache_populate_cuda </td>
          <td>(</td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>hash_size_cumsum</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int64_t&#160;</td>
          <td class="paramname"><em>total_cache_hash_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>cache_index_table_map</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>weights_offsets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>D_offsets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>linear_cache_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>lxu_cache_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>lxu_cache_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int64_t&#160;</td>
          <td class="paramname"><em>time_stamp</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>lru_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>stochastic_rounding</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >LRU cache: fetch the rows corresponding to <code>linear_cache_indices</code> from <code>weights</code>, and insert them into the cache at timestep <code>time_stamp</code>. </p>

</div>
</div>
<a id="ga2ced5bba3e0e02333122bcb1167485df" name="ga2ced5bba3e0e02333122bcb1167485df"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga2ced5bba3e0e02333122bcb1167485df">&#9670;&#160;</a></span>lxu_cache_flush_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void lxu_cache_flush_cuda </td>
          <td>(</td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>uvm_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>cache_hash_size_cumsum</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>cache_index_table_map</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>weights_offsets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>D_offsets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int64_t&#160;</td>
          <td class="paramname"><em>total_D</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>lxu_cache_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>lxu_cache_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>stochastic_rounding</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Flush the cache: store the weights from the cache to the backing storage. </p>

</div>
</div>
<a id="ga52754295d9d8c8b7d73d54ab643456d0" name="ga52754295d9d8c8b7d73d54ab643456d0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga52754295d9d8c8b7d73d54ab643456d0">&#9670;&#160;</a></span>lxu_cache_lookup_cuda()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Tensor lxu_cache_lookup_cuda </td>
          <td>(</td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>linear_cache_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor&#160;</td>
          <td class="paramname"><em>lxu_cache_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int64_t&#160;</td>
          <td class="paramname"><em>invalid_index</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Lookup the LRU/LFU cache: find the cache weights location for all indices. Look up the slots in the cache corresponding to <code>linear_cache_indices</code>, with a sentinel value for missing. </p>

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.5
</small></address>
</body>
</html>
